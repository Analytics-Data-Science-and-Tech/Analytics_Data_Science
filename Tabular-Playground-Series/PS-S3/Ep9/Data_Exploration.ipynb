{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e584e992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.4-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lightgbm\n",
      "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting catboost\n",
      "  Downloading catboost-1.1.1-cp310-none-manylinux1_x86_64.whl (76.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting optuna\n",
      "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.22.3)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lightgbm) (0.38.4)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lightgbm) (1.2.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (1.5.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: plotly in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (5.11.0)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (3.6.2)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (1.4.46)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (4.64.1)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (21.3)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cmaes>=0.9.1\n",
      "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=0.24.0->catboost) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (1.0.6)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from plotly->catboost) (8.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Installing collected packages: Mako, graphviz, colorlog, cmaes, xgboost, alembic, optuna, lightgbm, catboost\n",
      "Successfully installed Mako-1.2.4 alembic-1.10.2 catboost-1.1.1 cmaes-0.9.1 colorlog-6.7.0 graphviz-0.20.1 lightgbm-3.3.5 optuna-3.1.0 xgboost-1.7.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost lightgbm catboost optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9bbba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functools import partial\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, HistGradientBoostingClassifier, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor \n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "import optuna \n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Series/PS-S3/Ep9/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Series/PS-S3/Ep9/test.csv'\n",
    "file_key_3 = 'Tabular-Playground-Series/PS-S3/Ep9/sample_submission.csv'\n",
    "file_key_4 = 'Tabular-Playground-Series/PS-S3/Ep9/ConcreteStrengthData.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "bucket_object_3 = bucket.Object(file_key_3)\n",
    "file_object_3 = bucket_object_3.get()\n",
    "file_content_stream_3 = file_object_3.get('Body')\n",
    "\n",
    "bucket_object_4 = bucket.Object(file_key_4)\n",
    "file_object_4 = bucket_object_4.get()\n",
    "file_content_stream_4 = file_object_4.get('Body')\n",
    "\n",
    "## Reading data files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "submission = pd.read_csv(file_content_stream_3)\n",
    "# original = pd.read_csv(file_content_stream_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e6eca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CementComponent</th>\n",
       "      <th>BlastFurnaceSlag</th>\n",
       "      <th>FlyAshComponent</th>\n",
       "      <th>WaterComponent</th>\n",
       "      <th>SuperplasticizerComponent</th>\n",
       "      <th>CoarseAggregateComponent</th>\n",
       "      <th>FineAggregateComponent</th>\n",
       "      <th>AgeInDays</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CementComponent   BlastFurnaceSlag  FlyAshComponent  WaterComponent  \\\n",
       "0             540.0               0.0              0.0           162.0   \n",
       "1             540.0               0.0              0.0           162.0   \n",
       "2             332.5             142.5              0.0           228.0   \n",
       "3             332.5             142.5              0.0           228.0   \n",
       "4             198.6             132.4              0.0           192.0   \n",
       "\n",
       "   SuperplasticizerComponent  CoarseAggregateComponent  \\\n",
       "0                        2.5                    1040.0   \n",
       "1                        2.5                    1055.0   \n",
       "2                        0.0                     932.0   \n",
       "3                        0.0                     932.0   \n",
       "4                        0.0                     978.4   \n",
       "\n",
       "   FineAggregateComponent  AgeInDays  Strength  \n",
       "0                   676.0         28     79.99  \n",
       "1                   676.0         28     61.89  \n",
       "2                   594.0        270     40.27  \n",
       "3                   594.0        365     41.05  \n",
       "4                   825.5        360     44.30  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31b27ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5407</td>\n",
       "      <td>46.141747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5408</td>\n",
       "      <td>19.984184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5409</td>\n",
       "      <td>37.880736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5410</td>\n",
       "      <td>46.141747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>37.880736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5412</td>\n",
       "      <td>37.880736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5413</td>\n",
       "      <td>37.880736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5414</td>\n",
       "      <td>19.984184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5415</td>\n",
       "      <td>38.069818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5416</td>\n",
       "      <td>46.141747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   Strength\n",
       "0  5407  46.141747\n",
       "1  5408  19.984184\n",
       "2  5409  37.880736\n",
       "3  5410  46.141747\n",
       "4  5411  37.880736\n",
       "5  5412  37.880736\n",
       "6  5413  37.880736\n",
       "7  5414  19.984184\n",
       "8  5415  38.069818\n",
       "9  5416  46.141747"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "# X['Coarse_Fine'] = X['CoarseAggregateComponent'] / X['FineAggregateComponent']\n",
    "# X['Aggregate'] = X['CoarseAggregateComponent'] + X['FineAggregateComponent']\n",
    "# X['Slag_Cement'] = X['BlastFurnaceSlag'] / X['CementComponent']\n",
    "# X['Ash_Cement'] = X['FlyAshComponent'] / X['CementComponent']\n",
    "# X['Plastic_Cement'] = X['SuperplasticizerComponent'] / X['CementComponent']\n",
    "# X['Age_Water'] = X['AgeInDays'] / X['WaterComponent']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "# test_baseline['Coarse_Fine'] = test_baseline['CoarseAggregateComponent'] / test_baseline['FineAggregateComponent']\n",
    "# test_baseline['Aggregate'] = test_baseline['CoarseAggregateComponent'] + test_baseline['FineAggregateComponent']\n",
    "# test_baseline['Slag_Cement'] = test_baseline['BlastFurnaceSlag'] / test_baseline['CementComponent']\n",
    "# test_baseline['Ash_Cement'] = test_baseline['FlyAshComponent'] / test_baseline['CementComponent']\n",
    "# test_baseline['Plastic_Cement'] = test_baseline['SuperplasticizerComponent'] / test_baseline['CementComponent']\n",
    "# test_baseline['Age_Water'] = test_baseline['AgeInDays'] / test_baseline['WaterComponent']\n",
    "\n",
    "RF_md = RandomForestRegressor(n_estimators = 250, \n",
    "                              max_depth = 2,\n",
    "                              min_samples_split = 2,\n",
    "                              min_samples_leaf = 2).fit(X, Y)\n",
    "\n",
    "RF_pred = RF_md.predict(test_baseline)\n",
    "submission['Strength'] = RF_pred\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35fdd356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5407</td>\n",
       "      <td>47.634815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5408</td>\n",
       "      <td>20.584157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5409</td>\n",
       "      <td>34.306373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5410</td>\n",
       "      <td>47.065304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>31.262939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5412</td>\n",
       "      <td>39.992028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5413</td>\n",
       "      <td>33.404359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5414</td>\n",
       "      <td>23.408216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5415</td>\n",
       "      <td>45.831811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5416</td>\n",
       "      <td>40.655497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   Strength\n",
       "0  5407  47.634815\n",
       "1  5408  20.584157\n",
       "2  5409  34.306373\n",
       "3  5410  47.065304\n",
       "4  5411  31.262939\n",
       "5  5412  39.992028\n",
       "6  5413  33.404359\n",
       "7  5414  23.408216\n",
       "8  5415  45.831811\n",
       "9  5416  40.655497"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "\n",
    "hist_md = HistGradientBoostingRegressor(l2_regularization = 0.01,\n",
    "                                        early_stopping = False,\n",
    "                                        learning_rate = 0.01,\n",
    "                                        max_iter = 1000,\n",
    "                                        max_depth = 2,\n",
    "                                        max_bins = 255,\n",
    "                                        min_samples_leaf = 10,\n",
    "                                        max_leaf_nodes = 10).fit(X, Y)\n",
    "\n",
    "hist_pred = hist_md.predict(test_baseline)\n",
    "submission['Strength'] = hist_pred\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa37f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "\n",
    "lgb_md = LGBMRegressor(n_estimators = 1000,\n",
    "                       max_depth = 2,\n",
    "                       learning_rate = 0.01,\n",
    "                       num_leaves = 20,\n",
    "                       lambda_l1 = 3,\n",
    "                       lambda_l2 = 3,\n",
    "                       bagging_fraction = 0.7,\n",
    "                       feature_fraction = 0.7).fit(X, Y)\n",
    "\n",
    "lgb_pred = lgb_md.predict(test_baseline)\n",
    "submission['Strength'] = lgb_pred\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5b618",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lgb_full_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "386e6a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5407</td>\n",
       "      <td>47.530796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5408</td>\n",
       "      <td>20.616440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5409</td>\n",
       "      <td>33.766331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5410</td>\n",
       "      <td>46.767071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>33.138821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5412</td>\n",
       "      <td>39.776501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5413</td>\n",
       "      <td>33.750774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5414</td>\n",
       "      <td>23.091179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5415</td>\n",
       "      <td>44.752090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5416</td>\n",
       "      <td>40.118263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   Strength\n",
       "0  5407  47.530796\n",
       "1  5408  20.616440\n",
       "2  5409  33.766331\n",
       "3  5410  46.767071\n",
       "4  5411  33.138821\n",
       "5  5412  39.776501\n",
       "6  5413  33.750774\n",
       "7  5414  23.091179\n",
       "8  5415  44.752090\n",
       "9  5416  40.118263"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "\n",
    "XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "                      colsample_bytree = 0.7, \n",
    "                      gamma = 0.8, \n",
    "                      learning_rate = 0.01, \n",
    "                      max_depth = 2, \n",
    "                      min_child_weight = 10, \n",
    "                      n_estimators = 1000, \n",
    "                      subsample = 0.7).fit(X, Y)\n",
    "\n",
    "xgb_pred = XGB_md.predict(test_baseline)\n",
    "submission['Strength'] = xgb_pred\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bac970",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('xgb_full_submission_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87fc5cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5407</td>\n",
       "      <td>47.280411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5408</td>\n",
       "      <td>18.968193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5409</td>\n",
       "      <td>33.108115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5410</td>\n",
       "      <td>47.048871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>32.547861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5412</td>\n",
       "      <td>39.103932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5413</td>\n",
       "      <td>34.036958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5414</td>\n",
       "      <td>22.002971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5415</td>\n",
       "      <td>46.392186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5416</td>\n",
       "      <td>40.093044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   Strength\n",
       "0  5407  47.280411\n",
       "1  5408  18.968193\n",
       "2  5409  33.108115\n",
       "3  5410  47.048871\n",
       "4  5411  32.547861\n",
       "5  5412  39.103932\n",
       "6  5413  34.036958\n",
       "7  5414  22.002971\n",
       "8  5415  46.392186\n",
       "9  5416  40.093044"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "# X['Coarse_Fine'] = X['CoarseAggregateComponent'] / X['FineAggregateComponent']\n",
    "# X['Aggregate'] = X['CoarseAggregateComponent'] + X['FineAggregateComponent']\n",
    "# X['Slag_Cement'] = X['BlastFurnaceSlag'] / X['CementComponent']\n",
    "# X['Ash_Cement'] = X['FlyAshComponent'] / X['CementComponent']\n",
    "# X['Plastic_Cement'] = X['SuperplasticizerComponent'] / X['CementComponent']\n",
    "X['Age_Water'] = X['AgeInDays'] / X['WaterComponent']\n",
    "\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "# test_baseline['Coarse_Fine'] = test_baseline['CoarseAggregateComponent'] / test_baseline['FineAggregateComponent']\n",
    "# test_baseline['Aggregate'] = test_baseline['CoarseAggregateComponent'] + test_baseline['FineAggregateComponent']\n",
    "# test_baseline['Slag_Cement'] = test_baseline['BlastFurnaceSlag'] / test_baseline['CementComponent']\n",
    "# test_baseline['Ash_Cement'] = test_baseline['FlyAshComponent'] / test_baseline['CementComponent']\n",
    "# test_baseline['Plastic_Cement'] = test_baseline['SuperplasticizerComponent'] / test_baseline['CementComponent']\n",
    "test_baseline['Age_Water'] = test_baseline['AgeInDays'] / test_baseline['WaterComponent']\n",
    "\n",
    "\n",
    "cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                           iterations = 1000,\n",
    "                           learning_rate = 0.01,\n",
    "                           depth = 3,\n",
    "                           random_strength = 0.5,\n",
    "                           bagging_temperature = 0.7,\n",
    "                           border_count = 30,\n",
    "                           l2_leaf_reg = 5,\n",
    "                           verbose = False).fit(X, Y)\n",
    "\n",
    "cat_pred = cat_md.predict(test_baseline)\n",
    "submission['Strength'] = cat_pred\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5d9d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('catboost_full_submission_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "904afe05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5407</td>\n",
       "      <td>47.482007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5408</td>\n",
       "      <td>20.056263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5409</td>\n",
       "      <td>33.726940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5410</td>\n",
       "      <td>46.960415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>32.316540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   Strength\n",
       "0  5407  47.482007\n",
       "1  5408  20.056263\n",
       "2  5409  33.726940\n",
       "3  5410  46.960415\n",
       "4  5411  32.316540"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['Strength'] = (cat_pred + xgb_pred + hist_pred) / 3\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e01007dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('catboost_xgb_hist_full_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc07b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da07e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "\n",
    "preds_train, preds_test = list(), list()\n",
    "\n",
    "for i in tqdm(range(0, 1000)):\n",
    "    \n",
    "    CatBoostRegressor(loss_function = 'RMSE',\n",
    "                           iterations = 1000,\n",
    "                           learning_rate = 0.01,\n",
    "                           depth = 3,\n",
    "                           random_strength = 0.5,\n",
    "                           bagging_temperature = 0.7,\n",
    "                           border_count = 30,\n",
    "                           l2_leaf_reg = 5,\n",
    "                           verbose = False, \n",
    "                           random_seed = i).fit(X, Y)\n",
    "    \n",
    "#     cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "#                                iterations = 1756,\n",
    "#                                learning_rate = 0.017975994415651907,\n",
    "#                                depth = 3,\n",
    "#                                random_strength = 2.8219170899365174,\n",
    "#                                bagging_temperature = 0.19623966374044916,\n",
    "#                                border_count = 70,\n",
    "#                                l2_leaf_reg = 29,\n",
    "#                                verbose = False,\n",
    "#                                random_seed = i).fit(X, Y)\n",
    "    \n",
    "    preds_train.append(cat_md.predict(X))\n",
    "    preds_test.append(cat_md.predict(test_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1794605",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_preds_test = pd.DataFrame(preds_test).apply(np.mean, axis = 0)\n",
    "\n",
    "submission['Strength'] = cat_preds_test\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2345aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('catboost_full_1000_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5634f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedEnsemble(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _rmse_loss(self, coef, X, y):\n",
    "        \n",
    "        n = X.shape[1]\n",
    "        ens = 0\n",
    "        for i in range(0, n):\n",
    "            ens += coef[i]*X[:, i]\n",
    "        \n",
    "        ll = mean_squared_error(y, ens, squared = False)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._rmse_loss, X = X, y = y)\n",
    "        n = X.shape[1]\n",
    "        initial_coef = np.repeat(1/n, n)\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method = 'nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        \n",
    "        n = X.shape[1]\n",
    "        ens = 0\n",
    "        for i in range(0, n):\n",
    "            ens += coef[i]*X[:, i]\n",
    "        return ens\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61686a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pred_train = np.array(pd.DataFrame(preds_train).T)\n",
    "models_pred_oof = np.array(pd.DataFrame(preds_test).T)\n",
    "\n",
    "# n = models_pred_oof.shape[1]\n",
    "# ens = 0\n",
    "# for i in range(0, n):\n",
    "#     ens += models_pred_oof[:, i]\n",
    "\n",
    "opt_ens = OptimizedEnsemble()\n",
    "opt_ens.fit(models_pred_train, Y)\n",
    "coef = opt_ens.coefficients()\n",
    "ens_pred_train = opt_ens.predict(models_pred_train, coef)\n",
    "ens_pred_test = opt_ens.predict(models_pred_oof, coef)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09624736",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(Y, ens_pred_train, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b35d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175699e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Strength'] = ens_pred_test\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4503e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('catboost_full_50_opt_ens_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b80411d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9f4a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de001357",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(pd.DataFrame(preds).T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c558a5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782a3a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "XGB_cv_scores, XGB_imp = list(), list()\n",
    "XGB_preds = list()\n",
    "\n",
    "lgb_cv_scores, lgb_imp = list(), list()\n",
    "lgb_preds = list()\n",
    "\n",
    "cat_cv_scores, cat_imp = list(), list()\n",
    "cat_preds = list()\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    skf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############    \n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "        XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "                              colsample_bytree = 0.7, \n",
    "                              gamma = 0.8, \n",
    "                              learning_rate = 0.01, \n",
    "                              max_depth = 7, \n",
    "                              min_child_weight = 10, \n",
    "                              n_estimators = 1000, \n",
    "                              subsample = 0.7).fit(X_train, Y_train)\n",
    "        XGB_imp.append(XGB_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        XGB_pred_1 = XGB_md.predict(X_test)\n",
    "        XGB_pred_2 = XGB_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        XGB_cv_scores.append(mean_squared_error(Y_test, XGB_pred_1, squared = False))\n",
    "        XGB_preds.append(XGB_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## LightGBM ##\n",
    "        ##############\n",
    "        \n",
    "        lgb_md = LGBMRegressor(n_estimators = 1000,\n",
    "                               max_depth = 7,\n",
    "                               learning_rate = 0.01,\n",
    "                               num_leaves = 20,\n",
    "                               lambda_l1 = 3,\n",
    "                               lambda_l2 = 3,\n",
    "                               bagging_fraction = 0.7,\n",
    "                               feature_fraction = 0.7).fit(X_train, Y_train)\n",
    "        lgb_imp.append(lgb_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        lgb_pred_1 = lgb_md.predict(X_test)\n",
    "        lgb_pred_2 = lgb_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        lgb_cv_scores.append(mean_squared_error(Y_test, lgb_pred_1, squared = False))\n",
    "        lgb_preds.append(lgb_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## CatBoost ##\n",
    "        ##############\n",
    "        \n",
    "        cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                                   iterations = 1000,\n",
    "                                   learning_rate = 0.01,\n",
    "                                   depth = 7,\n",
    "                                   random_strength = 0.5,\n",
    "                                   bagging_temperature = 0.7,\n",
    "                                   border_count = 30,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   verbose = False).fit(X_train, Y_train)\n",
    "        cat_imp.append(cat_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        cat_pred_1 = cat_md.predict(X_test)\n",
    "        cat_pred_2 = cat_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        cat_cv_scores.append(mean_squared_error(Y_test, cat_pred_1, squared = False))\n",
    "        cat_preds.append(cat_pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924e7997",
   "metadata": {},
   "source": [
    "# Baseline Modeling 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29d9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "XGB_cv_scores, XGB_imp = list(), list()\n",
    "XGB_preds = list()\n",
    "\n",
    "lgb_cv_scores, lgb_imp = list(), list()\n",
    "lgb_preds = list()\n",
    "\n",
    "cat_cv_scores, cat_imp = list(), list()\n",
    "cat_preds = list()\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    skf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############    \n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "        XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "                              colsample_bytree = 0.7, \n",
    "                              gamma = 0.8, \n",
    "                              learning_rate = 0.01, \n",
    "                              max_depth = 7, \n",
    "                              min_child_weight = 10, \n",
    "                              n_estimators = 1000, \n",
    "                              subsample = 0.7).fit(X_train, Y_train)\n",
    "        XGB_imp.append(XGB_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        XGB_pred_1 = XGB_md.predict(X_test)\n",
    "        XGB_pred_2 = XGB_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        XGB_cv_scores.append(mean_squared_error(Y_test, XGB_pred_1, squared = False))\n",
    "        XGB_preds.append(XGB_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## LightGBM ##\n",
    "        ##############\n",
    "        \n",
    "        lgb_md = LGBMRegressor(n_estimators = 1000,\n",
    "                               max_depth = 7,\n",
    "                               learning_rate = 0.01,\n",
    "                               num_leaves = 20,\n",
    "                               lambda_l1 = 3,\n",
    "                               lambda_l2 = 3,\n",
    "                               bagging_fraction = 0.7,\n",
    "                               feature_fraction = 0.7).fit(X_train, Y_train)\n",
    "        lgb_imp.append(lgb_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        lgb_pred_1 = lgb_md.predict(X_test)\n",
    "        lgb_pred_2 = lgb_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        lgb_cv_scores.append(mean_squared_error(Y_test, lgb_pred_1, squared = False))\n",
    "        lgb_preds.append(lgb_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## CatBoost ##\n",
    "        ##############\n",
    "        \n",
    "        cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                                   iterations = 1000,\n",
    "                                   learning_rate = 0.01,\n",
    "                                   depth = 7,\n",
    "                                   random_strength = 0.5,\n",
    "                                   bagging_temperature = 0.7,\n",
    "                                   border_count = 30,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   verbose = False).fit(X_train, Y_train)\n",
    "        cat_imp.append(cat_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        cat_pred_1 = cat_md.predict(X_test)\n",
    "        cat_pred_2 = cat_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        cat_cv_scores.append(mean_squared_error(Y_test, cat_pred_1, squared = False))\n",
    "        cat_preds.append(cat_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f41cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_cv_score = np.mean(XGB_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the XGBoost model is:', XGB_cv_score)\n",
    "\n",
    "lgb_cv_score = np.mean(lgb_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the LightGBM model is:', lgb_cv_score)\n",
    "\n",
    "cat_cv_score = np.mean(cat_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the CatBoost model is:', cat_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f8a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_preds_test = pd.DataFrame(cat_preds).apply(np.mean, axis = 0)\n",
    "\n",
    "submission['Strength'] = cat_preds_test\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4954ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('catboost_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab743d",
   "metadata": {},
   "source": [
    "# Baseline Modeling 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0924c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_dup = train.drop(columns = 'id', axis = 1)\n",
    "train_no_dup = pd.DataFrame(train_no_dup.groupby(train_no_dup.columns.tolist()[0:8])['Strength'].mean()).reset_index()\n",
    "\n",
    "X = train_no_dup.drop(columns = ['Strength'], axis = 1)\n",
    "Y = train_no_dup['Strength']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "XGB_cv_scores, XGB_imp = list(), list()\n",
    "XGB_preds = list()\n",
    "\n",
    "lgb_cv_scores, lgb_imp = list(), list()\n",
    "lgb_preds = list()\n",
    "\n",
    "cat_cv_scores, cat_imp = list(), list()\n",
    "cat_preds = list()\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    skf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############    \n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "        XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "                              colsample_bytree = 0.7, \n",
    "                              gamma = 0.8, \n",
    "                              learning_rate = 0.01, \n",
    "                              max_depth = 7, \n",
    "                              min_child_weight = 10, \n",
    "                              n_estimators = 1000, \n",
    "                              subsample = 0.7).fit(X_train, Y_train)\n",
    "        XGB_imp.append(XGB_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        XGB_pred_1 = XGB_md.predict(X_test)\n",
    "        XGB_pred_2 = XGB_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        XGB_cv_scores.append(mean_squared_error(Y_test, XGB_pred_1, squared = False))\n",
    "        XGB_preds.append(XGB_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## LightGBM ##\n",
    "        ##############\n",
    "        \n",
    "        lgb_md = LGBMRegressor(n_estimators = 1000,\n",
    "                               max_depth = 7,\n",
    "                               learning_rate = 0.01,\n",
    "                               num_leaves = 20,\n",
    "                               lambda_l1 = 3,\n",
    "                               lambda_l2 = 3,\n",
    "                               bagging_fraction = 0.7,\n",
    "                               feature_fraction = 0.7).fit(X_train, Y_train)\n",
    "        lgb_imp.append(lgb_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        lgb_pred_1 = lgb_md.predict(X_test)\n",
    "        lgb_pred_2 = lgb_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        lgb_cv_scores.append(mean_squared_error(Y_test, lgb_pred_1, squared = False))\n",
    "        lgb_preds.append(lgb_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## CatBoost ##\n",
    "        ##############\n",
    "        \n",
    "        cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                                   iterations = 1000,\n",
    "                                   learning_rate = 0.01,\n",
    "                                   depth = 7,\n",
    "                                   random_strength = 0.5,\n",
    "                                   bagging_temperature = 0.7,\n",
    "                                   border_count = 30,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   verbose = False).fit(X_train, Y_train)\n",
    "        cat_imp.append(cat_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        cat_pred_1 = cat_md.predict(X_test)\n",
    "        cat_pred_2 = cat_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        cat_cv_scores.append(mean_squared_error(Y_test, cat_pred_1, squared = False))\n",
    "        cat_preds.append(cat_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca404d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_cv_score = np.mean(XGB_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the XGBoost model is:', XGB_cv_score)\n",
    "\n",
    "lgb_cv_score = np.mean(lgb_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the LightGBM model is:', lgb_cv_score)\n",
    "\n",
    "cat_cv_score = np.mean(cat_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the CatBoost model is:', cat_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_preds_test = pd.DataFrame(cat_preds).apply(np.mean, axis = 0)\n",
    "\n",
    "submission['Strength'] = cat_preds_test\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc09cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('catboost_submission_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdd1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_dup = train.drop(columns = 'id', axis = 1)\n",
    "train_no_dup = pd.DataFrame(train_no_dup.groupby(train_no_dup.columns.tolist()[0:8])['Strength'].median()).reset_index()\n",
    "\n",
    "X = train_no_dup.drop(columns = ['Strength'], axis = 1)\n",
    "Y = train_no_dup['Strength']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "XGB_cv_scores, XGB_imp = list(), list()\n",
    "XGB_preds = list()\n",
    "\n",
    "lgb_cv_scores, lgb_imp = list(), list()\n",
    "lgb_preds = list()\n",
    "\n",
    "cat_cv_scores, cat_imp = list(), list()\n",
    "cat_preds = list()\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    skf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############    \n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "#         XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "#                               colsample_bytree = 0.7, \n",
    "#                               gamma = 0.8, \n",
    "#                               learning_rate = 0.01, \n",
    "#                               max_depth = 7, \n",
    "#                               min_child_weight = 10, \n",
    "#                               n_estimators = 1000, \n",
    "#                               subsample = 0.7).fit(X_train, Y_train)\n",
    "#         XGB_imp.append(XGB_md.feature_importances_)\n",
    "        \n",
    "#         ## Predicting on X_test and test\n",
    "#         XGB_pred_1 = XGB_md.predict(X_test)\n",
    "#         XGB_pred_2 = XGB_md.predict(test_baseline)\n",
    "        \n",
    "#         ## Computing rmse\n",
    "#         XGB_cv_scores.append(mean_squared_error(Y_test, XGB_pred_1, squared = False))\n",
    "#         XGB_preds.append(XGB_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## LightGBM ##\n",
    "        ##############\n",
    "        \n",
    "#         lgb_md = LGBMRegressor(n_estimators = 1000,\n",
    "#                                max_depth = 7,\n",
    "#                                learning_rate = 0.01,\n",
    "#                                num_leaves = 20,\n",
    "#                                lambda_l1 = 3,\n",
    "#                                lambda_l2 = 3,\n",
    "#                                bagging_fraction = 0.7,\n",
    "#                                feature_fraction = 0.7).fit(X_train, Y_train)\n",
    "#         lgb_imp.append(lgb_md.feature_importances_)\n",
    "        \n",
    "#         ## Predicting on X_test and test\n",
    "#         lgb_pred_1 = lgb_md.predict(X_test)\n",
    "#         lgb_pred_2 = lgb_md.predict(test_baseline)\n",
    "        \n",
    "#         ## Computing rmse\n",
    "#         lgb_cv_scores.append(mean_squared_error(Y_test, lgb_pred_1, squared = False))\n",
    "#         lgb_preds.append(lgb_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## CatBoost ##\n",
    "        ##############\n",
    "        \n",
    "        cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                                   iterations = 4738,\n",
    "                                   learning_rate = 0.003143666241424718,\n",
    "                                   depth = 4,\n",
    "                                   random_strength = 0.29823973415192867,\n",
    "                                   bagging_temperature = 0.3408793603898661,\n",
    "                                   border_count = 112,\n",
    "                                   l2_leaf_reg = 17,\n",
    "                                   verbose = False).fit(X_train, Y_train)\n",
    "        cat_imp.append(cat_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        cat_pred_1 = cat_md.predict(X_test)\n",
    "        cat_pred_2 = cat_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        cat_cv_scores.append(mean_squared_error(Y_test, cat_pred_1, squared = False))\n",
    "        cat_preds.append(cat_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b016a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB_cv_score = np.mean(XGB_cv_scores)    \n",
    "# print('The average oof rmse score over 5-folds (run 5 times) of the XGBoost model is:', XGB_cv_score)\n",
    "\n",
    "# lgb_cv_score = np.mean(lgb_cv_scores)    \n",
    "# print('The average oof rmse score over 5-folds (run 5 times) of the LightGBM model is:', lgb_cv_score)\n",
    "\n",
    "cat_cv_score = np.mean(cat_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the CatBoost model is:', cat_cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e633240",
   "metadata": {},
   "source": [
    "# Baseline 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366127de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedEnsemble(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _rmse_loss(self, coef, X, y):\n",
    "        \n",
    "        ens = coef[0]*X[:, 0] + coef[1]*X[:, 1] + coef[2]*X[:, 2]\n",
    "        ll = mean_squared_error(y, ens, squared = False)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._rmse_loss, X = X, y = y)\n",
    "        initial_coef = [1/3, 1/3, 1/3]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method = 'nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        \n",
    "        ens = coef[0]*X[:, 0] + coef[1]*X[:, 1] + coef[2]*X[:, 2]\n",
    "        return ens\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd42d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_dup = train.drop(columns = 'id', axis = 1)\n",
    "train_no_dup = pd.DataFrame(train_no_dup.groupby(train_no_dup.columns.tolist()[0:8])['Strength'].median()).reset_index()\n",
    "\n",
    "X = train_no_dup.drop(columns = ['Strength'], axis = 1)\n",
    "Y = train_no_dup['Strength']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "ens_cv_scores, preds = list(), list()\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "\n",
    "    skf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############    \n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "        XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "                              colsample_bytree = 0.671460244215802, \n",
    "                              gamma = 2.5281806276307384, \n",
    "                              learning_rate = 0.002046162779305807, \n",
    "                              max_depth = 8, \n",
    "                              min_child_weight = 80, \n",
    "                              n_estimators = 2690, \n",
    "                              subsample = 0.44886485549735244).fit(X_train, Y_train)\n",
    "        \n",
    "        ##############\n",
    "        ## LightGBM ##\n",
    "        ##############\n",
    "        \n",
    "        lgb_md = LGBMRegressor(n_estimators = 5420,\n",
    "                               max_depth = 3,\n",
    "                               learning_rate = 0.0014779400349972686,\n",
    "                               num_leaves = 61,\n",
    "                               lambda_l1 = 7.384172796287736,\n",
    "                               lambda_l2 = 0.10456555506292783,\n",
    "                               bagging_fraction = 0.22841166601766863,\n",
    "                               feature_fraction = 0.659898030).fit(X_train, Y_train)\n",
    "        \n",
    "        ##############\n",
    "        ## CatBoost ##\n",
    "        ##############\n",
    "        \n",
    "        cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                                   iterations = 4738,\n",
    "                                   learning_rate = 0.003143666241424718,\n",
    "                                   depth = 4,\n",
    "                                   random_strength = 0.29823973415192867,\n",
    "                                   bagging_temperature = 0.3408793603898661,\n",
    "                                   border_count = 112,\n",
    "                                   l2_leaf_reg = 17,\n",
    "                                   verbose = False).fit(X_train, Y_train)\n",
    "        \n",
    "        ######################\n",
    "        ## Optimal Ensemble ##\n",
    "        ######################\n",
    "        \n",
    "        XGB_pred_1 = XGB_md.predict(X_test)\n",
    "        lgb_pred_1 = lgb_md.predict(X_test)\n",
    "        cat_pred_1 = cat_md.predict(X_test)\n",
    "        models_pred_oof = np.transpose((XGB_pred_1, lgb_pred_1, cat_pred_1))\n",
    "\n",
    "        opt_ens = OptimizedEnsemble()\n",
    "        opt_ens.fit(models_pred_oof, Y_test)\n",
    "        coef = opt_ens.coefficients()\n",
    "        \n",
    "        ens_pred = opt_ens.predict(models_pred_oof, coef)\n",
    "        ens_cv_scores.append(mean_squared_error(Y_test, ens_pred, squared = False))\n",
    "        \n",
    "        XGB_pred_2 = XGB_md.predict(test_baseline)\n",
    "        lgb_pred_2 = lgb_md.predict(test_baseline)\n",
    "        cat_pred_2 = cat_md.predict(test_baseline)\n",
    "        models_pred = np.transpose((XGB_pred_2, lgb_pred_2, cat_pred_2))\n",
    "        \n",
    "        ens_preds = opt_ens.predict(models_pred, coef)\n",
    "        preds.append(ens_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48965206",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_cv_score = np.mean(ens_cv_scores) # first run    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the ensemble model is:', ens_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_cv_score = np.mean(ens_cv_scores)  # second run  \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the ensemble model is:', ens_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_preds_test = pd.DataFrame(preds).apply(np.mean, axis = 0)\n",
    "\n",
    "submission['Strength'] = ens_preds_test\n",
    "submission.to_csv('Ensemble_Optuna_baseline_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adea8bba",
   "metadata": {},
   "source": [
    "## Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adccbc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290278f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecd5f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9bc8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b531f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0de5134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf60f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77775155",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_dup = train.drop(columns = 'id', axis = 1)\n",
    "train_no_dup = pd.DataFrame(train_no_dup.groupby(train_no_dup.columns.tolist()[0:8])['Strength'].median()).reset_index()\n",
    "\n",
    "X = train_no_dup.drop(columns = ['Strength'], axis = 1)\n",
    "Y = train_no_dup['Strength']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "ens_cv_scores, preds = list(), list()\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "\n",
    "    skf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "#         #############    \n",
    "#         ## XGBoost ##\n",
    "#         #############\n",
    "        \n",
    "#         XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "#                               colsample_bytree = 0.671460244215802, \n",
    "#                               gamma = 2.5281806276307384, \n",
    "#                               learning_rate = 0.002046162779305807, \n",
    "#                               max_depth = 8, \n",
    "#                               min_child_weight = 80, \n",
    "#                               n_estimators = 2690, \n",
    "#                               subsample = 0.44886485549735244).fit(X_train, Y_train)\n",
    "        \n",
    "#         ##############\n",
    "#         ## LightGBM ##\n",
    "#         ##############\n",
    "        \n",
    "#         lgb_md = LGBMRegressor(n_estimators = 5420,\n",
    "#                                max_depth = 3,\n",
    "#                                learning_rate = 0.0014779400349972686,\n",
    "#                                num_leaves = 61,\n",
    "#                                lambda_l1 = 7.384172796287736,\n",
    "#                                lambda_l2 = 0.10456555506292783,\n",
    "#                                bagging_fraction = 0.22841166601766863,\n",
    "#                                feature_fraction = 0.659898030).fit(X_train, Y_train)\n",
    "        \n",
    "        ##############\n",
    "        ## CatBoost ##\n",
    "        ##############\n",
    "        \n",
    "        cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                                   iterations = 4738,\n",
    "                                   learning_rate = 0.003143666241424718,\n",
    "                                   depth = 4,\n",
    "                                   random_strength = 0.29823973415192867,\n",
    "                                   bagging_temperature = 0.3408793603898661,\n",
    "                                   border_count = 112,\n",
    "                                   l2_leaf_reg = 17,\n",
    "                                   verbose = False).fit(X_train, Y_train)\n",
    "        \n",
    "        ######################\n",
    "        ## Optimal Ensemble ##\n",
    "        ######################\n",
    "        \n",
    "        XGB_pred_1 = XGB_md.predict(X_test)\n",
    "        lgb_pred_1 = lgb_md.predict(X_test)\n",
    "        cat_pred_1 = cat_md.predict(X_test)\n",
    "        models_pred_oof = np.transpose((XGB_pred_1, lgb_pred_1, cat_pred_1))\n",
    "\n",
    "        opt_ens = OptimizedEnsemble()\n",
    "        opt_ens.fit(models_pred_oof, Y_test)\n",
    "        coef = opt_ens.coefficients()\n",
    "        \n",
    "        ens_pred = opt_ens.predict(models_pred_oof, coef)\n",
    "        ens_cv_scores.append(mean_squared_error(Y_test, ens_pred, squared = False))\n",
    "        \n",
    "        XGB_pred_2 = XGB_md.predict(test_baseline)\n",
    "        lgb_pred_2 = lgb_md.predict(test_baseline)\n",
    "        cat_pred_2 = cat_md.predict(test_baseline)\n",
    "        models_pred = np.transpose((XGB_pred_2, lgb_pred_2, cat_pred_2))\n",
    "        \n",
    "        ens_preds = opt_ens.predict(models_pred, coef)\n",
    "        preds.append(ens_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e27e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c058faf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0841ebb8",
   "metadata": {},
   "source": [
    "# Baseline 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61685b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedEnsemble(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _rmse_loss(self, coef, X, y):\n",
    "        \n",
    "        ens = coef[0]*X[:, 0] + coef[1]*X[:, 1] + coef[2]*X[:, 2]\n",
    "        ll = mean_squared_error(y, ens, squared = False)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._rmse_loss, X = X, y = y)\n",
    "        initial_coef = [1/3, 1/3, 1/3]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method = 'nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        \n",
    "        ens = coef[0]*X[:, 0] + coef[1]*X[:, 1] + coef[2]*X[:, 2]\n",
    "        return ens\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87858af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_dup = train.drop(columns = 'id', axis = 1)\n",
    "train_no_dup = pd.DataFrame(train_no_dup.groupby(train_no_dup.columns.tolist()[0:8])['Strength'].median()).reset_index()\n",
    "\n",
    "X = train_no_dup.drop(columns = ['Strength'], axis = 1)\n",
    "Y = train_no_dup['Strength']\n",
    "\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "\n",
    "ens_cv_scores, preds = list(), list()\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "\n",
    "    skf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############    \n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "        XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "                              colsample_bytree = 0.7940111565728297, \n",
    "                              gamma = 3.3316249893010292, \n",
    "                              learning_rate = 0.0009167011149361065, \n",
    "                              max_depth = 8, \n",
    "                              min_child_weight = 89, \n",
    "                              n_estimators = 6766, \n",
    "                              subsample = 0.3771654611184001).fit(X_train, Y_train)\n",
    "        \n",
    "        ##############\n",
    "        ## LightGBM ##\n",
    "        ##############\n",
    "        \n",
    "        lgb_md = LGBMRegressor(n_estimators = 4273,\n",
    "                               max_depth = 4,\n",
    "                               learning_rate = 0.002480759916271656,\n",
    "                               num_leaves = 5,\n",
    "                               lambda_l1 = 1.2582711296889206,\n",
    "                               lambda_l2 = 0.018040323452000916,\n",
    "                               bagging_fraction = 0.7658802307213928,\n",
    "                               feature_fraction = 0.4895760311486668).fit(X_train, Y_train)\n",
    "        \n",
    "        ##############\n",
    "        ## CatBoost ##\n",
    "        ##############\n",
    "        \n",
    "        cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                                   iterations = 416,\n",
    "                                   learning_rate = 0.031225761812299576,\n",
    "                                   depth = 4,\n",
    "                                   random_strength = 0.19789440193456237,\n",
    "                                   bagging_temperature = 0.2831892755259466,\n",
    "                                   border_count = 56,\n",
    "                                   l2_leaf_reg = 26,\n",
    "                                   verbose = False).fit(X_train, Y_train)\n",
    "        \n",
    "        ######################\n",
    "        ## Optimal Ensemble ##\n",
    "        ######################\n",
    "        \n",
    "        XGB_pred_1 = XGB_md.predict(X_test)\n",
    "        lgb_pred_1 = lgb_md.predict(X_test)\n",
    "        cat_pred_1 = cat_md.predict(X_test)\n",
    "        models_pred_oof = np.transpose((XGB_pred_1, lgb_pred_1, cat_pred_1))\n",
    "\n",
    "        opt_ens = OptimizedEnsemble()\n",
    "        opt_ens.fit(models_pred_oof, Y_test)\n",
    "        coef = opt_ens.coefficients()\n",
    "        \n",
    "        ens_pred = opt_ens.predict(models_pred_oof, coef)\n",
    "        ens_cv_scores.append(mean_squared_error(Y_test, ens_pred, squared = False))\n",
    "        \n",
    "        XGB_pred_2 = XGB_md.predict(test_baseline)\n",
    "        lgb_pred_2 = lgb_md.predict(test_baseline)\n",
    "        cat_pred_2 = cat_md.predict(test_baseline)\n",
    "        models_pred = np.transpose((XGB_pred_2, lgb_pred_2, cat_pred_2))\n",
    "        \n",
    "        ens_preds = opt_ens.predict(models_pred, coef)\n",
    "        preds.append(ens_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9f5d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_cv_score = np.mean(ens_cv_scores) \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the ensemble model is:', ens_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474a9b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_preds_test = pd.DataFrame(preds).apply(np.mean, axis = 0)\n",
    "\n",
    "submission['Strength'] = ens_preds_test\n",
    "submission.to_csv('Ensemble_Optuna_baseline_submission_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0476ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a6a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cv_score = np.mean(cat_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the CatBoost model is:', cat_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a051ecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cv_score = np.mean(cat_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the CatBoost model is:', cat_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cbb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cv_score = np.mean(cat_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the CatBoost model is:', cat_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_preds_test = pd.DataFrame(cat_preds).apply(np.mean, axis = 0)\n",
    "\n",
    "submission['Strength'] = cat_preds_test\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88679f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('catboost_submission_6.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
