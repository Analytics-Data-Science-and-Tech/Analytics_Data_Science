{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424534b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lightgbm optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ab86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, cohen_kappa_score, davies_bouldin_score, calinski_harabasz_score, silhouette_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "# from xgboost import XGBClassifier, XGBRegressor\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "import optuna \n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Series/TS-S3-Ep5/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Series/TS-S3-Ep5/test.csv'\n",
    "file_key_3 = 'Tabular-Playground-Series/TS-S3-Ep5/sample_submission.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "bucket_object_3 = bucket.Object(file_key_3)\n",
    "file_object_3 = bucket_object_3.get()\n",
    "file_content_stream_3 = file_object_3.get('Body')\n",
    "\n",
    "## Reading data files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "submission = pd.read_csv(file_content_stream_3)\n",
    "\n",
    "## Enginering features\n",
    "train['alcohol_density'] = train['alcohol'] * train['density']\n",
    "train['sulphate/density'] = train['sulphates']  / train['density']\n",
    "train['alcohol_sulphate'] = train['alcohol'] * train['sulphates']\n",
    "\n",
    "test['alcohol_density'] = test['alcohol']  * test['density']\n",
    "test['sulphate/density'] = test['sulphates']  / test['density']\n",
    "test['alcohol_sulphate'] = test['alcohol'] * test['sulphates']\n",
    "\n",
    "test_md = test.copy()\n",
    "\n",
    "X = train[['sulphate/density', 'alcohol_density', 'alcohol', 'sulphates']]\n",
    "Y = train['quality'] \n",
    "\n",
    "test_md = test_md[['sulphate/density', 'alcohol_density', 'alcohol', 'sulphates']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d606b00",
   "metadata": {},
   "source": [
    "# Optimal Rounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa47e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 3\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 4\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 5\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 6\n",
    "            elif pred >= coef[3] and pred < coef[4]:\n",
    "                X_p[i] = 7\n",
    "            else:\n",
    "                X_p[i] = 8\n",
    "\n",
    "        ll = cohen_kappa_score(y, X_p, weights = 'quadratic')\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X = X, y = y)\n",
    "        initial_coef = [3.5, 4.5, 5.5, 6.5, 7.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method = 'nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 3\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 4\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 5\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 6\n",
    "            elif pred >= coef[3] and pred < coef[4]:\n",
    "                X_p[i] = 7\n",
    "            else:\n",
    "                X_p[i] = 8\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09541f6",
   "metadata": {},
   "source": [
    "# Optuna Optimzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fecaca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    ## Parameters to be evaluated\n",
    "    param = dict(objective = 'regression_l1',\n",
    "                 verbose = -100,\n",
    "                 boosting_type = 'gbdt', \n",
    "                 random_state = 811,\n",
    "                 n_estimators = trial.suggest_int('n_estimators', 300, 10000),\n",
    "                 learning_rate = trial.suggest_float('learning_rate', 0.001, 1, log=True),\n",
    "                 max_depth = trial.suggest_int('max_depth', 3, 12),\n",
    "                 lambda_l1 = trial.suggest_float('lambda_l1', 0.01, 10.0, log=True),\n",
    "                 lambda_l2 = trial.suggest_float('lambda_l2', 0.01, 10.0, log=True),\n",
    "                 num_leaves = trial.suggest_int('num_leaves', 2, 100),\n",
    "                 bagging_fraction = trial.suggest_float('bagging_fraction', 0.2, 0.9),\n",
    "                 feature_fraction = trial.suggest_float('feature_fraction', 0.2, 0.9)\n",
    "                 )\n",
    "\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "#     skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "    skf = KFold(n_splits = 5, shuffle = True, random_state = 811)\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(X, Y)):\n",
    "        \n",
    "        print(fold, end = ' ')\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train , y_valid = Y.iloc[train_idx] , Y.iloc[valid_idx]\n",
    "\n",
    "        model = LGBMRegressor(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds_valid = model.predict(X_valid)\n",
    "        \n",
    "        optR = OptimizedRounder()\n",
    "        optR.fit(preds_valid, y_valid)\n",
    "        coef = optR.coefficients()\n",
    "        preds_valid = optR.predict(preds_valid, coef).astype(int)\n",
    "        \n",
    "        score = cohen_kappa_score(y_valid,  preds_valid, weights = \"quadratic\")\n",
    "        scores.append(score)\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c45d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction = \"maximize\")\n",
    "study.optimize(objective, n_trials = 50, timeout = 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bfbd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770c67a1",
   "metadata": {},
   "source": [
    "# LightGBM Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf3d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_cv_scores, lgb_imp = list(), list()\n",
    "preds = list()\n",
    "\n",
    "skf = KFold(n_splits = 5, shuffle = True, random_state = 811)\n",
    "    \n",
    "for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "    ## Splitting the data \n",
    "    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "    Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "    \n",
    "    ## Building the model\n",
    "    lgb_md = LGBMRegressor(n_estimators = 6725,\n",
    "                            max_depth = 5,\n",
    "                            learning_rate = 0.022628495232843018,\n",
    "                            num_leaves = 20,\n",
    "                            lambda_l1 = 0.08350981191808945,\n",
    "                            lambda_l2 = 1.491720444290465,\n",
    "                            bagging_fraction = 0.34023074860366764,\n",
    "                            feature_fraction = 0.2824957743296221,\n",
    "                            random_state = 811).fit(X_train, Y_train)\n",
    "    lgb_imp.append(lgb_md.feature_importances_)\n",
    "    \n",
    "    ## Predicting on X_test and test\n",
    "    lgb_pred_1 = lgb_md.predict(X_test)\n",
    "    lgb_pred_2 = lgb_md.predict(test_md)\n",
    "        \n",
    "    ## Applying Optimal Rounder (using abhishek approach)\n",
    "    optR = OptimizedRounder()\n",
    "    optR.fit(lgb_pred_1, Y_test)\n",
    "    coef = optR.coefficients()\n",
    "    lgb_pred_1 = optR.predict(lgb_pred_1, coef).astype(int)\n",
    "    lgb_pred_2 = optR.predict(lgb_pred_2, coef).astype(int)\n",
    "        \n",
    "    ## Computing roc-auc score\n",
    "    lgb_cv_scores.append(cohen_kappa_score(Y_test, lgb_pred_1, weights = 'quadratic'))\n",
    "    preds.append(lgb_pred_2)\n",
    "\n",
    "lgb_cv_score = np.mean(lgb_cv_scores)    \n",
    "print('The average weighted kappa score score over 5-folds (run 5 times) is:', lgb_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504eb451",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_preds_test = pd.DataFrame(preds).mode(axis = 0).loc[0, ]\n",
    "\n",
    "submission['quality'] = lgb_preds_test.astype(int)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb01b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('LightGBM_Reg_FE_3.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
