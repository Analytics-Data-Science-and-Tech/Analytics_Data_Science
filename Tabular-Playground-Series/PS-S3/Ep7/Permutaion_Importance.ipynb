{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ad58f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting optuna\n",
      "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (1.4.42)\n",
      "Collecting cmaes>=0.9.1\n",
      "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (1.22.4)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.9.4-py3-none-any.whl (210 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.5/210.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (4.64.1)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3.post0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
      "Successfully installed Mako-1.2.4 alembic-1.9.4 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c89e4710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "import optuna \n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Series/PS-S3/Ep7/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Series/PS-S3/Ep7/test.csv'\n",
    "file_key_3 = 'Tabular-Playground-Series/PS-S3/Ep7/sample_submission.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "bucket_object_3 = bucket.Object(file_key_3)\n",
    "file_object_3 = bucket_object_3.get()\n",
    "file_content_stream_3 = file_object_3.get('Body')\n",
    "\n",
    "## Reading data files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "submission = pd.read_csv(file_content_stream_3)\n",
    "\n",
    "## Fixing dates (https://www.kaggle.com/competitions/playground-series-s3e7/discussion/386655)\n",
    "train['arrival_year_month'] = pd.to_datetime(train['arrival_year'].astype(str) + train['arrival_month'].astype(str), format = '%Y%m')\n",
    "test['arrival_year_month'] = pd.to_datetime(test['arrival_year'].astype(str) + test['arrival_month'].astype(str), format = '%Y%m')\n",
    "\n",
    "train.loc[train.arrival_date > train.arrival_year_month.dt.days_in_month, 'arrival_date'] = train.arrival_year_month.dt.days_in_month\n",
    "test.loc[test.arrival_date > test.arrival_year_month.dt.days_in_month, 'arrival_date'] = test.arrival_year_month.dt.days_in_month\n",
    "\n",
    "train.drop(columns = 'arrival_year_month', inplace = True)\n",
    "test.drop(columns = 'arrival_year_month', inplace = True)\n",
    "\n",
    "train['low_price_flag'] = np.where(train['avg_price_per_room'] < 30, 1, 0)\n",
    "train['segment_0'] = np.where(train['market_segment_type'] == 0, 1, 0)\n",
    "train['segment_1'] = np.where(train['market_segment_type'] == 1, 1, 0)\n",
    "train['total_guests'] = train['no_of_adults'] + train['no_of_children']\n",
    "train['stay_length'] = train['no_of_weekend_nights'] + train['no_of_week_nights']\n",
    "train['stay_during_weekend'] = np.where(train['no_of_weekend_nights'] > 0, 1, 0)\n",
    "train['quarter_1'] = np.where(train['arrival_month'] <= 3, 1, 0)\n",
    "train['quarter_2'] = np.where(((train['arrival_month'] >= 4) & (train['arrival_month'] <= 6)), 1, 0)\n",
    "train['quarter_3'] = np.where(((train['arrival_month'] >= 7) & (train['arrival_month'] <= 9)), 1, 0)\n",
    "train['quarter_4'] = np.where(train['arrival_month'] >= 10, 1, 0)\n",
    "train['segment_0_feature_1'] = np.where(((train['market_segment_type'] == 0) & (train['lead_time'] <= 90)), 1, 0)\n",
    "train['segment_0_feature_2'] = np.where(((train['market_segment_type'] == 0) & (train['avg_price_per_room'] > 98)), 1, 0)\n",
    "train['segment_1_feature_1'] = np.where(((train['market_segment_type'] == 1) & (train['no_of_special_requests'] == 0)), 1, 0)\n",
    "train['segment_1_feature_2'] = np.where(((train['market_segment_type'] == 1) & (train['no_of_special_requests'] > 0) & (train['lead_time'] <= 150)), 1, 0)\n",
    "train['segment_0_year_flag'] = np.where(((train['market_segment_type'] == 0) & (train['arrival_year'] == 2018)), 1, 0)\n",
    "train['segment_1_year_flag'] = np.where(((train['market_segment_type'] == 1) & (train['arrival_year'] == 2018)), 1, 0)\n",
    "train['price_lead_time_flag'] = np.where(((train['avg_price_per_room'] > 100) & (train['lead_time'] > 150)), 1, 0)\n",
    "\n",
    "test['low_price_flag'] = np.where(test['avg_price_per_room'] < 30, 1, 0)\n",
    "test['segment_0'] = np.where(test['market_segment_type'] == 0, 1, 0)\n",
    "test['segment_1'] = np.where(test['market_segment_type'] == 1, 1, 0)\n",
    "test['total_guests'] = test['no_of_adults'] + test['no_of_children']\n",
    "test['stay_length'] = test['no_of_weekend_nights'] + test['no_of_week_nights']\n",
    "test['stay_during_weekend'] = np.where(test['no_of_weekend_nights'] > 0, 1, 0)\n",
    "test['quarter_1'] = np.where(test['arrival_month'] <= 3, 1, 0)\n",
    "test['quarter_2'] = np.where(((test['arrival_month'] >= 4) & (test['arrival_month'] <= 6)), 1, 0)\n",
    "test['quarter_3'] = np.where(((test['arrival_month'] >= 7) & (test['arrival_month'] <= 9)), 1, 0)\n",
    "test['quarter_4'] = np.where(test['arrival_month'] >= 10, 1, 0)\n",
    "test['segment_0_feature_1'] = np.where(((test['market_segment_type'] == 0) & (test['lead_time'] <= 90)), 1, 0)\n",
    "test['segment_0_feature_2'] = np.where(((test['market_segment_type'] == 0) & (test['avg_price_per_room'] > 98)), 1, 0)\n",
    "test['segment_1_feature_1'] = np.where(((test['market_segment_type'] == 1) & (test['no_of_special_requests'] == 0)), 1, 0)\n",
    "test['segment_1_feature_2'] = np.where(((test['market_segment_type'] == 1) & (test['no_of_special_requests'] > 0) & (test['lead_time'] <= 150)), 1, 0)\n",
    "test['segment_0_year_flag'] = np.where(((test['market_segment_type'] == 0) & (test['arrival_year'] == 2018)), 1, 0)\n",
    "test['segment_1_year_flag'] = np.where(((test['market_segment_type'] == 1) & (test['arrival_year'] == 2018)), 1, 0)\n",
    "test['price_lead_time_flag'] = np.where(((test['avg_price_per_room'] > 100) & (test['lead_time'] > 150)), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50302eb",
   "metadata": {},
   "source": [
    "# Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b22e3a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dup = train.copy()\n",
    "test_dup = test.copy()\n",
    "\n",
    "duplicates = pd.merge(train, test, on = train_dup.columns.tolist()[1:18])\n",
    "train_dup_ids = duplicates['id_x'].tolist()\n",
    "test_dup_ids = duplicates['id_y'].tolist()\n",
    "\n",
    "train_clean = train[~np.isin(train['id'], train_dup_ids)].reset_index(drop = True)\n",
    "train_dup = train[np.isin(train['id'], train_dup_ids)].reset_index(drop = True)\n",
    "\n",
    "test_clean = test[~np.isin(test['id'], test_dup_ids)].reset_index(drop = True)\n",
    "test_dup = test[np.isin(test['id'], test_dup_ids)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d292f95d",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3249101",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_clean.drop(columns = ['id', 'low_price_flag', 'no_of_adults', 'no_of_children', 'no_of_weekend_nights', 'no_of_week_nights', 'booking_status'], axis = 1)\n",
    "Y = train_clean['booking_status']\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "\n",
    "hist_md = HistGradientBoostingClassifier().fit(X_train, Y_train)\n",
    "\n",
    "result = permutation_importance(hist_md, X_val, Y_val, n_repeats = 50, scoring = 'roc_auc', random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5c9be69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lead_time',\n",
       " 'segment_1_feature_1',\n",
       " 'avg_price_per_room',\n",
       " 'no_of_special_requests',\n",
       " 'arrival_month',\n",
       " 'price_lead_time_flag',\n",
       " 'required_car_parking_space',\n",
       " 'repeated_guest',\n",
       " 'room_type_reserved',\n",
       " 'total_guests',\n",
       " 'arrival_year',\n",
       " 'segment_1',\n",
       " 'stay_length',\n",
       " 'market_segment_type',\n",
       " 'segment_0_feature_1',\n",
       " 'stay_during_weekend']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.DataFrame({'Feature': X.columns , 'Imp': result.importances_mean})\n",
    "feature_imp.sort_values(by = 'Imp', ascending = False, inplace = True)\n",
    "feature_imp.reset_index(drop = True, inplace = True)\n",
    "feature_to_select = feature_imp['Feature'][0:16]\n",
    "feature_to_select.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f19dcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type_of_meal_plan', 'required_car_parking_space', 'room_type_reserved',\n",
       "       'lead_time', 'arrival_year', 'arrival_month', 'arrival_date',\n",
       "       'market_segment_type', 'repeated_guest', 'no_of_previous_cancellations',\n",
       "       'no_of_previous_bookings_not_canceled', 'avg_price_per_room',\n",
       "       'no_of_special_requests', 'segment_0', 'segment_1', 'total_guests',\n",
       "       'stay_length', 'stay_during_weekend', 'quarter_1', 'quarter_2',\n",
       "       'quarter_3', 'quarter_4', 'segment_0_feature_1', 'segment_0_feature_2',\n",
       "       'segment_1_feature_1', 'segment_1_feature_2', 'segment_0_year_flag',\n",
       "       'segment_1_year_flag', 'price_lead_time_flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
