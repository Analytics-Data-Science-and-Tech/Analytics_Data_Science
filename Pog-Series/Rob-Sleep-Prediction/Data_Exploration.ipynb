{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9832faef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.4-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lightgbm\n",
      "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting catboost\n",
      "  Downloading catboost-1.1.1-cp310-none-manylinux1_x86_64.whl (76.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting holidays\n",
      "  Downloading holidays-0.21.13-py3-none-any.whl (378 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.2/378.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting optuna\n",
      "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.22.3)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lightgbm) (0.38.4)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lightgbm) (1.2.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (1.5.2)\n",
      "Requirement already satisfied: plotly in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (5.11.0)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (3.6.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Collecting PyMeeus\n",
      "  Downloading PyMeeus-0.5.12.tar.gz (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting convertdate>=2.3.0\n",
      "  Downloading convertdate-2.4.0-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from holidays) (2.8.2)\n",
      "Collecting korean-lunar-calendar\n",
      "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
      "Collecting hijri-converter\n",
      "  Downloading hijri_converter-2.2.4-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (1.4.46)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (4.64.1)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cmaes>=0.9.1\n",
      "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (5.4.1)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=0.24.0->catboost) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (1.0.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (4.38.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from plotly->catboost) (8.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Building wheels for collected packages: PyMeeus\n",
      "  Building wheel for PyMeeus (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyMeeus: filename=PyMeeus-0.5.12-py3-none-any.whl size=731999 sha256=5c30d8317ef8418e95e4411fe10a88efe0094ac6c72b56f771fcefdb043cfdf2\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/74/47/c4/678b0a3d5213e2f8500f3ea0f8dc3c81478e5b806c557dff58\n",
      "Successfully built PyMeeus\n",
      "Installing collected packages: PyMeeus, korean-lunar-calendar, Mako, hijri-converter, graphviz, convertdate, colorlog, cmaes, xgboost, holidays, alembic, optuna, lightgbm, catboost\n",
      "Successfully installed Mako-1.2.4 PyMeeus-0.5.12 alembic-1.10.2 catboost-1.1.1 cmaes-0.9.1 colorlog-6.7.0 convertdate-2.4.0 graphviz-0.20.1 hijri-converter-2.2.4 holidays-0.21.13 korean-lunar-calendar-0.3.1 lightgbm-3.3.5 optuna-3.1.0 xgboost-1.7.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost lightgbm catboost holidays optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3381eac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import holidays\n",
    "\n",
    "from functools import partial\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, StratifiedKFold, TimeSeriesSplit, GroupKFold\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, HistGradientBoostingClassifier, HistGradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor \n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "import optuna \n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Series/Pog-Series/Rob-Sleep-Prediction/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Series/Pog-Series/Rob-Sleep-Prediction/test.csv'\n",
    "file_key_3 = 'Tabular-Playground-Series/Pog-Series/Rob-Sleep-Prediction/sample_submission.csv'\n",
    "# file_key_4 = 'Tabular-Playground-Series/PS-S3/Ep10/Pulsar.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "bucket_object_3 = bucket.Object(file_key_3)\n",
    "file_object_3 = bucket_object_3.get()\n",
    "file_content_stream_3 = file_object_3.get('Body')\n",
    "\n",
    "# bucket_object_4 = bucket.Object(file_key_4)\n",
    "# file_object_4 = bucket_object_4.get()\n",
    "# file_content_stream_4 = file_object_4.get('Body')\n",
    "\n",
    "## Reading data files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "\n",
    "# train.drop(columns = 'id', axis = 1, inplace = True)\n",
    "# train['is_generated'] = 1\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "\n",
    "# test['is_generated'] = 1\n",
    "\n",
    "submission = pd.read_csv(file_content_stream_3)\n",
    "# original = pd.read_csv(file_content_stream_4)\n",
    "# original['is_generated'] = 0\n",
    "\n",
    "# train = pd.concat([train, original], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403a035f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sleep_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-19</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-20</td>\n",
       "      <td>7.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-21</td>\n",
       "      <td>6.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-22</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>8.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  sleep_hours\n",
       "0 2015-02-19     6.400000\n",
       "1 2015-02-20     7.583333\n",
       "2 2015-02-21     6.350000\n",
       "3 2015-02-22     6.500000\n",
       "4 2015-02-23     8.916667"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc773dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holidays(df):\n",
    "    years_list = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "    holiday_US = holidays.CountryHoliday('US', years = years_list)\n",
    "    holiday_dict = holiday_US.copy()\n",
    "\n",
    "    df['holiday_name'] = df['date'].map(holiday_dict)\n",
    "    df['is_holiday'] = np.where(df['holiday_name'].notnull(), 1, 0)\n",
    "    df['holiday_name'] = df['holiday_name'].fillna('Not Holiday')\n",
    "    \n",
    "    return df.drop(columns = ['holiday_name'])\n",
    "\n",
    "\n",
    "def feature_engineer(df):\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    new_df[\"month\"] = df[\"date\"].dt.month\n",
    "    new_df[\"month_sin\"] = np.sin(new_df['month'] * (2 * np.pi / 12))\n",
    "#     new_df[\"month_cos\"] = np.cos(new_df['month'] * (2 * np.pi / 12))\n",
    "    \n",
    "    new_df[\"day\"] = df[\"date\"].dt.day\n",
    "    new_df[\"day_sin\"] = np.sin(new_df['day'] * (2 * np.pi / 12))\n",
    "#     new_df[\"day_cos\"] = np.cos(new_df['day'] * (2 * np.pi / 12))\n",
    "    \n",
    "    new_df[\"day_of_week\"] = df[\"date\"].dt.dayofweek\n",
    "    new_df[\"day_of_week\"] = new_df[\"day_of_week\"].apply(lambda x: 0 if x <= 3 else(1 if x == 4 else (2 if x == 5 else (3))))\n",
    "    \n",
    "    new_df[\"day_of_year\"] = df[\"date\"].dt.dayofyear\n",
    "    new_df[\"year\"] = df[\"date\"].dt.year\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "train = feature_engineer(train)\n",
    "test = feature_engineer(test)\n",
    "\n",
    "train = get_holidays(train)\n",
    "test = get_holidays(test)\n",
    "\n",
    "train.loc[((train['date'] >= '2017-09-27') & (train['date'] <= '2018-06-12')), 'sleep_hours'] = train.loc[((train['date'] >= '2017-09-27') & (train['date'] <= '2018-06-12')), 'sleep_hours'] / 1.94 \n",
    "\n",
    "X = train.drop(columns = ['date', 'sleep_hours', 'year'], axis = 1)\n",
    "Y = train['sleep_hours']\n",
    "\n",
    "test = test.drop(columns = ['date', 'sleep_hours', 'year'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "751d12a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>day</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>year</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>21</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  month_sin  day   day_sin  day_of_week  day_of_year  year  is_holiday\n",
       "0      2   0.866025   19 -0.500000            0           50  2015           0\n",
       "1      2   0.866025   20 -0.866025            1           51  2015           0\n",
       "2      2   0.866025   21 -1.000000            2           52  2015           0\n",
       "3      2   0.866025   22 -0.866025            3           53  2015           0\n",
       "4      2   0.866025   23 -0.500000            0           54  2015           0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3ad1ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.403e+02, tolerance: 1.928e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.467e+02, tolerance: 1.940e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.507e+02, tolerance: 1.951e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.439e+02, tolerance: 1.932e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.422e+02, tolerance: 1.932e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.461e+02, tolerance: 1.935e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.497e+02, tolerance: 1.947e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.343e+02, tolerance: 1.911e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.383e+02, tolerance: 1.921e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.287e+02, tolerance: 1.901e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.445e+02, tolerance: 1.934e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.517e+02, tolerance: 1.948e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.347e+02, tolerance: 1.911e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.149e+02, tolerance: 1.873e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.376e+02, tolerance: 1.920e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.508e+02, tolerance: 1.950e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.335e+02, tolerance: 1.910e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.382e+02, tolerance: 1.921e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.139e+02, tolerance: 1.878e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.420e+02, tolerance: 1.933e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.340e+02, tolerance: 1.912e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.420e+02, tolerance: 1.930e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.514e+02, tolerance: 1.948e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.456e+02, tolerance: 1.936e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.236e+02, tolerance: 1.894e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.372e+02, tolerance: 1.920e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.456e+02, tolerance: 1.939e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.467e+02, tolerance: 1.943e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.445e+02, tolerance: 1.935e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.401e+02, tolerance: 1.927e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "linear_preds = np.zeros(test.shape[0])\n",
    "linear_rmse = 0\n",
    "\n",
    "ridge_preds = np.zeros(test.shape[0])\n",
    "ridge_rmse = 0\n",
    "\n",
    "lasso_preds = np.zeros(test.shape[0])\n",
    "lasso_rmse = 0\n",
    "\n",
    "elastic_preds = np.zeros(test.shape[0])\n",
    "elastic_rmse = 0\n",
    "\n",
    "kf = KFold(n_splits = 30, shuffle = True, random_state = 42)\n",
    "# kf = GroupKFold(n_splits = 5)\n",
    "\n",
    "for trn_idx, test_idx in kf.split(X, Y):\n",
    "# for trn_idx, test_idx in kf.split(X, groups = X.year):\n",
    "    \n",
    "    x_train, x_valid = X.iloc[trn_idx], X.iloc[test_idx]\n",
    "    y_train, y_valid = Y.iloc[trn_idx], Y.iloc[test_idx]\n",
    "    \n",
    "    ##################\n",
    "    ## Linear model ##\n",
    "    ##################\n",
    "    \n",
    "    linear_model = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "    y_pred = linear_model.predict(x_valid)\n",
    "    linear_rmse += mean_squared_error(y_pred, y_valid, squared = False) / kf.n_splits\n",
    "    \n",
    "    linear_pred = linear_model.predict(test)\n",
    "    linear_pred = pd.Series(linear_pred) \n",
    "    linear_preds += linear_pred / kf.n_splits\n",
    "    \n",
    "    ###########\n",
    "    ## Ridge ##\n",
    "    ###########\n",
    "    \n",
    "    ridge_model = Ridge(alpha = 0.0999, tol = 1e-2, max_iter = 1000000, random_state = 0).fit(x_train, y_train)\n",
    "\n",
    "    y_pred = ridge_model.predict(x_valid)\n",
    "    ridge_rmse += mean_squared_error(y_pred, y_valid, squared = False) / kf.n_splits\n",
    "    \n",
    "    ridge_pred = ridge_model.predict(test)\n",
    "    ridge_pred = pd.Series(ridge_pred) \n",
    "    ridge_preds += ridge_pred / kf.n_splits\n",
    "    \n",
    "    ###########\n",
    "    ## Lasso ##\n",
    "    ###########\n",
    "    \n",
    "    lasso_model = Lasso(alpha = 0.0999, tol = 1e-2, max_iter = 1000000, random_state = 0).fit(x_train, y_train)\n",
    "\n",
    "    y_pred = lasso_model.predict(x_valid)\n",
    "    lasso_rmse += mean_squared_error(y_pred, y_valid, squared = False) / kf.n_splits\n",
    "    \n",
    "    lasso_pred = lasso_model.predict(test)\n",
    "    lasso_pred = pd.Series(lasso_pred) \n",
    "    lasso_preds += lasso_pred / kf.n_splits\n",
    "    \n",
    "    #############\n",
    "    ## Elastic ##\n",
    "    #############\n",
    "    \n",
    "    elastic_model = ElasticNet(alpha = 0.0002, l1_ratio = 0.001, random_state = 42).fit(x_train, y_train)\n",
    "\n",
    "    y_pred = elastic_model.predict(x_valid)\n",
    "    elastic_rmse += mean_squared_error(y_pred, y_valid, squared = False) / kf.n_splits\n",
    "    \n",
    "    elastic_pred = elastic_model.predict(test)\n",
    "    elastic_pred = pd.Series(elastic_pred) \n",
    "    elastic_preds += elastic_pred / kf.n_splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "187fcb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>0.907870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.907847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.911310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elastic</td>\n",
       "      <td>0.907846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  CV-Score\n",
       "0   Linear  0.907870\n",
       "1    Ridge  0.907847\n",
       "2    Lasso  0.911310\n",
       "3  Elastic  0.907846"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_perf = pd.DataFrame({'Model': ['Linear', 'Ridge', 'Lasso', 'Elastic'], \n",
    "                        'CV-Score': [linear_rmse, ridge_rmse, lasso_rmse, elastic_rmse]})\n",
    "md_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39270741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>0.902437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.902408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.905345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elastic</td>\n",
       "      <td>0.902320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  CV-Score\n",
       "0   Linear  0.902437\n",
       "1    Ridge  0.902408\n",
       "2    Lasso  0.905345\n",
       "3  Elastic  0.902320"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_perf = pd.DataFrame({'Model': ['Linear', 'Ridge', 'Lasso', 'Elastic'], \n",
    "                        'CV-Score': [linear_rmse, ridge_rmse, lasso_rmse, elastic_rmse]})\n",
    "md_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d3d80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>0.902998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.902969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.905833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elastic</td>\n",
       "      <td>0.902971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  CV-Score\n",
       "0   Linear  0.902998\n",
       "1    Ridge  0.902969\n",
       "2    Lasso  0.905833\n",
       "3  Elastic  0.902971"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_perf = pd.DataFrame({'Model': ['Linear', 'Ridge', 'Lasso', 'Elastic'], \n",
    "                        'CV-Score': [linear_rmse, ridge_rmse, lasso_rmse, elastic_rmse]})\n",
    "md_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20940dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sleep_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>6.896605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>6.905294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>6.603509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>6.604246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>6.606458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sleep_hours\n",
       "0  2022-01-01     6.896605\n",
       "1  2022-01-02     6.905294\n",
       "2  2022-01-03     6.603509\n",
       "3  2022-01-04     6.604246\n",
       "4  2022-01-05     6.606458"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 1/ linear_rmse  \n",
    "w2 = 1/ ridge_rmse\n",
    "w3 = 1/ lasso_rmse\n",
    "w4 = 1/ elastic_rmse\n",
    "wtot = w1 + w2 + w3 + w4\n",
    "\n",
    "w1 = w1 / wtot\n",
    "w2 = w2 / wtot\n",
    "w3 = w3 / wtot\n",
    "w4 = w4 / wtot\n",
    "\n",
    "submission['sleep_hours'] = linear_preds * w1 + ridge_preds * w2 + lasso_preds * w3  + elastic_preds * w4\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da67e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('baseline_submission_4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b80ec0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sleep_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>6.955219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>6.958634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>6.596936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>6.598015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>6.601075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sleep_hours\n",
       "0  2022-01-01     6.955219\n",
       "1  2022-01-02     6.958634\n",
       "2  2022-01-03     6.596936\n",
       "3  2022-01-04     6.598015\n",
       "4  2022-01-05     6.601075"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['sleep_hours'] =  elastic_preds \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6faa8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('baseline_submission_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08b2405a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sleep_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>6.955125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>6.958714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>6.596975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>6.598063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>6.601143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sleep_hours\n",
       "0  2022-01-01     6.955125\n",
       "1  2022-01-02     6.958714\n",
       "2  2022-01-03     6.596975\n",
       "3  2022-01-04     6.598063\n",
       "4  2022-01-05     6.601143"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['sleep_hours'] =  elastic_preds \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0988871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('baseline_submission_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8467d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:14<00:00, 14.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The oof mean-squared-log-error of the XGBoost model is  0.8999885829047847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_cv_scores, xgb_preds = list(), list()\n",
    "\n",
    "for i in tqdm(range(1)):\n",
    "\n",
    "    skf = KFold(n_splits = 30, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############\n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "        xgb_md = XGBRegressor(tree_method = 'hist',\n",
    "                              colsample_bytree = 0.4, \n",
    "                              gamma = 1.25, \n",
    "                              learning_rate = 0.01, \n",
    "                              max_depth = 2, \n",
    "                              min_child_weight = 80, \n",
    "                              n_estimators = 2000, \n",
    "                              subsample = 1).fit(X_train, Y_train)\n",
    "        \n",
    "        ## Predicting on X_test and test        \n",
    "        xgb_pred_1 = xgb_md.predict(X_test)\n",
    "        xgb_pred_2 = xgb_md.predict(test)\n",
    "        \n",
    "        ## Computing rmse and storing test predictions\n",
    "        xgb_cv_scores.append(mean_squared_error(Y_test, xgb_pred_1, squared = False))\n",
    "        xgb_preds.append(xgb_pred_2)\n",
    "        \n",
    "xgb_cv_score = np.mean(xgb_cv_scores)\n",
    "print('The oof mean-squared-log-error of the XGBoost model is ', xgb_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8994529678578282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04f0fda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "The oof mean-squared-log-error of the XGBoost model is  0.9004400901291761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_cv_scores, lgb_preds = list(), list()\n",
    "\n",
    "for i in tqdm(range(1)):\n",
    "\n",
    "    skf = KFold(n_splits = 30, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############\n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "        lgb_md = LGBMRegressor(n_estimators = 2000,\n",
    "                               max_depth = 2,\n",
    "                               learning_rate = 0.01,\n",
    "                               num_leaves = 50,\n",
    "                               lambda_l1 = 20,\n",
    "                               lambda_l2 = 25,\n",
    "                               bagging_fraction = 0.8,\n",
    "                               feature_fraction = 0.8).fit(X_train, Y_train)\n",
    "        \n",
    "        ## Predicting on X_test and test        \n",
    "        lgb_pred_1 = lgb_md.predict(X_test)\n",
    "        lgb_pred_2 = lgb_md.predict(test)\n",
    "        \n",
    "        ## Computing rmse and storing test predictions\n",
    "        lgb_cv_scores.append(mean_squared_error(Y_test, lgb_pred_1, squared = False))\n",
    "        lgb_preds.append(lgb_pred_2)\n",
    "        \n",
    "lgb_cv_score = np.mean(lgb_cv_scores)\n",
    "print('The oof mean-squared-log-error of the XGBoost model is ', lgb_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8991208416290151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af7f39d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sleep_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>6.841592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>6.772600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>6.576557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>6.576552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>6.543252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sleep_hours\n",
       "0  2022-01-01     6.841592\n",
       "1  2022-01-02     6.772600\n",
       "2  2022-01-03     6.576557\n",
       "3  2022-01-04     6.576552\n",
       "4  2022-01-05     6.543252"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_preds = pd.DataFrame(lgb_preds).mean(axis = 0)\n",
    "submission['sleep_hours'] =  lgb_preds\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8240f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lgb_baseline_submission_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7979d",
   "metadata": {},
   "source": [
    "# Changes based on public notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37cf3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import holidays\n",
    "\n",
    "from functools import partial\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, StratifiedKFold, TimeSeriesSplit, GroupKFold\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, HistGradientBoostingClassifier, HistGradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor \n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "import optuna \n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Series/Pog-Series/Rob-Sleep-Prediction/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Series/Pog-Series/Rob-Sleep-Prediction/test.csv'\n",
    "file_key_3 = 'Tabular-Playground-Series/Pog-Series/Rob-Sleep-Prediction/sample_submission.csv'\n",
    "# file_key_4 = 'Tabular-Playground-Series/PS-S3/Ep10/Pulsar.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "bucket_object_3 = bucket.Object(file_key_3)\n",
    "file_object_3 = bucket_object_3.get()\n",
    "file_content_stream_3 = file_object_3.get('Body')\n",
    "\n",
    "## Reading data files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "\n",
    "submission = pd.read_csv(file_content_stream_3)\n",
    "\n",
    "def get_holidays(df):\n",
    "    years_list = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "    holiday_US = holidays.CountryHoliday('US', years = years_list)\n",
    "    holiday_dict = holiday_US.copy()\n",
    "\n",
    "    df['holiday_name'] = df['date'].map(holiday_dict)\n",
    "    df['is_holiday'] = np.where(df['holiday_name'].notnull(), 1, 0)\n",
    "    df['holiday_name'] = df['holiday_name'].fillna('Not Holiday')\n",
    "    \n",
    "    return df.drop(columns = ['holiday_name'])\n",
    "\n",
    "\n",
    "def feature_engineer(df):\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    new_df[\"month\"] = df[\"date\"].dt.month\n",
    "    new_df[\"month_sin\"] = np.sin(new_df['month'] * (2 * np.pi / 12))\n",
    "#     new_df[\"month_cos\"] = np.cos(new_df['month'] * (2 * np.pi / 12))\n",
    "    \n",
    "    new_df[\"day\"] = df[\"date\"].dt.day\n",
    "    new_df[\"day_sin\"] = np.sin(new_df['day'] * (2 * np.pi / 12))\n",
    "#     new_df[\"day_cos\"] = np.cos(new_df['day'] * (2 * np.pi / 12))\n",
    "    \n",
    "    new_df[\"day_of_week\"] = df[\"date\"].dt.dayofweek\n",
    "    new_df[\"day_of_week\"] = new_df[\"day_of_week\"].apply(lambda x: 0 if x <= 3 else(1 if x == 4 else (2 if x == 5 else (3))))\n",
    "    \n",
    "    new_df[\"day_of_year\"] = df[\"date\"].dt.dayofyear\n",
    "    new_df[\"year\"] = df[\"date\"].dt.year\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "train = feature_engineer(train)\n",
    "test = feature_engineer(test)\n",
    "\n",
    "train = get_holidays(train)\n",
    "test = get_holidays(test)\n",
    "\n",
    "train.loc[((train['date'] >= '2017-09-27') & (train['date'] <= '2018-06-12')), 'sleep_hours'] = train.loc[((train['date'] >= '2017-09-27') & (train['date'] <= '2018-06-12')), 'sleep_hours'] / 1.94 \n",
    "\n",
    "X = train.drop(columns = ['date', 'sleep_hours', 'year'], axis = 1)\n",
    "Y = train['sleep_hours']\n",
    "\n",
    "test = test.drop(columns = ['date', 'sleep_hours', 'year'], axis = 1)\n",
    "\n",
    "train = train[train['date'] > '2015-07-20'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6478ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sleep_hours</th>\n",
       "      <th>month</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>day</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>year</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-21</td>\n",
       "      <td>7.850000</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>21</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-22</td>\n",
       "      <td>5.916667</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>22</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-23</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>23</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-24</td>\n",
       "      <td>6.450000</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>24</td>\n",
       "      <td>-4.898587e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-25</td>\n",
       "      <td>7.783333</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>25</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>206</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  sleep_hours  month  month_sin  day       day_sin  day_of_week  \\\n",
       "0 2015-07-21     7.850000      7       -0.5   21 -1.000000e+00            0   \n",
       "1 2015-07-22     5.916667      7       -0.5   22 -8.660254e-01            0   \n",
       "2 2015-07-23     6.916667      7       -0.5   23 -5.000000e-01            0   \n",
       "3 2015-07-24     6.450000      7       -0.5   24 -4.898587e-16            1   \n",
       "4 2015-07-25     7.783333      7       -0.5   25  5.000000e-01            2   \n",
       "\n",
       "   day_of_year  year  is_holiday  \n",
       "0          202  2015           0  \n",
       "1          203  2015           0  \n",
       "2          204  2015           0  \n",
       "3          205  2015           0  \n",
       "4          206  2015           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc04708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.403e+02, tolerance: 1.928e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.467e+02, tolerance: 1.940e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.507e+02, tolerance: 1.951e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.439e+02, tolerance: 1.932e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.422e+02, tolerance: 1.932e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.461e+02, tolerance: 1.935e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.497e+02, tolerance: 1.947e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.343e+02, tolerance: 1.911e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.383e+02, tolerance: 1.921e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.287e+02, tolerance: 1.901e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.445e+02, tolerance: 1.934e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.517e+02, tolerance: 1.948e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.347e+02, tolerance: 1.911e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.149e+02, tolerance: 1.873e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.376e+02, tolerance: 1.920e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.508e+02, tolerance: 1.950e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.335e+02, tolerance: 1.910e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.382e+02, tolerance: 1.921e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.139e+02, tolerance: 1.878e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.420e+02, tolerance: 1.933e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.340e+02, tolerance: 1.912e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.420e+02, tolerance: 1.930e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.514e+02, tolerance: 1.948e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.456e+02, tolerance: 1.936e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.236e+02, tolerance: 1.894e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.372e+02, tolerance: 1.920e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.456e+02, tolerance: 1.939e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.467e+02, tolerance: 1.943e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.445e+02, tolerance: 1.935e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.401e+02, tolerance: 1.927e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "linear_preds = np.zeros(test.shape[0])\n",
    "linear_rmse = 0\n",
    "\n",
    "ridge_preds = np.zeros(test.shape[0])\n",
    "ridge_rmse = 0\n",
    "\n",
    "lasso_preds = np.zeros(test.shape[0])\n",
    "lasso_rmse = 0\n",
    "\n",
    "elastic_preds = np.zeros(test.shape[0])\n",
    "elastic_rmse = 0\n",
    "\n",
    "kf = KFold(n_splits = 30, shuffle = True, random_state = 42)\n",
    "# kf = GroupKFold(n_splits = 5)\n",
    "\n",
    "for trn_idx, test_idx in kf.split(X, Y):\n",
    "# for trn_idx, test_idx in kf.split(X, groups = X.year):\n",
    "    \n",
    "    x_train, x_valid = X.iloc[trn_idx], X.iloc[test_idx]\n",
    "    y_train, y_valid = Y.iloc[trn_idx], Y.iloc[test_idx]\n",
    "    \n",
    "    ##################\n",
    "    ## Linear model ##\n",
    "    ##################\n",
    "    \n",
    "    linear_model = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "    y_pred = linear_model.predict(x_valid)\n",
    "    linear_rmse += mean_squared_error(y_pred, y_valid, squared = False) / kf.n_splits\n",
    "    \n",
    "    linear_pred = linear_model.predict(test)\n",
    "    linear_pred = pd.Series(linear_pred) \n",
    "    linear_preds += linear_pred / kf.n_splits\n",
    "    \n",
    "    ###########\n",
    "    ## Ridge ##\n",
    "    ###########\n",
    "    \n",
    "    ridge_model = Ridge(alpha = 0.0999, tol = 1e-2, max_iter = 1000000, random_state = 0).fit(x_train, y_train)\n",
    "\n",
    "    y_pred = ridge_model.predict(x_valid)\n",
    "    ridge_rmse += mean_squared_error(y_pred, y_valid, squared = False) / kf.n_splits\n",
    "    \n",
    "    ridge_pred = ridge_model.predict(test)\n",
    "    ridge_pred = pd.Series(ridge_pred) \n",
    "    ridge_preds += ridge_pred / kf.n_splits\n",
    "    \n",
    "    ###########\n",
    "    ## Lasso ##\n",
    "    ###########\n",
    "    \n",
    "    lasso_model = Lasso(alpha = 0.0999, tol = 1e-2, max_iter = 1000000, random_state = 0).fit(x_train, y_train)\n",
    "\n",
    "    y_pred = lasso_model.predict(x_valid)\n",
    "    lasso_rmse += mean_squared_error(y_pred, y_valid, squared = False) / kf.n_splits\n",
    "    \n",
    "    lasso_pred = lasso_model.predict(test)\n",
    "    lasso_pred = pd.Series(lasso_pred) \n",
    "    lasso_preds += lasso_pred / kf.n_splits\n",
    "    \n",
    "    #############\n",
    "    ## Elastic ##\n",
    "    #############\n",
    "    \n",
    "    elastic_model = ElasticNet(alpha = 0.0002, l1_ratio = 0.001, random_state = 42).fit(x_train, y_train)\n",
    "\n",
    "    y_pred = elastic_model.predict(x_valid)\n",
    "    elastic_rmse += mean_squared_error(y_pred, y_valid, squared = False) / kf.n_splits\n",
    "    \n",
    "    elastic_pred = elastic_model.predict(test)\n",
    "    elastic_pred = pd.Series(elastic_pred) \n",
    "    elastic_preds += elastic_pred / kf.n_splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b507f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>0.902998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.902969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.905833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elastic</td>\n",
       "      <td>0.902971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  CV-Score\n",
       "0   Linear  0.902998\n",
       "1    Ridge  0.902969\n",
       "2    Lasso  0.905833\n",
       "3  Elastic  0.902971"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_perf = pd.DataFrame({'Model': ['Linear', 'Ridge', 'Lasso', 'Elastic'], \n",
    "                        'CV-Score': [linear_rmse, ridge_rmse, lasso_rmse, elastic_rmse]})\n",
    "md_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "552f525b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The oof mean-squared-log-error of the XGBoost model is  0.8999885829047847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_cv_scores, xgb_preds = list(), list()\n",
    "\n",
    "for i in tqdm(range(1)):\n",
    "\n",
    "    skf = KFold(n_splits = 30, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############\n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "        xgb_md = XGBRegressor(tree_method = 'hist',\n",
    "                              colsample_bytree = 0.4, \n",
    "                              gamma = 1.25, \n",
    "                              learning_rate = 0.01, \n",
    "                              max_depth = 2, \n",
    "                              min_child_weight = 80, \n",
    "                              n_estimators = 2000, \n",
    "                              subsample = 1).fit(X_train, Y_train)\n",
    "        \n",
    "        ## Predicting on X_test and test        \n",
    "        xgb_pred_1 = xgb_md.predict(X_test)\n",
    "        xgb_pred_2 = xgb_md.predict(test)\n",
    "        \n",
    "        ## Computing rmse and storing test predictions\n",
    "        xgb_cv_scores.append(mean_squared_error(Y_test, xgb_pred_1, squared = False))\n",
    "        xgb_preds.append(xgb_pred_2)\n",
    "        \n",
    "xgb_cv_score = np.mean(xgb_cv_scores)\n",
    "print('The oof mean-squared-log-error of the XGBoost model is ', xgb_cv_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
