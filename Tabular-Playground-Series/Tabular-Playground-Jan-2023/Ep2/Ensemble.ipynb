{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62ec65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.3-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lightgbm\n",
      "  Downloading lightgbm-3.3.4-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.22.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.9.3)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lightgbm) (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Installing collected packages: xgboost, lightgbm\n",
      "Successfully installed lightgbm-3.3.4 xgboost-1.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f58104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Series/Tabular-Playground-Jan-2023-2/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Series/Tabular-Playground-Jan-2023-2/test.csv'\n",
    "file_key_3 = 'Tabular-Playground-Series/Tabular-Playground-Jan-2023-2/sample_submission.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "bucket_object_3 = bucket.Object(file_key_3)\n",
    "file_object_3 = bucket_object_3.get()\n",
    "file_content_stream_3 = file_object_3.get('Body')\n",
    "\n",
    "## Reading data files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "submission = pd.read_csv(file_content_stream_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49798a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def rank_test(train_preds, test_preds):\n",
    "    # rank train preds\n",
    "    train_rank = rankdata(train_preds)\n",
    "    preds_rank_zip = list(zip(train_preds, train_rank))\n",
    "\n",
    "    # sort zipped list by first key\n",
    "    preds_rank_zip.sort(key = lambda x: x[0])\n",
    "\n",
    "    # unzip the sorted zipped list\n",
    "    train_preds, train_rank = zip(*preds_rank_zip)\n",
    "\n",
    "    # use the closest prediction to get the closets rank\n",
    "    return np.array([\n",
    "        train_rank[\n",
    "            bisect_left(train_preds, x)\n",
    "        ] for x in test_preds\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fc212c",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc8c0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc-auc score over 5-folds (run 5 times) is: 0.8834240968293544\n"
     ]
    }
   ],
   "source": [
    "train_logit = train.copy()\n",
    "test_logit = test.copy()\n",
    "\n",
    "## Defining scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "## Defining inputs and target\n",
    "train_dummies = pd.get_dummies(train_logit[['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']])\n",
    "train_dummies = train_dummies.drop(columns = ['gender_Other', 'ever_married_No', 'work_type_children', 'Residence_type_Urban', 'smoking_status_Unknown'])\n",
    "\n",
    "X = train_logit.drop(columns = ['id', 'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'stroke'], axis = 1)\n",
    "X = pd.concat([X, train_dummies], axis = 1)\n",
    "Y = train_logit['stroke']\n",
    "\n",
    "test_dummies = pd.get_dummies(test_logit[['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']])\n",
    "test_dummies = test_dummies.drop(columns = ['gender_Other', 'ever_married_No', 'work_type_children', 'Residence_type_Urban', 'smoking_status_Unknown'])\n",
    "\n",
    "test_logit = test_logit.drop(columns = ['id', 'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'], axis = 1)\n",
    "test_logit = pd.concat([test_logit, test_dummies], axis = 1)\n",
    "test_logit = pd.DataFrame(scaler.fit_transform(test_logit), columns = test_logit.columns)\n",
    "\n",
    "cv_scores, roc_auc_scores = list(), list()\n",
    "preds = list()\n",
    "\n",
    "## Running 5 times CV\n",
    "for i in range(5):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "        \n",
    "        ## Scaling the data\n",
    "        X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n",
    "        X_test = pd.DataFrame(scaler.fit_transform(X_test), columns = X.columns)\n",
    "        \n",
    "        ## Building logistic model\n",
    "        logit_md = LogisticRegression(C = 0.2, penalty = 'l1', solver = 'saga', max_iter = 1000).fit(X_train, Y_train)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        logit_pred_1 = logit_md.predict_proba(X_test)[:, 1]\n",
    "        logit_pred_2 = logit_md.predict_proba(test_logit)[:, 1]\n",
    "        \n",
    "        ## Computing roc-auc score\n",
    "        roc_auc_scores.append(roc_auc_score(Y_test, logit_pred_1))\n",
    "        preds.append(logit_pred_2)\n",
    "        \n",
    "    cv_scores.append(np.mean(roc_auc_scores))\n",
    "\n",
    "logit_cv_score = np.mean(cv_scores)    \n",
    "print('The roc-auc score over 5-folds (run 5 times) is:', logit_cv_score)\n",
    "\n",
    "## Building model in the entire train dataset\n",
    "logit_md = LogisticRegression(C = 0.2, penalty = 'l1', solver = 'saga', max_iter = 10000).fit(X, Y)\n",
    "\n",
    "logit_preds_train = logit_md.predict_proba(X)[:, 1]\n",
    "logit_preds = pd.DataFrame(preds).apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aead936a",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53547bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc-auc score over 5-folds (run 5 times) is: 0.69579513665679\n"
     ]
    }
   ],
   "source": [
    "cv_scores, roc_auc_scores = list(), list()\n",
    "preds = list()\n",
    "\n",
    "## Running 5 times CV\n",
    "for i in range(5):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "        \n",
    "        ## Scaling the data\n",
    "        X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n",
    "        X_test = pd.DataFrame(scaler.fit_transform(X_test), columns = X.columns)\n",
    "        \n",
    "        ## Building logistic model\n",
    "        svm_md = SVC(C = 100, gamma = 1, kernel = 'rbf', probability = True).fit(X_train, Y_train)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        svm_pred_1 = svm_md.predict_proba(X_test)[:, 1]\n",
    "        svm_pred_2 = svm_md.predict_proba(test_logit)[:, 1]\n",
    "        \n",
    "        ## Computing roc-auc score\n",
    "        roc_auc_scores.append(roc_auc_score(Y_test, svm_pred_1))\n",
    "        preds.append(svm_pred_2)\n",
    "        \n",
    "    cv_scores.append(np.mean(roc_auc_scores))\n",
    "\n",
    "svm_cv_score = np.mean(cv_scores)    \n",
    "print('The roc-auc score over 5-folds (run 5 times) is:', svm_cv_score)\n",
    "\n",
    "## Building model in the entire train dataset\n",
    "X_trans = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "svm_md = SVC(C = 100, gamma = 1, kernel = 'rbf', probability = True).fit(X_trans, Y)\n",
    "\n",
    "svm_preds_train = svm_md.predict_proba(X_trans)[:, 1]\n",
    "svm_preds = pd.DataFrame(preds).apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c283ab",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "938d2f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc-auc score over 5-folds (run 5 times) is: 0.8852571565023715\n"
     ]
    }
   ],
   "source": [
    "train_RF = train.copy()\n",
    "test_RF = test.copy()\n",
    "\n",
    "## Defining inputs and target\n",
    "train_dummies = pd.get_dummies(train_RF[['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']])\n",
    "train_dummies = train_dummies.drop(columns = ['gender_Other', 'ever_married_No', 'work_type_children', 'Residence_type_Urban', 'smoking_status_Unknown'])\n",
    "\n",
    "X = train_RF.drop(columns = ['id', 'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'stroke'], axis = 1)\n",
    "X = pd.concat([X, train_dummies], axis = 1)\n",
    "Y = train_RF['stroke']\n",
    "\n",
    "test_dummies = pd.get_dummies(test_RF[['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']])\n",
    "test_dummies = test_dummies.drop(columns = ['gender_Other', 'ever_married_No', 'work_type_children', 'Residence_type_Urban', 'smoking_status_Unknown'])\n",
    "\n",
    "test_RF = test_RF.drop(columns = ['id', 'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'], axis = 1)\n",
    "test_RF = pd.concat([test_RF, test_dummies], axis = 1)\n",
    "\n",
    "cv_scores, roc_auc_scores = list(), list()\n",
    "preds = list()\n",
    "\n",
    "## Running 5 times CV\n",
    "for i in range(5):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "    \n",
    "        ## Building RF model\n",
    "        RF_md = RandomForestClassifier(max_depth = 7, min_samples_leaf = 5, min_samples_split = 2, n_estimators = 300).fit(X_train, Y_train)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        RF_pred_1 = RF_md.predict_proba(X_test)[:, 1]\n",
    "        RF_pred_2 = RF_md.predict_proba(test_RF)[:, 1]\n",
    "        \n",
    "        ## Computing roc-auc score\n",
    "        roc_auc_scores.append(roc_auc_score(Y_test, RF_pred_1))\n",
    "        preds.append(RF_pred_2)\n",
    "        \n",
    "    cv_scores.append(np.mean(roc_auc_scores))\n",
    "\n",
    "RF_cv_score = np.mean(cv_scores)    \n",
    "print('The roc-auc score over 5-folds (run 5 times) is:', RF_cv_score)\n",
    "\n",
    "## Building model in the entire train dataset\n",
    "RF_md = RandomForestClassifier(max_depth = 7, min_samples_leaf = 5, min_samples_split = 2, n_estimators = 300).fit(X, Y)\n",
    "\n",
    "RF_preds_train = RF_md.predict_proba(X)[:, 1]\n",
    "RF_preds = pd.DataFrame(preds).apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c0e62b",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "835e36b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc-auc score over 5-folds (run 5 times) is: 0.8853855128396434\n"
     ]
    }
   ],
   "source": [
    "train_XGB = train.copy()\n",
    "test_XGB = test.copy()\n",
    "\n",
    "## Defining inputs and target\n",
    "train_dummies = pd.get_dummies(train_XGB[['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']])\n",
    "train_dummies = train_dummies.drop(columns = ['gender_Other', 'ever_married_No', 'work_type_children', 'Residence_type_Urban', 'smoking_status_Unknown'])\n",
    "\n",
    "X = train_XGB.drop(columns = ['id', 'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'stroke'], axis = 1)\n",
    "X = pd.concat([X, train_dummies], axis = 1)\n",
    "Y = train_XGB['stroke']\n",
    "\n",
    "test_dummies = pd.get_dummies(test_XGB[['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']])\n",
    "test_dummies = test_dummies.drop(columns = ['gender_Other', 'ever_married_No', 'work_type_children', 'Residence_type_Urban', 'smoking_status_Unknown'])\n",
    "\n",
    "test_XGB = test_XGB.drop(columns = ['id', 'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'], axis = 1)\n",
    "test_XGB = pd.concat([test_XGB, test_dummies], axis = 1)\n",
    "\n",
    "cv_scores, roc_auc_scores = list(), list()\n",
    "preds = list()\n",
    "\n",
    "## Running 5 times CV\n",
    "for i in range(5):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "    \n",
    "        ## Building RF model\n",
    "        XGB_md = XGBClassifier(colsample_bytree = 0.8, \n",
    "                               gamma = 0.3, \n",
    "                               learning_rate = 0.01, \n",
    "                               max_depth = 5, \n",
    "                               min_child_weight = 10, \n",
    "                               n_estimators = 500, \n",
    "                               subsample = 0.8).fit(X_train, Y_train)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        XGB_pred_1 = XGB_md.predict_proba(X_test)[:, 1]\n",
    "        XGB_pred_2 = XGB_md.predict_proba(test_XGB)[:, 1]\n",
    "        \n",
    "        ## Computing roc-auc score\n",
    "        roc_auc_scores.append(roc_auc_score(Y_test, XGB_pred_1))\n",
    "        preds.append(XGB_pred_2)\n",
    "        \n",
    "    cv_scores.append(np.mean(roc_auc_scores))\n",
    "\n",
    "XGB_cv_score = np.mean(cv_scores)    \n",
    "print('The roc-auc score over 5-folds (run 5 times) is:', XGB_cv_score)\n",
    "\n",
    "## Building model in the entire train dataset\n",
    "XGB_md = XGBClassifier(colsample_bytree = 0.8, \n",
    "                       gamma = 0.3, \n",
    "                       learning_rate = 0.01, \n",
    "                       max_depth = 5, \n",
    "                       min_child_weight = 10, \n",
    "                       n_estimators = 500, \n",
    "                       subsample = 0.8).fit(X, Y)\n",
    "\n",
    "XGB_preds_train = XGB_md.predict_proba(X)[:, 1]\n",
    "XGB_preds = pd.DataFrame(preds).apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9474dd2",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30e77069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "The roc-auc score over 5-folds (run 5 times) is: 0.8826822779125866\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n"
     ]
    }
   ],
   "source": [
    "train_lgb = train.copy()\n",
    "test_lgb = test.copy()\n",
    "\n",
    "## Defining inputs and target\n",
    "train_dummies = pd.get_dummies(train_lgb[['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']])\n",
    "train_dummies = train_dummies.drop(columns = ['gender_Other', 'ever_married_No', 'work_type_children', 'Residence_type_Urban', 'smoking_status_Unknown'])\n",
    "\n",
    "X = train_lgb.drop(columns = ['id', 'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'stroke'], axis = 1)\n",
    "X = pd.concat([X, train_dummies], axis = 1)\n",
    "Y = train_lgb['stroke']\n",
    "\n",
    "test_dummies = pd.get_dummies(test_lgb[['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']])\n",
    "test_dummies = test_dummies.drop(columns = ['gender_Other', 'ever_married_No', 'work_type_children', 'Residence_type_Urban', 'smoking_status_Unknown'])\n",
    "\n",
    "test_lgb = test_lgb.drop(columns = ['id', 'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'], axis = 1)\n",
    "test_lgb = pd.concat([test_lgb, test_dummies], axis = 1)\n",
    "\n",
    "cv_scores, roc_auc_scores = list(), list()\n",
    "preds = list()\n",
    "\n",
    "## Running 5 times CV\n",
    "for i in range(5):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "    \n",
    "        ## Building RF model\n",
    "        lgb_md = LGBMClassifier(n_estimators = 1000,\n",
    "                                max_depth = 7,\n",
    "                                learning_rate = 0.01,\n",
    "                                num_leaves = 20,\n",
    "                                lambda_l1 = 3,\n",
    "                                lambda_l2 = 3,\n",
    "                                bagging_fraction = 0.7,\n",
    "                                feature_fraction = 0.7).fit(X_train, Y_train)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        lgb_pred_1 = lgb_md.predict_proba(X_test)[:, 1]\n",
    "        lgb_pred_2 = lgb_md.predict_proba(test_lgb)[:, 1]\n",
    "        \n",
    "        ## Computing roc-auc score\n",
    "        roc_auc_scores.append(roc_auc_score(Y_test, lgb_pred_1))\n",
    "        preds.append(lgb_pred_2)\n",
    "        \n",
    "    cv_scores.append(np.mean(roc_auc_scores))\n",
    "\n",
    "lgb_cv_score = np.mean(cv_scores)    \n",
    "print('The roc-auc score over 5-folds (run 5 times) is:', lgb_cv_score)\n",
    "\n",
    "## Building model in the entire train dataset\n",
    "lgb_md = LGBMClassifier(n_estimators = 1000,\n",
    "                        max_depth = 7,\n",
    "                        learning_rate = 0.01,\n",
    "                        num_leaves = 20,\n",
    "                        lambda_l1 = 3,\n",
    "                        lambda_l2 = 3,\n",
    "                        bagging_fraction = 0.7,\n",
    "                        feature_fraction = 0.7).fit(X, Y)\n",
    "\n",
    "lgb_preds_train = lgb_md.predict_proba(X)[:, 1]\n",
    "lgb_preds = pd.DataFrame(preds).apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5752187",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95b980c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_samples_leaf': 9, 'min_samples_split': 6, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "X_ensemble = pd.DataFrame({'logistic': logit_preds_train, 'SVM': svm_preds_train, 'RF': RF_preds_train, 'XGB': XGB_preds_train, 'LightGBM': lgb_preds_train})\n",
    "X_test_ensemble = pd.DataFrame({'logistic': logit_preds, 'SVM': svm_preds, 'RF': RF_preds, 'XGB': XGB_preds, 'LightGBM': lgb_preds})\n",
    "\n",
    "## Defining the hyper-parameter grid\n",
    "RF_param_grid = {'n_estimators': [100, 300, 500], \n",
    "                 'max_depth': [3, 5, 7], \n",
    "                 'min_samples_split': [2, 6, 10], \n",
    "                 'min_samples_leaf': [1, 5, 9]\n",
    "                }\n",
    "\n",
    "## Performing grid search with 5 folds\n",
    "RF_grid_search = GridSearchCV(RandomForestClassifier(), RF_param_grid, cv = 5, scoring = 'roc_auc', n_jobs = -1).fit(X_ensemble, Y)\n",
    "\n",
    "## Extracting the best model\n",
    "best_params = RF_grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d746259e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15304</td>\n",
       "      <td>0.352390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15305</td>\n",
       "      <td>0.539846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15306</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15307</td>\n",
       "      <td>0.043453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15308</td>\n",
       "      <td>0.487708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    stroke\n",
       "0  15304  0.352390\n",
       "1  15305  0.539846\n",
       "2  15306  0.000146\n",
       "3  15307  0.043453\n",
       "4  15308  0.487708"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_ensemble_md = RandomForestClassifier(n_estimators = 300, max_depth = 7, min_samples_split = 6, min_samples_leaf = 9).fit(X_ensemble, Y)\n",
    "\n",
    "RF_ensemble_pred = RF_ensemble_md.predict_proba(X_test_ensemble)[:, 1]\n",
    "\n",
    "submission['stroke'] = RF_ensemble_pred\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "070a0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('stacking_submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
