{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b5aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e7dd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "## Importing libraries\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Amex_Metric import amex_metric\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Reading the data\n",
    "train = pd.read_csv('/home/ec2-user/SageMaker/Analytics_Data_Science/American_Express/Evan/amex_train_payment_spend_final.csv')\n",
    "test = pd.read_csv('/home/ec2-user/SageMaker/Analytics_Data_Science/American_Express/Evan/amex_test_payment_spend_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d5302e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_median</th>\n",
       "      <th>P_2_correlation</th>\n",
       "      <th>P_3_mean</th>\n",
       "      <th>P_2_sum</th>\n",
       "      <th>S_25_mean</th>\n",
       "      <th>S_25_sum</th>\n",
       "      <th>S_25_std</th>\n",
       "      <th>S_25_mad</th>\n",
       "      <th>S_25_data_range</th>\n",
       "      <th>S_25_iqr</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.9336</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>-0.438767</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>12.140</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>12.670</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.009280</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>-0.854416</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>11.695</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>12.680</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>-0.109422</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>11.420</td>\n",
       "      <td>0.9740</td>\n",
       "      <td>12.664</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>0.5990</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>0.953176</td>\n",
       "      <td>0.6110</td>\n",
       "      <td>7.785</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>12.670</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>0.8794</td>\n",
       "      <td>-0.597527</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>11.590</td>\n",
       "      <td>0.9740</td>\n",
       "      <td>12.664</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  P_2_mean  P_2_median  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...    0.9336      0.9385   \n",
       "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...    0.9000      0.9050   \n",
       "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...    0.8784      0.8850   \n",
       "3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...    0.5990      0.5980   \n",
       "4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...    0.8916      0.8794   \n",
       "\n",
       "   P_2_correlation  P_3_mean  P_2_sum  S_25_mean  S_25_sum  S_25_std  \\\n",
       "0        -0.438767    0.6800   12.140     0.9746    12.670  0.002504   \n",
       "1        -0.854416    0.5670   11.695     0.9756    12.680  0.002622   \n",
       "2        -0.109422    0.6180   11.420     0.9740    12.664  0.002858   \n",
       "3         0.953176    0.6110    7.785     0.9746    12.670  0.002941   \n",
       "4        -0.597527    0.5273   11.590     0.9740    12.664  0.003314   \n",
       "\n",
       "   S_25_mad  S_25_data_range  S_25_iqr  target  \n",
       "0  0.001802         0.009280  0.001465       0  \n",
       "1  0.001802         0.008790  0.001465       0  \n",
       "2  0.002329         0.009766  0.003418       0  \n",
       "3  0.002403         0.008790  0.004395       0  \n",
       "4  0.002817         0.008790  0.005371       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ce696c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae8f51c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_median</th>\n",
       "      <th>P_2_sum</th>\n",
       "      <th>P_2_correlation</th>\n",
       "      <th>P_3_mean</th>\n",
       "      <th>S_25_mean</th>\n",
       "      <th>S_25_sum</th>\n",
       "      <th>S_25_std</th>\n",
       "      <th>S_25_mad</th>\n",
       "      <th>S_25_data_range</th>\n",
       "      <th>S_25_iqr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>0.6016</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>5.414</td>\n",
       "      <td>-0.484413</td>\n",
       "      <td>0.5737</td>\n",
       "      <td>0.9740</td>\n",
       "      <td>8.766</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.00879</td>\n",
       "      <td>0.005859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>11.210</td>\n",
       "      <td>-0.459726</td>\n",
       "      <td>0.5530</td>\n",
       "      <td>0.9740</td>\n",
       "      <td>12.664</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.00830</td>\n",
       "      <td>0.005371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...</td>\n",
       "      <td>0.7490</td>\n",
       "      <td>0.7437</td>\n",
       "      <td>9.734</td>\n",
       "      <td>-0.398301</td>\n",
       "      <td>0.6710</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>12.650</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.00830</td>\n",
       "      <td>0.005371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...</td>\n",
       "      <td>0.4746</td>\n",
       "      <td>0.4740</td>\n",
       "      <td>6.170</td>\n",
       "      <td>0.511864</td>\n",
       "      <td>0.6110</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>12.650</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>0.00879</td>\n",
       "      <td>0.005859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...</td>\n",
       "      <td>0.3240</td>\n",
       "      <td>0.3162</td>\n",
       "      <td>4.215</td>\n",
       "      <td>-0.495118</td>\n",
       "      <td>0.6350</td>\n",
       "      <td>0.5396</td>\n",
       "      <td>7.016</td>\n",
       "      <td>0.363472</td>\n",
       "      <td>0.334700</td>\n",
       "      <td>0.81640</td>\n",
       "      <td>0.712158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  P_2_mean  P_2_median  \\\n",
       "0  00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.6016      0.5970   \n",
       "1  00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...    0.8623      0.8610   \n",
       "2  0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...    0.7490      0.7437   \n",
       "3  00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...    0.4746      0.4740   \n",
       "4  00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...    0.3240      0.3162   \n",
       "\n",
       "   P_2_sum  P_2_correlation  P_3_mean  S_25_mean  S_25_sum  S_25_std  \\\n",
       "0    5.414        -0.484413    0.5737     0.9740     8.766  0.003436   \n",
       "1   11.210        -0.459726    0.5530     0.9740    12.664  0.003073   \n",
       "2    9.734        -0.398301    0.6710     0.9730    12.650  0.003055   \n",
       "3    6.170         0.511864    0.6110     0.9730    12.650  0.003233   \n",
       "4    4.215        -0.495118    0.6350     0.5396     7.016  0.363472   \n",
       "\n",
       "   S_25_mad  S_25_data_range  S_25_iqr  \n",
       "0  0.003038          0.00879  0.005859  \n",
       "1  0.002554          0.00830  0.005371  \n",
       "2  0.002628          0.00830  0.005371  \n",
       "3  0.002855          0.00879  0.005859  \n",
       "4  0.334700          0.81640  0.712158  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76e32bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589833, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c82d0c3",
   "metadata": {},
   "source": [
    "## Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "719e6c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Process Starting --\n"
     ]
    }
   ],
   "source": [
    "## Importing libraries\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import miceforest as mf\n",
    "\n",
    "## -------------------------------------------\n",
    "\n",
    "## Sanity check\n",
    "print('-- Process Starting --')\n",
    "\n",
    "## Defining the bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'evan-callaghan-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key = 'Kaggle-American-Express-Default/amex_test_data.csv'\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "## Creating data-type dictionary for reading the train data-frame\n",
    "dtype_dict = {'customer_ID': \"object\", 'S_2': \"object\", 'P_2': 'float16', 'D_39': 'float16', 'B_1': 'float16','B_2': 'float16', 'R_1': 'float16','S_3': 'float16','D_41': 'float16','B_3': 'float16','D_42': 'float16','D_43': 'float16','D_44': 'float16', 'B_4': 'float16','D_45': 'float16','B_5': 'float16','R_2': 'float16','D_46': 'float16','D_47': 'float16','D_48': 'float16', 'D_49': 'float16','B_6': 'float16','B_7': 'float16','B_8': 'float16','D_50': 'float16','D_51': 'float16','B_9': 'float16', 'R_3': 'float16','D_52': 'float16','P_3': 'float16','B_10': 'float16','D_53': 'float16','S_5': 'float16','B_11': 'float16', 'S_6': 'float16','D_54': 'float16','R_4': 'float16','S_7': 'float16','B_12': 'float16','S_8': 'float16','D_55': 'float16', 'D_56': 'float16','B_13': 'float16','R_5': 'float16','D_58': 'float16','S_9': 'float16','B_14': 'float16','D_59': 'float16', 'D_60': 'float16','D_61': 'float16','B_15': 'float16','S_11': 'float16','D_62': 'float16','D_63': 'object','D_64': 'object', 'D_65': 'float16','B_16': 'float16','B_17': 'float16','B_18': 'float16','B_19': 'float16','D_66': 'float16','B_20': 'float16', 'D_68': 'float16','S_12': 'float16','R_6': 'float16','S_13': 'float16','B_21': 'float16','D_69': 'float16','B_22': 'float16', 'D_70': 'float16','D_71': 'float16','D_72': 'float16','S_15': 'float16','B_23': 'float16','D_73': 'float16','P_4': 'float16', 'D_74': 'float16','D_75': 'float16','D_76': 'float16','B_24': 'float16','R_7': 'float16','D_77': 'float16','B_25': 'float16', 'B_26': 'float16','D_78': 'float16','D_79': 'float16','R_8': 'float16','R_9': 'float16','S_16': 'float16','D_80': 'float16', 'R_10': 'float16','R_11': 'float16','B_27': 'float16','D_81': 'float16','D_82': 'float16','S_17': 'float16','R_12': 'float16', 'B_28': 'float16','R_13': 'float16','D_83': 'float16','R_14': 'float16','R_15': 'float16','D_84': 'float16','R_16': 'float16', 'B_29': 'float16','B_30': 'float16','S_18': 'float16','D_86': 'float16','D_87': 'float16','R_17': 'float16','R_18': 'float16', 'D_88': 'float16','B_31': 'int64','S_19': 'float16','R_19': 'float16','B_32': 'float16','S_20': 'float16','R_20': 'float16', 'R_21': 'float16','B_33': 'float16','D_89': 'float16','R_22': 'float16','R_23': 'float16','D_91': 'float16','D_92': 'float16', 'D_93': 'float16','D_94': 'float16','R_24': 'float16','R_25': 'float16','D_96': 'float16','S_22': 'float16','S_23': 'float16', 'S_24': 'float16','S_25': 'float16','S_26': 'float16','D_102': 'float16','D_103': 'float16','D_104': 'float16','D_105': 'float16', 'D_106': 'float16','D_107': 'float16','B_36': 'float16','B_37': 'float16', 'R_26': 'float16','R_27': 'float16','B_38': 'float16', 'D_108': 'float16','D_109': 'float16','D_110': 'float16','D_111': 'float16','B_39': 'float16','D_112': 'float16','B_40': 'float16', 'S_27': 'float16','D_113': 'float16','D_114': 'float16','D_115': 'float16','D_116': 'float16','D_117': 'float16','D_118': 'float16', 'D_119': 'float16','D_120': 'float16','D_121': 'float16','D_122': 'float16','D_123': 'float16','D_124': 'float16','D_125': 'float16', 'D_126': 'float16','D_127': 'float16','D_128': 'float16','D_129': 'float16','B_41': 'float16','B_42': 'float16','D_130': 'float16', 'D_131': 'float16','D_132': 'float16','D_133': 'float16','R_28': 'float16','D_134': 'float16','D_135': 'float16','D_136': 'float16', 'D_137': 'float16','D_138': 'float16','D_139': 'float16','D_140': 'float16','D_141': 'float16','D_142': 'float16','D_143': 'float16', 'D_144': 'float16','D_145': 'float16'}\n",
    "\n",
    "## Reading the data\n",
    "test = pd.read_csv(file_content_stream, dtype = dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "097807dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>0.631348</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.814453</td>\n",
       "      <td>0.007545</td>\n",
       "      <td>0.168701</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>0.586914</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>0.011024</td>\n",
       "      <td>0.811035</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.241333</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.001460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>0.608887</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.016388</td>\n",
       "      <td>1.004883</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.267090</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.006481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>0.614746</td>\n",
       "      <td>0.009064</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.816406</td>\n",
       "      <td>0.009720</td>\n",
       "      <td>0.188965</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.015327</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.007858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>0.591797</td>\n",
       "      <td>0.238770</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>0.810547</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.180054</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.011284</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>0.004330</td>\n",
       "      <td>0.008385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.009468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID         S_2       P_2  \\\n",
       "0  00000469ba478561f23a92a868bd366de6f6527a684c9a...  2019-02-19  0.631348   \n",
       "1  00000469ba478561f23a92a868bd366de6f6527a684c9a...  2019-03-25  0.586914   \n",
       "2  00000469ba478561f23a92a868bd366de6f6527a684c9a...  2019-04-25  0.608887   \n",
       "3  00000469ba478561f23a92a868bd366de6f6527a684c9a...  2019-05-20  0.614746   \n",
       "4  00000469ba478561f23a92a868bd366de6f6527a684c9a...  2019-06-15  0.591797   \n",
       "\n",
       "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  ...  \\\n",
       "0  0.001912  0.010727  0.814453  0.007545  0.168701  0.009972  0.002348  ...   \n",
       "1  0.005276  0.011024  0.811035  0.001817  0.241333  0.000166  0.009132  ...   \n",
       "2  0.003326  0.016388  1.004883  0.000114  0.267090  0.004196  0.004192  ...   \n",
       "3  0.009064  0.021667  0.816406  0.009720  0.188965  0.004124  0.015327  ...   \n",
       "4  0.238770  0.015930  0.810547  0.002026  0.180054  0.000731  0.011284  ...   \n",
       "\n",
       "   D_136  D_137  D_138     D_139     D_140     D_141  D_142     D_143  \\\n",
       "0    NaN    NaN    NaN       NaN  0.004669       NaN    NaN       NaN   \n",
       "1    NaN    NaN    NaN  0.000142  0.004940  0.009018    NaN  0.003695   \n",
       "2    NaN    NaN    NaN  0.000074  0.002113  0.004658    NaN  0.003155   \n",
       "3    NaN    NaN    NaN  0.004742  0.006393  0.002890    NaN  0.006042   \n",
       "4    NaN    NaN    NaN  0.008133  0.004330  0.008385    NaN  0.001008   \n",
       "\n",
       "      D_144     D_145  \n",
       "0  0.008278       NaN  \n",
       "1  0.003754  0.001460  \n",
       "2  0.002155  0.006481  \n",
       "3  0.005207  0.007858  \n",
       "4  0.007420  0.009468  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e89a983c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7249445, 190)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c9bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sanity check\n",
    "print('-- Data Read --')\n",
    "\n",
    "## Subsetting the data for Payment and Spend variables\n",
    "test = test[['customer_ID', 'P_2', 'P_3', 'P_4', 'S_3', 'S_5', 'S_6', 'S_7', 'S_8', 'S_9', 'S_11', 'S_12', 'S_13', 'S_15', 'S_16', 'S_17', \n",
    "               'S_18', 'S_19', 'S_20', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'S_27']]\n",
    "\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8462299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589833"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['customer_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "875a8f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589833, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby('customer_ID')[['P_2', 'P_3']].mean().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7d914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing the test data-frame using the Mice Forest library\n",
    "\n",
    "## Defining the input variables and dropping customer_ID\n",
    "mf_test = test.drop(columns = ['customer_ID'])\n",
    "\n",
    "# Building the miceforest kernel\n",
    "kernel_test = mf.ImputationKernel(mf_test, datasets = 5, save_all_iterations = True)\n",
    "\n",
    "## Assigning the final imputed data-frames\n",
    "test_impute = kernel_test.complete_data(dataset = 0, inplace = False)\n",
    "\n",
    "## Adding \"customer_ID\" back into the data-frames\n",
    "test_impute = pd.concat([test[['customer_ID']], test_impute], axis = 1)\n",
    "\n",
    "## Sanity check\n",
    "print('-- Testing data-frame imputation complete -- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c493cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating other aggregated features of interest\n",
    "\n",
    "## Sanity check\n",
    "print('-- Testing data-frame aggregations starting -- \\n')\n",
    "\n",
    "## Creating a series of aggregation functions\n",
    "def data_range(x):\n",
    "    return x.max() - x.min()\n",
    "def iqr(x):\n",
    "    return np.percentile(x, 75) - np.percentile(x, 25)\n",
    "def correlation(x):\n",
    "    return pd.Series(x.values).corr(other = pd.Series(x.index), method = 'pearson')\n",
    "\n",
    "## Creating new Payment features with the cleaned test data-frame\n",
    "payment_vars_test = test_impute.groupby('customer_ID').agg({'P_2':['mean', 'median', 'sum', correlation], 'P_3':['mean']}).reset_index(drop = False)\n",
    "\n",
    "## Renaming variable names\n",
    "payment_vars_test.columns = ['customer_ID', 'P_2_mean', 'P_2_median', 'P_2_sum', 'P_2_correlation', 'P_3_mean']\n",
    "\n",
    "## Creating new Spend features with the cleaned test data-frame\n",
    "spend_vars_test = test_impute.groupby('customer_ID').agg({'S_25':['mean', 'sum', 'std', 'mad', data_range, iqr]}).reset_index(drop = False)\n",
    "\n",
    "spend_vars_test.columns = ['customer_ID', 'S_25_mean', 'S_25_sum', 'S_25_std', 'S_25_mad', 'S_25_data_range', 'S_25_iqr']\n",
    "\n",
    "## Sanity check\n",
    "print('-- Testing aggregations complete -- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ed0b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combining desired count features with other aggregated features to create final data-frame\n",
    "\n",
    "## Joining the Payment and Spend train data-frames\n",
    "testing = payment_vars_test.merge(spend_vars_test, how = 'left', on = 'customer_ID')\n",
    "\n",
    "## -------------------------------------------\n",
    "\n",
    "## Exporting the resulting training data-frame to a csv file\n",
    "testing.to_csv('amex_test_payment_spend_final.csv', index = False)\n",
    "\n",
    "## Sanity check\n",
    "print('-- Testing data-frame complete -- \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53229a7",
   "metadata": {},
   "source": [
    "## Modeling Processes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d36967e",
   "metadata": {},
   "source": [
    "#### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecdd060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the train data-frame into training (80%) and validation (20%)\n",
    "\n",
    "## Defining the input and target variables\n",
    "X_train = train.drop(columns = ['customer_ID', 'target'])\n",
    "X_test = test.drop(columns = ['customer_ID'])\n",
    "Y_train = train['target']\n",
    "\n",
    "## Splitting the data\n",
    "X_training, X_validation, Y_training, Y_validation = train_test_split(X_train, Y_train, test_size = 0.2, stratify = Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b77682",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b581fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost Classifier\n",
    "def objective_amex_xgb(trial):\n",
    "    \n",
    "    ## Defining the XGB hyper-parameter grid\n",
    "    XGB_param_grid = {'n_estimators': trial.suggest_int('n_estimators', 100, 500, 100),\n",
    "                     'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.951, step = 0.05),\n",
    "                     'min_split_loss': trial.suggest_int('min_split_loss', 0, 5, 1),\n",
    "                     'max_depth' : trial.suggest_int('max_depth', 3, 7, 1),\n",
    "                     'min_child_weight' : trial.suggest_int('min_child_weight', 5, 9, 1),\n",
    "                     'subsample' : trial.suggest_float('subsample', 0.6, 1, step = 0.1),\n",
    "                     'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.6, 1, step = 0.1)}\n",
    "    \n",
    "    ## Building the XGBClassifier model\n",
    "    model = XGBClassifier(**XGB_param_grid, n_jobs = -1).fit(X_training, Y_training)\n",
    "        \n",
    "    ## Predicting on the validation data-frame\n",
    "    xgb_val_preds = model.predict_proba(X_validation)[:, 1]\n",
    "    \n",
    "    ## Evaluating model performance on the validation set\n",
    "    amex_score = amex_metric(Y_validation, xgb_val_preds)\n",
    "    \n",
    "    ## Returning absolute difference of model validation predictions\n",
    "    return amex_score\n",
    "\n",
    "\n",
    "## RandomForest Classifier\n",
    "def objective_amex_rf(trial):\n",
    "    \n",
    "    ## Defining the XGB hyper-parameter grid\n",
    "    rf_param_grid = {'n_estimators': trial.suggest_int('n_estimators', 100, 500, 100), \n",
    "                     'max_depth' : trial.suggest_int('max_depth', 3, 7, 1),\n",
    "                     'min_samples_split' : trial.suggest_int('min_samples_split', 5, 15, 1), \n",
    "                     'min_samples_leaf' : trial.suggest_int('min_samples_leaf', 5, 15, 1)}\n",
    "    \n",
    "    ## Building the RandomForestClassifier model\n",
    "    model = RandomForestClassifier(**rf_param_grid, n_jobs = -1).fit(X_training, Y_training)\n",
    "        \n",
    "    ## Predicting on the validation data-frame\n",
    "    rf_val_preds = model.predict_proba(X_validation)[:, 1]\n",
    "    \n",
    "    ## Evaluating model performance on the validation set\n",
    "    amex_score = amex_metric(Y_validation, rf_val_preds)\n",
    "    \n",
    "    ## Returning absolute difference of model validation predictions\n",
    "    return amex_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "285e22b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-24 19:16:38,185]\u001b[0m A new study created in memory with name: no-name-d1bc5d7b-0ddf-46dd-92ff-2fd97598f7cc\u001b[0m\n",
      "\u001b[32m[I 2022-07-24 19:17:20,932]\u001b[0m Trial 0 finished with value: 9.124367584192536e-05 and parameters: {'n_estimators': 300, 'learning_rate': 0.101, 'min_split_loss': 2, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.6}. Best is trial 0 with value: 9.124367584192536e-05.\u001b[0m\n",
      "\u001b[32m[I 2022-07-24 19:17:33,246]\u001b[0m Trial 1 finished with value: 0.00027461626555567997 and parameters: {'n_estimators': 100, 'learning_rate': 0.30100000000000005, 'min_split_loss': 5, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.9}. Best is trial 1 with value: 0.00027461626555567997.\u001b[0m\n",
      "\u001b[32m[I 2022-07-24 19:18:01,368]\u001b[0m Trial 2 finished with value: 0.0004714649529968494 and parameters: {'n_estimators': 300, 'learning_rate': 0.7010000000000001, 'min_split_loss': 4, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.9, 'colsample_bytree': 0.7}. Best is trial 2 with value: 0.0004714649529968494.\u001b[0m\n",
      "\u001b[32m[I 2022-07-24 19:18:48,104]\u001b[0m Trial 3 finished with value: 0.00020937913673720748 and parameters: {'n_estimators': 400, 'learning_rate': 0.101, 'min_split_loss': 0, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.6, 'colsample_bytree': 0.6}. Best is trial 2 with value: 0.0004714649529968494.\u001b[0m\n",
      "\u001b[32m[I 2022-07-24 19:19:36,846]\u001b[0m Trial 4 finished with value: 6.039194265300418e-05 and parameters: {'n_estimators': 400, 'learning_rate': 0.201, 'min_split_loss': 1, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.8, 'colsample_bytree': 0.7}. Best is trial 2 with value: 0.0004714649529968494.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Calling Optuna objective function for XGBoost\n",
    "xgb_study = optuna.create_study(direction = 'maximize')\n",
    "xgb_study.optimize(objective_amex_xgb, n_trials = 5)\n",
    "\n",
    "## Extracting best model \n",
    "xgb_best_params = xgb_study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3691e518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-24 19:19:36,854]\u001b[0m A new study created in memory with name: no-name-8efbd714-701c-4b80-b66b-7a5d1fe38088\u001b[0m\n",
      "\u001b[32m[I 2022-07-24 19:19:50,920]\u001b[0m Trial 0 finished with value: 0.00047763268668644596 and parameters: {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.00047763268668644596.\u001b[0m\n",
      "\u001b[32m[I 2022-07-24 19:20:47,148]\u001b[0m Trial 1 finished with value: 0.0003671679426219543 and parameters: {'n_estimators': 400, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.00047763268668644596.\u001b[0m\n",
      "\u001b[32m[I 2022-07-24 19:21:18,361]\u001b[0m Trial 2 finished with value: 0.00039576080194453703 and parameters: {'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.00047763268668644596.\u001b[0m\n",
      "\u001b[32m[I 2022-07-24 19:22:11,143]\u001b[0m Trial 3 finished with value: 0.00019163317026102758 and parameters: {'n_estimators': 300, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.00047763268668644596.\u001b[0m\n",
      "\u001b[32m[I 2022-07-24 19:22:37,893]\u001b[0m Trial 4 finished with value: 0.0005562645072869077 and parameters: {'n_estimators': 200, 'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 6}. Best is trial 4 with value: 0.0005562645072869077.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Calling Optuna objective function for Random Forest\n",
    "rf_study = optuna.create_study(direction = 'maximize')\n",
    "rf_study.optimize(objective_amex_rf, n_trials = 5)\n",
    "\n",
    "## Extracting best model \n",
    "rf_best_params = rf_study.best_trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ae5e2",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8101beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a Random Forest model with the optimal set of hyper-parameters\n",
    "rf_md = RandomForestClassifier(**rf_best_params, n_jobs = -1).fit(X_training, Y_training)\n",
    "\n",
    "## Predicting on the test data-frame\n",
    "X_test_preds = rf_md.predict_proba(X_test)[:, 1]\n",
    "\n",
    "## Creating the final output data-frame\n",
    "data_out = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': X_test_preds})\n",
    "\n",
    "## Exporting as a csv file for submission\n",
    "data_out.to_csv('amex_rf_payment_spend_preds.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a XGBoost model with the optimal set of hyper-parameters\n",
    "xgb_md = XGBClassifier(**xgb_best_params, n_jobs = -1).fit(X_training, Y_training)\n",
    "\n",
    "## Predicting on the test data-frame\n",
    "X_test_preds = xgb_md.predict_proba(X_test)[:, 1]\n",
    "\n",
    "## Creating the final output data-frame\n",
    "data_out = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': X_test_preds})\n",
    "\n",
    "## Exporting as a csv file for submission\n",
    "data_out.to_csv('amex_xgb_payment_spend_preds.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
