{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ff9eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Series/Tabular-Playground-Nov-2022/sample_submission.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "submission = pd.read_parquet(file_content_stream_1)\n",
    "df = pd.read_parquet('s3://analytics-data-science-competitions/Tabular-Playground-Series/Tabular-Playground-Nov-2022/preds_concat_gzip.parquet', engine = 'fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313742c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = df.clip(0, 1) ## Notice that some of the model prediction files have negative likehookds and greater than 1 likelihoods\n",
    "train = preds_df[preds_df['target'].notnull()]\n",
    "test = preds_df[preds_df['target'].isnull()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f8a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "train_new = train.copy()\n",
    "logloss = list()\n",
    "\n",
    "for i in range(0, 5000):\n",
    "    \n",
    "    logloss.append(log_loss(train_new['target'], train_new.iloc[:, i]))\n",
    "    \n",
    "#  Log-Loss dataframe\n",
    "logloss_data = pd.DataFrame({'File': train_new.columns[:-1], 'LogLoss': logloss})\n",
    "logloss_data = logloss_data.sort_values(by = 'LogLoss').reset_index(drop = True)\n",
    "logloss_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "logloss_data.to_csv('logloss_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab7f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[logloss_data['File'][0:100].values]\n",
    "Y = train['target']\n",
    "\n",
    "test_new = test[logloss_data['File'][0:100].values]\n",
    "\n",
    "## Defining list to store results\n",
    "logit_results, test_preds_logit = list(), list()\n",
    "\n",
    "fold = 1\n",
    "kfold = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "        \n",
    "for train_ix, test_ix in kfold.split(X, Y):\n",
    "    \n",
    "    ## Splitting the data \n",
    "    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "    Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "\n",
    "    ## Building model\n",
    "    logit_md = LogisticRegression(solver = 'liblinear', penalty = 'l1').fit(X_train, Y_train)\n",
    "        \n",
    "    ## Predicting on test\n",
    "    logit_pred = logit_md.predict_proba(X_test)[:, 1]\n",
    "    score = log_loss(Y_test, logit_pred)\n",
    "    logit_results.append(score)\n",
    "        \n",
    "    print('Fold ', str(fold), ' result is:', score, '\\n')\n",
    "\n",
    "    test_preds_logit.append(logit_md.predict_proba(test_new)[:, 1])\n",
    "    fold +=1\n",
    "\n",
    "print('The average log-loss over 5-fold CV is', np.mean(logit_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b039cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_logit = pd.DataFrame(test_preds_logit)\n",
    "print(test_preds_logit.shape)\n",
    "\n",
    "test_preds_logit = test_preds_logit.mean(axis = 0)\n",
    "print(test_preds_logit.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c09987",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['pred'] = test_preds_logit\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f9a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d21cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a0171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "logistic_performance = pd.DataFrame({'Number_of_Features': [100, 200, 300, 400, 500], 'CV_score': [0.5314294293449413, 0.5303333592114292, 0.5306822864009136, 0.5301723355083536, 0.5306497920414268], 'LB_score': [0.52438, 0.5239, 0.52357, 0.52319, 0.52313]})\n",
    "logistic_performance['CV_score'] = round(logistic_performance['CV_score'], 5)\n",
    "logistic_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ddae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "\n",
    "sns.lineplot(data = logistic_performance, x = 'Number_of_Features', y = 'CV_score', label = 'CV-score').set(xlabel = 'Number of Features', ylabel = 'Log-Loss Score', title = 'Logistic Regression Performance')\n",
    "sns.lineplot(data = logistic_performance, x = 'Number_of_Features', y = 'LB_score', label = 'LB-score')\n",
    "\n",
    "plt.savefig('logistic_performace.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = logistic_performance.drop(columns = 'Number_of_Features', axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b78e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d1159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418b28d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>LogLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6222863195.csv</td>\n",
       "      <td>0.622286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6223807245.csv</td>\n",
       "      <td>0.622381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6225426578.csv</td>\n",
       "      <td>0.622543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6247722291.csv</td>\n",
       "      <td>0.624772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6253455681.csv</td>\n",
       "      <td>0.625346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6254850917.csv</td>\n",
       "      <td>0.625485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6255093621.csv</td>\n",
       "      <td>0.625509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6260141578.csv</td>\n",
       "      <td>0.626014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6263493693.csv</td>\n",
       "      <td>0.626349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6272779211.csv</td>\n",
       "      <td>0.627278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               File   LogLoss\n",
       "0  0.6222863195.csv  0.622286\n",
       "1  0.6223807245.csv  0.622381\n",
       "2  0.6225426578.csv  0.622543\n",
       "3  0.6247722291.csv  0.624772\n",
       "4  0.6253455681.csv  0.625346\n",
       "5  0.6254850917.csv  0.625485\n",
       "6  0.6255093621.csv  0.625509\n",
       "7  0.6260141578.csv  0.626014\n",
       "8  0.6263493693.csv  0.626349\n",
       "9  0.6272779211.csv  0.627278"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "logloss_data = pd.read_csv('logloss_data.csv')\n",
    "\n",
    "data_temp = logloss_data.iloc[0:10, ]\n",
    "data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3dbaa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27469/3596268345.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_temp['w'] = 1 / data_temp['LogLoss']\n",
      "/tmp/ipykernel_27469/3596268345.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_temp['W'] = data_temp['w'] / np.sum(data_temp['w'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>w</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6222863195.csv</td>\n",
       "      <td>0.622286</td>\n",
       "      <td>1.606977</td>\n",
       "      <td>0.100403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6223807245.csv</td>\n",
       "      <td>0.622381</td>\n",
       "      <td>1.606734</td>\n",
       "      <td>0.100387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6225426578.csv</td>\n",
       "      <td>0.622543</td>\n",
       "      <td>1.606316</td>\n",
       "      <td>0.100361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6247722291.csv</td>\n",
       "      <td>0.624772</td>\n",
       "      <td>1.600583</td>\n",
       "      <td>0.100003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6253455681.csv</td>\n",
       "      <td>0.625346</td>\n",
       "      <td>1.599116</td>\n",
       "      <td>0.099911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6254850917.csv</td>\n",
       "      <td>0.625485</td>\n",
       "      <td>1.598759</td>\n",
       "      <td>0.099889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6255093621.csv</td>\n",
       "      <td>0.625509</td>\n",
       "      <td>1.598697</td>\n",
       "      <td>0.099885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6260141578.csv</td>\n",
       "      <td>0.626014</td>\n",
       "      <td>1.597408</td>\n",
       "      <td>0.099805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6263493693.csv</td>\n",
       "      <td>0.626349</td>\n",
       "      <td>1.596553</td>\n",
       "      <td>0.099751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6272779211.csv</td>\n",
       "      <td>0.627278</td>\n",
       "      <td>1.594190</td>\n",
       "      <td>0.099604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               File   LogLoss         w         W\n",
       "0  0.6222863195.csv  0.622286  1.606977  0.100403\n",
       "1  0.6223807245.csv  0.622381  1.606734  0.100387\n",
       "2  0.6225426578.csv  0.622543  1.606316  0.100361\n",
       "3  0.6247722291.csv  0.624772  1.600583  0.100003\n",
       "4  0.6253455681.csv  0.625346  1.599116  0.099911\n",
       "5  0.6254850917.csv  0.625485  1.598759  0.099889\n",
       "6  0.6255093621.csv  0.625509  1.598697  0.099885\n",
       "7  0.6260141578.csv  0.626014  1.597408  0.099805\n",
       "8  0.6263493693.csv  0.626349  1.596553  0.099751\n",
       "9  0.6272779211.csv  0.627278  1.594190  0.099604"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temp['w'] = 1 / data_temp['LogLoss']\n",
    "data_temp['W'] = data_temp['w'] / np.sum(data_temp['w'])\n",
    "data_temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
