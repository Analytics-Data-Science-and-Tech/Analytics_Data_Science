{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa8cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "\n",
    "## Defining the bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'evan-callaghan-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key = 'Kaggle-American-Express-Default/amex_sample_submission.csv'\n",
    "file_key2 = 'Kaggle-American-Express-Default/amex_train_labels.csv'\n",
    "file_key3 = 'Kaggle-American-Express-Default/amex_train_data.csv'\n",
    "file_key4 = 'Kaggle-American-Express-Default/amex_test_data.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "bucket_object2 = bucket.Object(file_key2)\n",
    "bucket_object3 = bucket.Object(file_key3)\n",
    "bucket_object4 = bucket.Object(file_key4)\n",
    "\n",
    "file_object = bucket_object.get()\n",
    "file_object2 = bucket_object2.get()\n",
    "file_object3 = bucket_object3.get()\n",
    "file_object4 = bucket_object4.get()\n",
    "\n",
    "file_content_stream = file_object.get('Body')\n",
    "file_content_stream2 = file_object2.get('Body')\n",
    "file_content_stream3 = file_object3.get('Body')\n",
    "file_content_stream4 = file_object4.get('Body')\n",
    "\n",
    "## Creating data-type dictionary for reading the train data-frame\n",
    "dtype_dict = {'customer_ID': \"object\", 'S_2': \"object\", 'P_2': 'float16', 'D_39': 'float16', 'B_1': 'float16','B_2': 'float16',\n",
    "              'R_1': 'float16','S_3': 'float16','D_41': 'float16','B_3': 'float16','D_42': 'float16','D_43': 'float16','D_44': 'float16',\n",
    "              'B_4': 'float16','D_45': 'float16','B_5': 'float16','R_2': 'float16','D_46': 'float16','D_47': 'float16','D_48': 'float16',\n",
    "              'D_49': 'float16','B_6': 'float16','B_7': 'float16','B_8': 'float16','D_50': 'float16','D_51': 'float16','B_9': 'float16',\n",
    "              'R_3': 'float16','D_52': 'float16','P_3': 'float16','B_10': 'float16','D_53': 'float16','S_5': 'float16','B_11': 'float16',\n",
    "              'S_6': 'float16','D_54': 'float16','R_4': 'float16','S_7': 'float16','B_12': 'float16','S_8': 'float16','D_55': 'float16',\n",
    "              'D_56': 'float16','B_13': 'float16','R_5': 'float16','D_58': 'float16','S_9': 'float16','B_14': 'float16','D_59': 'float16',\n",
    "              'D_60': 'float16','D_61': 'float16','B_15': 'float16','S_11': 'float16','D_62': 'float16','D_63': 'object','D_64': 'object',\n",
    "              'D_65': 'float16','B_16': 'float16','B_17': 'float16','B_18': 'float16','B_19': 'float16','D_66': 'float16','B_20': 'float16',\n",
    "              'D_68': 'float16','S_12': 'float16','R_6': 'float16','S_13': 'float16','B_21': 'float16','D_69': 'float16','B_22': 'float16',\n",
    "              'D_70': 'float16','D_71': 'float16','D_72': 'float16','S_15': 'float16','B_23': 'float16','D_73': 'float16','P_4': 'float16',\n",
    "              'D_74': 'float16','D_75': 'float16','D_76': 'float16','B_24': 'float16','R_7': 'float16','D_77': 'float16','B_25': 'float16',\n",
    "              'B_26': 'float16','D_78': 'float16','D_79': 'float16','R_8': 'float16','R_9': 'float16','S_16': 'float16','D_80': 'float16',\n",
    "              'R_10': 'float16','R_11': 'float16','B_27': 'float16','D_81': 'float16','D_82': 'float16','S_17': 'float16','R_12': 'float16',\n",
    "              'B_28': 'float16','R_13': 'float16','D_83': 'float16','R_14': 'float16','R_15': 'float16','D_84': 'float16','R_16': 'float16',\n",
    "              'B_29': 'float16','B_30': 'float16','S_18': 'float16','D_86': 'float16','D_87': 'float16','R_17': 'float16','R_18': 'float16',\n",
    "              'D_88': 'float16','B_31': 'int64','S_19': 'float16','R_19': 'float16','B_32': 'float16','S_20': 'float16','R_20': 'float16',\n",
    "              'R_21': 'float16','B_33': 'float16','D_89': 'float16','R_22': 'float16','R_23': 'float16','D_91': 'float16','D_92': 'float16',\n",
    "              'D_93': 'float16','D_94': 'float16','R_24': 'float16','R_25': 'float16','D_96': 'float16','S_22': 'float16','S_23': 'float16',\n",
    "              'S_24': 'float16','S_25': 'float16','S_26': 'float16','D_102': 'float16','D_103': 'float16','D_104': 'float16','D_105': 'float16',\n",
    "              'D_106': 'float16','D_107': 'float16','B_36': 'float16','B_37': 'float16', 'R_26': 'float16','R_27': 'float16','B_38': 'float16',\n",
    "              'D_108': 'float16','D_109': 'float16','D_110': 'float16','D_111': 'float16','B_39': 'float16','D_112': 'float16','B_40': 'float16',\n",
    "              'S_27': 'float16','D_113': 'float16','D_114': 'float16','D_115': 'float16','D_116': 'float16','D_117': 'float16','D_118': 'float16',\n",
    "              'D_119': 'float16','D_120': 'float16','D_121': 'float16','D_122': 'float16','D_123': 'float16','D_124': 'float16','D_125': 'float16',\n",
    "              'D_126': 'float16','D_127': 'float16','D_128': 'float16','D_129': 'float16','B_41': 'float16','B_42': 'float16','D_130': 'float16',\n",
    "              'D_131': 'float16','D_132': 'float16','D_133': 'float16','R_28': 'float16','D_134': 'float16','D_135': 'float16','D_136': 'float16',\n",
    "              'D_137': 'float16','D_138': 'float16','D_139': 'float16','D_140': 'float16','D_141': 'float16','D_142': 'float16','D_143': 'float16',\n",
    "              'D_144': 'float16','D_145': 'float16'}\n",
    "\n",
    "## Reading the data\n",
    "sample_submission = pd.read_csv(file_content_stream)\n",
    "train_labels = pd.read_csv(file_content_stream2)\n",
    "train = pd.read_csv(file_content_stream3, dtype = dtype_dict)\n",
    "#test = pd.read_csv(file_content_stream4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7695052",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Builidng a subset of the training data-frame with 100 randomly sampled customers\n",
    "list1 = set(train['customer_ID'].unique())\n",
    "sample = sample(list1, 100)\n",
    "\n",
    "## Subsetting the data\n",
    "train_sample = train[np.isin(train['customer_ID'], sample)]\n",
    "train_labels_sample = train_labels[np.isin(train_labels['customer_ID'], sample)]\n",
    "\n",
    "## Printing the shape of the resulting data-frame\n",
    "train_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822741ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Creating a subset of the training data\n",
    "sub = train_sample[train_sample['customer_ID'] == '04305420dfcc6bae8a5943fde9b19a8beff5456e529a0e6bce15655d9b814329']\n",
    "\n",
    "## Defining the input and target variables\n",
    "X = np.asarray(sub['S_2'])\n",
    "Y = np.asarray(sub['S_5'])\n",
    "\n",
    "## Cleaning the date variable\n",
    "df = pd.DataFrame({'time': X, 'value': Y})\n",
    "df.time = pd.to_datetime(df.time)\n",
    "\n",
    "## Fitting a linear regression line\n",
    "lm_md = LinearRegression().fit(df.time.values.reshape(-1, 1), df['value'].values.reshape(-1, 1)) \n",
    "\n",
    "## Extracting the linear model coefficients\n",
    "print('Coefficient:', lm_md.coef_)\n",
    "\n",
    "## Predicting on the train set\n",
    "y_pred = lm_md.predict(df.time.values.astype(float).reshape(-1, 1))\n",
    "df['pred'] = y_pred\n",
    "\n",
    "## Plotting results\n",
    "ax = df.plot(x='time', y='value', color='black', style='.', figsize = ([14, 8]))\n",
    "df.plot(x='time', y='pred', color='orange', linewidth=3, ax=ax, alpha=0.5)\n",
    "ax.set_title('My Title')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[train_labels['customer_ID'] == '04305420dfcc6bae8a5943fde9b19a8beff5456e529a0e6bce15655d9b814329']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e67576",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining a list of all customer_IDs\n",
    "customers = train_samples['customer_ID'].unique()\n",
    "\n",
    "## Initialzing new column in the train_labels_sample data-frame\n",
    "train_labels_sample['Spend_Slope'] = np.nan\n",
    "\n",
    "## Looping through each set of customers:\n",
    "for customer in customers:\n",
    "    \n",
    "    ## Subsetting by customer\n",
    "    customers_temp = train_sample[train_sample['customer_ID'] == customer]\n",
    "    \n",
    "    ## Spend variable subset\n",
    "    spend_temp = customer_temp[['S_2', 'S_3', 'S_5', 'S_6', 'S_7', 'S_8', 'S_9','S_11', 'S_12', 'S_13', 'S_15', 'S_16', \n",
    "                                'S_17', 'S_18', 'S_19', 'S_20', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'S_27']]\n",
    "    \n",
    "    ## Defining the input and target variables\n",
    "    X = spend_temp['S_2']\n",
    "    Y = spend_temp.drop(columns = ['S_2'])\n",
    "    \n",
    "    ## Creating the linear regression model\n",
    "    lm_md = LinearRegression().fit(X, Y)\n",
    "    \n",
    "    ## Extracting the slope of the line\n",
    "    slope = lm_md.coef_\n",
    "    \n",
    "    ## Creating new variable for spend slope\n",
    "    train_labels_sample['Spend_Slope'] = np.where(train_labels_sample['customer_ID'] == customer, slope, train_labels_sample['Spend_Slope'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d186257",
   "metadata": {},
   "source": [
    "## Idea:\n",
    "Create subsets on customer_ID and create a simple linear regression model to extract the slope of the line\n",
    "\n",
    "Useful for change in spending habit, change in balance, and change in paymne behaviours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ec052",
   "metadata": {},
   "source": [
    "## Variable engineering processes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2747c21",
   "metadata": {},
   "source": [
    "#### Mean, Median, and Mode for each customer and variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a12144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "## Defining a list of all customerIDs\n",
    "customers = train_samples['customer_ID'].unique()\n",
    "\n",
    "## Defining an empty data-frame to store results\n",
    "train_samples_out = pd.DataFrame()\n",
    "\n",
    "## Looping through all customer subsets\n",
    "for customer in customers:\n",
    "    \n",
    "    ## Subsetting the data\n",
    "    customer_temp = train_samples[train_samples['customer_ID'] == customer]\n",
    "    \n",
    "    ## Creating the mean, median, and mode variables\n",
    "    \n",
    "    \n",
    "values = mydata.values\n",
    "imputer = Imputer(missing_values=’NaN’, strategy=’mean’)\n",
    "transformed_values = imputer.fit_transform(values)\n",
    "# strategy can be changed to \"median\" and “most_frequent”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
