{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db5b5480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: tidytext in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (0.0.1)\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.8/636.8 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: siuba in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tidytext) (0.3.0)\n",
      "Requirement already satisfied: nltk>=3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (2021.11.10)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from siuba->tidytext) (1.20.3)\n",
      "Requirement already satisfied: PyYAML>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from siuba->tidytext) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.2.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from siuba->tidytext) (1.4.27)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from siuba->tidytext) (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas>=0.24.0->siuba->tidytext) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas>=0.24.0->siuba->tidytext) (2021.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from SQLAlchemy>=1.2.19->siuba->tidytext) (1.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->siuba->tidytext) (1.16.0)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tidytext textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9dfad59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a170c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "from Help_Funs import count_chars, count_words, count_capital_chars, count_capital_words, count_sent, count_unique_words, count_stopwords, count_hashtags \n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Covid-tweets/training_data.csv'\n",
    "file_key_2 = 'Covid-tweets/test_data.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "\n",
    "## Feature Engineering \n",
    "train['is_quote'] = train['is_quote'].str.lower()\n",
    "train['is_quote'] = np.where(train['is_quote'] == 'false', 0, 1)\n",
    "train['is_retweet'] = train['is_retweet'].str.lower()\n",
    "train['is_retweet'] = np.where(train['is_retweet'] == 'false', 0, 1)\n",
    "train['Trump_flag'] = np.where(train['reply_to_screen_name'] == 'realDonaldTrump', 1, 0)\n",
    "train['jfrketich_flag'] = np.where(train['reply_to_screen_name'] == 'jfrketich', 1, 0)\n",
    "\n",
    "\n",
    "test['is_quote'] = np.where(test['is_quote'] == False, 0, 1)\n",
    "test['is_retweet'] = np.where(test['is_retweet'] == False, 0, 1)\n",
    "test['Trump_flag'] = np.where(test['reply_to_screen_name'] == 'realDonaldTrump', 1, 0)\n",
    "test['jfrketich_flag'] = np.where(test['reply_to_screen_name'] == 'jfrketich', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef971b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "others = set([\"1\", \"2\", \"it'll\", \"ill\", \"=\", '+', \"'s'\", '\"'])\n",
    "stop_words = stop_words.union(others)\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    if type(tweet) == np.float:\n",
    "        return \"\"\n",
    "    temp = tweet.lower()\n",
    "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(r'http\\S+', '', temp)\n",
    "    temp = re.sub('[()!?]', ' ', temp)\n",
    "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
    "    temp = re.sub(\"[^a-z0-9]\",\" \", temp)\n",
    "    temp = temp.split()\n",
    "    temp = [w for w in temp if not w in stop_words]\n",
    "    temp = \" \".join(word for word in temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deca45c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/240000 [00:00<?, ?it/s]/tmp/ipykernel_8449/4248643825.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['clean_tweet'][i] =  clean_tweet(train['text'][i])\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "100%|██████████| 240000/240000 [00:08<00:00, 27094.70it/s]\n"
     ]
    }
   ],
   "source": [
    "train['clean_tweet'] = np.nan\n",
    "\n",
    "for i in tqdm(range(0, train.shape[0])):\n",
    "    \n",
    "    train['clean_tweet'][i] =  clean_tweet(train['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f25d1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>country</th>\n",
       "      <th>Trump_flag</th>\n",
       "      <th>jfrketich_flag</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remember the #WuhanCoronaVirus? The pandemic w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>WuhanCoronaVirus KillerCuomo</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>remember pandemic great percentage deaths resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My sources @WhiteHouse say 2 tactics will be u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Trump</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sources say tactics used get america open amp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll venture a wild guess: If you were running...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>COVID19</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>venture wild guess running usa crisis youd wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Pakistan (#GreenStimulus = #Nature protection...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pakistan GreenStimulus Nature Green</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>protection jobs community youth within recentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>🇺🇸 Pandémie de #coronavirus: 30 pasteurs améri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>coronavirus COVID__19 COVIDー19</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pand mie de 30 pasteurs ricains qui avaient mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text reply_to_screen_name  \\\n",
       "0  Remember the #WuhanCoronaVirus? The pandemic w...                  NaN   \n",
       "1  My sources @WhiteHouse say 2 tactics will be u...                  NaN   \n",
       "2  I'll venture a wild guess: If you were running...                  NaN   \n",
       "3  #Pakistan (#GreenStimulus = #Nature protection...                  NaN   \n",
       "4  🇺🇸 Pandémie de #coronavirus: 30 pasteurs améri...                  NaN   \n",
       "\n",
       "   is_quote  is_retweet                             hashtags country  \\\n",
       "0         1           1         WuhanCoronaVirus KillerCuomo      us   \n",
       "1         1           1                                Trump      us   \n",
       "2         1           1                              COVID19      us   \n",
       "3         1           1  Pakistan GreenStimulus Nature Green      us   \n",
       "4         1           1       coronavirus COVID__19 COVIDー19      us   \n",
       "\n",
       "   Trump_flag  jfrketich_flag  \\\n",
       "0           0               0   \n",
       "1           0               0   \n",
       "2           0               0   \n",
       "3           0               0   \n",
       "4           0               0   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  remember pandemic great percentage deaths resu...  \n",
       "1  sources say tactics used get america open amp ...  \n",
       "2  venture wild guess running usa crisis youd wan...  \n",
       "3  protection jobs community youth within recentl...  \n",
       "4  pand mie de 30 pasteurs ricains qui avaient mi...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ebb1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "train['sentiment'] = train['clean_tweet'].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a28c8bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>country</th>\n",
       "      <th>Trump_flag</th>\n",
       "      <th>jfrketich_flag</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remember the #WuhanCoronaVirus? The pandemic w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>WuhanCoronaVirus KillerCuomo</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>remember pandemic great percentage deaths resu...</td>\n",
       "      <td>0.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My sources @WhiteHouse say 2 tactics will be u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Trump</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sources say tactics used get america open amp ...</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll venture a wild guess: If you were running...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>COVID19</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>venture wild guess running usa crisis youd wan...</td>\n",
       "      <td>0.22500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Pakistan (#GreenStimulus = #Nature protection...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pakistan GreenStimulus Nature Green</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>protection jobs community youth within recentl...</td>\n",
       "      <td>0.03125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>🇺🇸 Pandémie de #coronavirus: 30 pasteurs améri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>coronavirus COVID__19 COVIDー19</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pand mie de 30 pasteurs ricains qui avaient mi...</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text reply_to_screen_name  \\\n",
       "0  Remember the #WuhanCoronaVirus? The pandemic w...                  NaN   \n",
       "1  My sources @WhiteHouse say 2 tactics will be u...                  NaN   \n",
       "2  I'll venture a wild guess: If you were running...                  NaN   \n",
       "3  #Pakistan (#GreenStimulus = #Nature protection...                  NaN   \n",
       "4  🇺🇸 Pandémie de #coronavirus: 30 pasteurs améri...                  NaN   \n",
       "\n",
       "   is_quote  is_retweet                             hashtags country  \\\n",
       "0         1           1         WuhanCoronaVirus KillerCuomo      us   \n",
       "1         1           1                                Trump      us   \n",
       "2         1           1                              COVID19      us   \n",
       "3         1           1  Pakistan GreenStimulus Nature Green      us   \n",
       "4         1           1       coronavirus COVID__19 COVIDー19      us   \n",
       "\n",
       "   Trump_flag  jfrketich_flag  \\\n",
       "0           0               0   \n",
       "1           0               0   \n",
       "2           0               0   \n",
       "3           0               0   \n",
       "4           0               0   \n",
       "\n",
       "                                         clean_tweet  sentiment  \n",
       "0  remember pandemic great percentage deaths resu...    0.20000  \n",
       "1  sources say tactics used get america open amp ...    0.00000  \n",
       "2  venture wild guess running usa crisis youd wan...    0.22500  \n",
       "3  protection jobs community youth within recentl...    0.03125  \n",
       "4  pand mie de 30 pasteurs ricains qui avaient mi...    0.00000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71c8c69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x = 'sentiment', data = train)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0127b8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96da5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb5ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f5ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd72f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3794b34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffc651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bef08309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                    🇺🇸 Pandémie de #coronavirus: 30 pasteurs améri...\n",
       "reply_to_screen_name                                                  NaN\n",
       "is_quote                                                                1\n",
       "is_retweet                                                              1\n",
       "hashtags                                   coronavirus COVID__19 COVIDー19\n",
       "country                                                                us\n",
       "Trump_flag                                                              0\n",
       "jfrketich_flag                                                          0\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fba0284d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remember the #WuhanCoronaVirus? The pandemic w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My sources @WhiteHouse say 2 tactics will be u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll venture a wild guess: If you were running...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Pakistan (#GreenStimulus = #Nature protection...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>🇺🇸 Pandémie de #coronavirus: 30 pasteurs améri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Remember the #WuhanCoronaVirus? The pandemic w...\n",
       "1  My sources @WhiteHouse say 2 tactics will be u...\n",
       "2  I'll venture a wild guess: If you were running...\n",
       "3  #Pakistan (#GreenStimulus = #Nature protection...\n",
       "4  🇺🇸 Pandémie de #coronavirus: 30 pasteurs améri..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tidytext import unnest_tokens\n",
    "import re\n",
    "\n",
    "A = pd.DataFrame({'text': train['text']})\n",
    "A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d6b3fd81",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9957/2600220654.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^a-zA-Z]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "re.sub('[^a-zA-Z]', ' ', test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "e0b4709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@JoeBiden - This is #Chinese #Propaganda &amp; not true!\n",
      "\n",
      "To refresh ur Dementia Mind, #China LIED, the @WHO LIED &amp; #DrFauci said in January, #USA has nothing to fear with #COVID19! THEN @POTUS finds out it DOES transfer Human-to-Human &amp; immediately BANNED Flights from China Jan. 28!\n",
      "JoeBiden  This is Chinese Propaganda amp not true\n",
      "\n",
      "To refresh ur Dementia Mind China LIED the WHO LIED amp DrFauci said in January USA has nothing to fear with COVID19 THEN POTUS finds out it DOES transfer HumantoHuman amp immediately BANNED Flights from China Jan 28\n"
     ]
    }
   ],
   "source": [
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "test_str = A['text'][543]\n",
    "print(test_str)\n",
    "\n",
    "for ele in test_str:\n",
    "    if ele in punc:\n",
    "        test_str = test_str.replace(ele, '')\n",
    "        \n",
    "print(test_str)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "be90b506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JoeBiden  This is Chinese Propaganda amp not true\n",
      "\n",
      "To refresh ur Dementia Mind China LIED the WHO LIED amp DrFauci said in January USA has nothing to fear with COVID19 THEN POTUS finds out it DOES transfer HumantoHuman amp immediately BANNED Flights from China Jan 28\n"
     ]
    }
   ],
   "source": [
    "test_str = re.sub(r'http\\S+', '', test_str)\n",
    "print(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "21f59391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New list : ['JoeBiden  This is Chinese Propaganda amp not true\\n\\nTo refresh ur Dementia Mind China LIED the WHO LIED amp DrFauci said in January USA has nothing to fear with COVID19 THEN POTUS finds out it DOES transfer HumantoHuman amp immediately BANNED Flights from China Jan 28']\n"
     ]
    }
   ],
   "source": [
    "list1 = [test_str]\n",
    "rez = []\n",
    "\n",
    "for x in list1:\n",
    "    rez.append(x.replace('-', ' '))\n",
    "\n",
    "print(\"New list : \" + str(rez))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "894ab4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New list : ['So I made a memecorona virus meme coronavirusmeme toilet paper coronapocalypse ']\n"
     ]
    }
   ],
   "source": [
    "list1 = [test_str]\n",
    "rez = []\n",
    "\n",
    "for x in list1:\n",
    "    rez.append(x.replace('\\n', ' '))\n",
    "\n",
    "print(\"New list : \" + str(rez))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "df117e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'made memecorona virus meme coronavirusmeme toilet paper coronapocalypse'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "  \n",
    "example_sent = rez\n",
    "  \n",
    "stop_words = set(stopwords.words('english'))\n",
    "others = set([\"1\", \"2\", \"it'll\", \"ill\", \"=\", '+', \"'s'\", '\"'])\n",
    "stop_words = stop_words.union(others)\n",
    "  \n",
    "word_tokens = word_tokenize(example_sent[0])\n",
    "  \n",
    "filtered_sentence = ' '.join([w for w in word_tokens if not w.lower() in stop_words])\n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "89c82d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    if type(tweet) == np.float:\n",
    "        return \"\"\n",
    "    temp = tweet.lower()\n",
    "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(r'http\\S+', '', temp)\n",
    "    temp = re.sub('[()!?]', ' ', temp)\n",
    "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
    "    temp = re.sub(\"[^a-z0-9]\",\" \", temp)\n",
    "    temp = temp.split()\n",
    "#     word_tokens = word_tokenize(temp)\n",
    "    temp = [w for w in temp if not w in stop_words]\n",
    "    temp = \" \".join(word for word in temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "0eeafef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nothing important safety children middle crisis ensure america children safe actionable plan magical thinking'"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = clean_tweet(A['text'][1020])\n",
    "x\n",
    "# [w for w in x if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0300afae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Remember WuhanCoronaVirus pandemic great percentage deaths resulted KillerCuomo ’ nursing home slaughter one quarantined Democrats ’ back rest assured soon riots stop Anything destroy Trump'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = filtered_sentence.replace(\" ' \", \"\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f7a6c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in filtered_sentence:\n",
    "    if ele in \"\\'\":\n",
    "        filtered_sentence = filtered_sentence.replace(ele, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4091e293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Remember WuhanCoronaVirus pandemic great percentage deaths resulted KillerCuomo ’ nursing home slaughter one quarantined Democrats ’ back rest assured soon riots stop Anything destroy Trump'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "632b2667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59b100d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = unnest_tokens(A, 'word', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5268e397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6997814, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81de0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "analyze = vectorizer.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a049acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['remember',\n",
       " 'the',\n",
       " 'wuhancoronavirus',\n",
       " 'the',\n",
       " 'pandemic',\n",
       " 'where',\n",
       " 'great',\n",
       " 'percentage',\n",
       " 'of',\n",
       " 'the',\n",
       " 'deaths',\n",
       " 'resulted',\n",
       " 'from',\n",
       " 'killercuomo',\n",
       " 'nursing',\n",
       " 'home',\n",
       " 'slaughter',\n",
       " 'the',\n",
       " 'one',\n",
       " 'where',\n",
       " 'we',\n",
       " 'were',\n",
       " 'quarantined',\n",
       " 'by',\n",
       " 'democrats',\n",
       " 'it',\n",
       " 'll',\n",
       " 'be',\n",
       " 'back',\n",
       " 'rest',\n",
       " 'assured',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'the',\n",
       " 'riots',\n",
       " 'stop',\n",
       " 'anything',\n",
       " 'to',\n",
       " 'destroy',\n",
       " 'trump']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze(A['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dfa7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc = [A['text'][0], A['text'][1], A['text'][2]]\n",
    "X = vectorizer.fit_transform(Doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1ffa469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278771</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.106006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082323</td>\n",
       "      <td>0.082323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106006</td>\n",
       "      <td>0.278771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108790</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.326370</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108790</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337941</td>\n",
       "      <td>0.084485</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.100406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.100406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264042</td>\n",
       "      <td>0.100406</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.077974</td>\n",
       "      <td>0.077974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.100406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132021</td>\n",
       "      <td>0.264042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.108790  0.143046  0.143046  0.326370  0.143046   \n",
       "2  0.132021  0.132021  0.100406  0.000000  0.000000  0.301217  0.000000   \n",
       "\n",
       "        7         8         9         10        11        12        13   \\\n",
       "0  0.139386  0.000000  0.278771  0.139386  0.139386  0.106006  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.108790  0.000000   \n",
       "2  0.000000  0.132021  0.000000  0.000000  0.000000  0.000000  0.132021   \n",
       "\n",
       "        14        15        16        17        18        19        20   \\\n",
       "0  0.139386  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.143046  0.143046  0.000000  0.108790  0.143046  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.132021  0.100406  0.000000  0.132021   \n",
       "\n",
       "        21        22        23        24        25        26        27   \\\n",
       "0  0.000000  0.139386  0.000000  0.139386  0.000000  0.139386  0.000000   \n",
       "1  0.143046  0.000000  0.143046  0.000000  0.143046  0.000000  0.143046   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        28        29        30        31        32        33        34   \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.139386  0.000000  0.000000   \n",
       "1  0.143046  0.143046  0.000000  0.143046  0.000000  0.000000  0.286092   \n",
       "2  0.000000  0.000000  0.132021  0.000000  0.000000  0.132021  0.000000   \n",
       "\n",
       "        35        36        37        38        39        40        41   \\\n",
       "0  0.139386  0.000000  0.000000  0.139386  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.143046  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.132021  0.000000  0.000000  0.132021  0.132021  0.132021   \n",
       "\n",
       "        42        43        44        45        46        47        48   \\\n",
       "0  0.000000  0.139386  0.000000  0.000000  0.139386  0.000000  0.106006   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.132021  0.000000  0.132021  0.132021  0.000000  0.264042  0.100406   \n",
       "\n",
       "        49   ...       54        55        56        57        58        59   \\\n",
       "0  0.000000  ...  0.106006  0.000000  0.139386  0.000000  0.000000  0.000000   \n",
       "1  0.000000  ...  0.000000  0.143046  0.000000  0.143046  0.143046  0.000000   \n",
       "2  0.132021  ...  0.100406  0.000000  0.000000  0.000000  0.000000  0.132021   \n",
       "\n",
       "        60        61        62        63        64        65        66   \\\n",
       "0  0.000000  0.000000  0.139386  0.139386  0.000000  0.139386  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.143046  0.000000  0.143046   \n",
       "2  0.132021  0.132021  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        67        68        69        70        71        72        73   \\\n",
       "0  0.139386  0.139386  0.139386  0.139386  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.143046  0.000000  0.143046   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.264042  0.000000   \n",
       "\n",
       "        74        75        76        77        78        79        80   \\\n",
       "0  0.000000  0.000000  0.000000  0.139386  0.139386  0.000000  0.139386   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.143046  0.000000   \n",
       "2  0.132021  0.132021  0.132021  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        81        82        83        84        85        86        87   \\\n",
       "0  0.000000  0.530031  0.000000  0.000000  0.082323  0.082323  0.000000   \n",
       "1  0.143046  0.000000  0.143046  0.000000  0.337941  0.084485  0.143046   \n",
       "2  0.000000  0.100406  0.000000  0.132021  0.077974  0.077974  0.000000   \n",
       "\n",
       "        88        89        90        91        92        93        94   \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.139386  0.000000   \n",
       "1  0.000000  0.143046  0.143046  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.264042  0.000000  0.000000  0.132021  0.132021  0.000000  0.132021   \n",
       "\n",
       "        95        96        97        98        99        100       101  \\\n",
       "0  0.106006  0.278771  0.000000  0.000000  0.000000  0.000000  0.139386   \n",
       "1  0.000000  0.000000  0.143046  0.000000  0.143046  0.000000  0.000000   \n",
       "2  0.100406  0.000000  0.000000  0.132021  0.000000  0.264042  0.000000   \n",
       "\n",
       "        102       103  \n",
       "0  0.000000  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.132021  0.264042  \n",
       "\n",
       "[3 rows x 104 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95bb59bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240000, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9fbb0",
   "metadata": {},
   "source": [
    "# Basic Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeebb06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['char_count'] = train['text'].apply(lambda x: count_chars(x))\n",
    "train['word_count'] = train['text'].apply(lambda x: count_words(x))\n",
    "train['sent_count'] = train['text'].apply(lambda x: count_sent(x))\n",
    "train['capital_char_count'] = train['text'].apply(lambda x: count_capital_chars(x))\n",
    "train['capital_word_count'] = train['text'].apply(lambda x: count_capital_words(x))\n",
    "# train['quoted_word_count'] = train['text'].apply(lambda x: count_words_in_quotes(x))\n",
    "train['stopword_count'] = train['text'].apply(lambda x: count_stopwords(x))\n",
    "train['unique_word_count'] = train['text'].apply(lambda x: count_unique_words(x))\n",
    "                                                 \n",
    "test['char_count'] = test['text'].apply(lambda x: count_chars(x))\n",
    "test['word_count'] = test['text'].apply(lambda x: count_words(x))\n",
    "test['sent_count'] = test['text'].apply(lambda x: count_sent(x))\n",
    "test['capital_char_count'] = test['text'].apply(lambda x: count_capital_chars(x))\n",
    "test['capital_word_count'] = test['text'].apply(lambda x: count_capital_words(x))\n",
    "# test['quoted_word_count'] = test['text'].apply(lambda x: count_words_in_quotes(x))\n",
    "test['stopword_count'] = test['text'].apply(lambda x: count_stopwords(x))\n",
    "test['unique_word_count'] = test['text'].apply(lambda x: count_unique_words(x))\n",
    "                                                 \n",
    "## Average word length\n",
    "train['avg_wordlength'] = train['char_count'] / train['word_count']\n",
    "test['avg_wordlength'] = test['char_count'] / test['word_count']\n",
    "\n",
    "## Average sentence lenght\n",
    "train['avg_sentlength'] = train['word_count'] / train['sent_count']\n",
    "test['avg_sentlength'] = test['word_count'] / test['sent_count']\n",
    "\n",
    "## Unique words vs count words\n",
    "train['unique_vs_words'] = train['unique_word_count'] / train['word_count']\n",
    "test['unique_vs_words'] = test['unique_word_count'] / test['word_count']\n",
    "\n",
    "## stopwords vs count words\n",
    "train['stopwords_vs_words'] = train['stopword_count'] / train['word_count']\n",
    "test['stopwords_vs_words'] = test['stopword_count'] / test['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abba12de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index = False)\n",
    "test.to_csv('test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6660c71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Category\n",
       "0   0         4\n",
       "1   1         5\n",
       "2   2         5\n",
       "3   3         4\n",
       "4   4         5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Defining input and target\n",
    "X = train.drop(columns = ['text', 'reply_to_screen_name', 'hashtags', 'country'], axis = 1)\n",
    "Y = train['country']\n",
    "Y = np.where(Y == 'us', 0, \n",
    "             np.where(Y == 'uk', 1, \n",
    "                      np.where(Y == 'canada', 2, \n",
    "                               np.where(Y == 'australia', 3,\n",
    "                                        np.where(Y == 'ireland', 4, 5)))))\n",
    "\n",
    "test_id = test['Id']\n",
    "test = test.drop(columns = ['Id', 'text', 'reply_to_screen_name', 'hashtags'], axis = 1)\n",
    "\n",
    "## Splitting the data \n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "\n",
    "## Building the multi-classifier (using RF) \n",
    "one_vs_all_RF = OneVsRestClassifier(estimator = RandomForestClassifier(n_estimators = 500, max_depth = 9)).fit(X, Y)\n",
    "\n",
    "## Predicting on the test\n",
    "one_vs_all_RF_pred = one_vs_all_RF.predict_proba(test)\n",
    "one_vs_all_RF_pred = np.argmax(one_vs_all_RF_pred, axis = 1)\n",
    "\n",
    "data_out = pd.DataFrame({'Id': test_id, 'Category': one_vs_all_RF_pred})\n",
    "data_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b0d402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out['Category'] = np.where(data_out['Category'] == 0, 'us',\n",
    "                                np.where(data_out['Category'] == 1, 'uk',\n",
    "                                         np.where(data_out['Category'] == 2, 'canada',\n",
    "                                                  np.where(data_out['Category'] == 3, 'australia',\n",
    "                                                           np.where(data_out['Category'] == 4, 'ireland', 'new_zealand')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eaf89fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>new_zealand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>new_zealand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>new_zealand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id     Category\n",
       "0   0      ireland\n",
       "1   1  new_zealand\n",
       "2   2  new_zealand\n",
       "3   3      ireland\n",
       "4   4  new_zealand"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98b544b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out.to_csv('RF_submission_4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a036bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "us             40000\n",
       "uk             40000\n",
       "canada         40000\n",
       "australia      40000\n",
       "ireland        40000\n",
       "new_zealand    40000\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c303abb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>country</th>\n",
       "      <th>Trump_flag</th>\n",
       "      <th>jfrketich_flag</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_char_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>avg_sentlength</th>\n",
       "      <th>unique_vs_words</th>\n",
       "      <th>stopwords_vs_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remember the #WuhanCoronaVirus? The pandemic w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>WuhanCoronaVirus KillerCuomo</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "      <td>6.512195</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.414634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My sources @WhiteHouse say 2 tactics will be u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Trump</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>5.854167</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.229167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll venture a wild guess: If you were running...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>COVID19</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>5.840000</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Pakistan (#GreenStimulus = #Nature protection...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pakistan GreenStimulus Nature Green</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>7.612903</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>🇺🇸 Pandémie de #coronavirus: 30 pasteurs améri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>coronavirus COVID__19 COVIDー19</td>\n",
       "      <td>us</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>7.971429</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text reply_to_screen_name  \\\n",
       "0  Remember the #WuhanCoronaVirus? The pandemic w...                  NaN   \n",
       "1  My sources @WhiteHouse say 2 tactics will be u...                  NaN   \n",
       "2  I'll venture a wild guess: If you were running...                  NaN   \n",
       "3  #Pakistan (#GreenStimulus = #Nature protection...                  NaN   \n",
       "4  🇺🇸 Pandémie de #coronavirus: 30 pasteurs améri...                  NaN   \n",
       "\n",
       "   is_quote  is_retweet                             hashtags country  \\\n",
       "0         1           1         WuhanCoronaVirus KillerCuomo      us   \n",
       "1         1           1                                Trump      us   \n",
       "2         1           1                              COVID19      us   \n",
       "3         1           1  Pakistan GreenStimulus Nature Green      us   \n",
       "4         1           1       coronavirus COVID__19 COVIDー19      us   \n",
       "\n",
       "   Trump_flag  jfrketich_flag  char_count  word_count  sent_count  \\\n",
       "0           0               0         267          41           5   \n",
       "1           0               0         281          48           6   \n",
       "2           0               0         292          50           3   \n",
       "3           0               0         236          31           1   \n",
       "4           0               0         279          35           3   \n",
       "\n",
       "   capital_char_count  capital_word_count  stopword_count  unique_word_count  \\\n",
       "0                  12                   0              17                 36   \n",
       "1                  22                   2              11                 42   \n",
       "2                  20                   3              16                 44   \n",
       "3                  23                   1               8                 30   \n",
       "4                  18                   2               2                 35   \n",
       "\n",
       "   avg_wordlength  avg_sentlength  unique_vs_words  stopwords_vs_words  \n",
       "0        6.512195        8.200000         0.878049            0.414634  \n",
       "1        5.854167        8.000000         0.875000            0.229167  \n",
       "2        5.840000       16.666667         0.880000            0.320000  \n",
       "3        7.612903       31.000000         0.967742            0.258065  \n",
       "4        7.971429       11.666667         1.000000            0.057143  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d2bb706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COVID19                        58516\n",
       "coronavirus                    13002\n",
       "Covid19                         8020\n",
       "COVID                           4649\n",
       "covid19                         4578\n",
       "                               ...  \n",
       "covid19 Lockdown                   1\n",
       "NCAAFootball coronavirus           1\n",
       "Liverpool Covid19 JustsayNO        1\n",
       "coronavirus DYK                    1\n",
       "Covid_19 HopeAlive                 1\n",
       "Name: hashtags, Length: 80149, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['hashtags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac0b9577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "realDonaldTrump    497\n",
       "jfrketich          129\n",
       "NYGovCuomo          72\n",
       "BorisJohnson        70\n",
       "InfoInterest        47\n",
       "                  ... \n",
       "SNC_GC               1\n",
       "starwars             1\n",
       "UniofOxford          1\n",
       "OPHA_Ontario         1\n",
       "SoonerReporter       1\n",
       "Name: reply_to_screen_name, Length: 7943, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['reply_to_screen_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af8ab301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "realDonaldTrump    112\n",
       "jfrketich           26\n",
       "paddypower          19\n",
       "BdaGovernment       16\n",
       "LukePField          15\n",
       "                  ... \n",
       "FarleyMedia          1\n",
       "pmagn                1\n",
       "CllrIanSherwood      1\n",
       "OprosUK              1\n",
       "SqueezeJuice         1\n",
       "Name: reply_to_screen_name, Length: 2418, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['reply_to_screen_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "20dc8b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test['reply_to_screen_name'].unique() == 'InfoInterest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66f9ebe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    150205\n",
       "0     89795\n",
       "Name: is_quote, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['is_quote'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a8d274b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    205896\n",
       "0     34104\n",
       "Name: is_retweet, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['is_retweet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ed23af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "us             40000\n",
       "uk             40000\n",
       "canada         40000\n",
       "australia      40000\n",
       "ireland        40000\n",
       "new_zealand    40000\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c2a16e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False               109482\n",
       "FALSE                89795\n",
       "True                 21590\n",
       "TRUE                 19132\n",
       "Colin o'donoghue         1\n",
       "Name: is_quote, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['is_quote'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d76c822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train['is_quote'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cd52682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162661</th>\n",
       "      <td>0</td>\n",
       "      <td>NYCTogether</td>\n",
       "      <td>Colin o'donoghue</td>\n",
       "      <td>ireland</td>\n",
       "      <td>1498</td>\n",
       "      <td>ireland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text reply_to_screen_name          is_quote is_retweet hashtags  \\\n",
       "162661    0          NYCTogether  Colin o'donoghue    ireland     1498   \n",
       "\n",
       "        country  \n",
       "162661  ireland  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['is_quote'] == \"Colin o'donoghue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ddc825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240000, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6cdfb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ethical investing is not optional anymore, say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>covid19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#COVID19 | Suite à la conférence de presse du ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>COVID19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yesterday, I had a live discussion with @Steve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>COVID19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nepal - #Coronavirus cases up 24% in a week. D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American economy jumped up a %  big news story...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>LysolAndCloroxSales</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text reply_to_screen_name  \\\n",
       "0  Ethical investing is not optional anymore, say...                  NaN   \n",
       "1  #COVID19 | Suite à la conférence de presse du ...                  NaN   \n",
       "2  Yesterday, I had a live discussion with @Steve...                  NaN   \n",
       "3  Nepal - #Coronavirus cases up 24% in a week. D...                  NaN   \n",
       "4  American economy jumped up a %  big news story...                  NaN   \n",
       "\n",
       "   is_quote  is_retweet             hashtags  Id  \n",
       "0     False       False              covid19   0  \n",
       "1     False        True              COVID19   1  \n",
       "2     False        True              COVID19   2  \n",
       "3     False        True          Coronavirus   3  \n",
       "4     False       False  LysolAndCloroxSales   4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9829070e",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "098881af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_quote'] = train['is_quote'].str.lower()\n",
    "train['is_quote'] = np.where(train['is_quote'] == 'false', 0, 1)\n",
    "\n",
    "test['is_quote'] = np.where(test['is_quote'] == False, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5e48554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True       87067\n",
       "TRUE       74823\n",
       "False      44005\n",
       "FALSE      34104\n",
       "ireland        1\n",
       "Name: is_retweet, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['is_retweet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04281aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162661</th>\n",
       "      <td>0</td>\n",
       "      <td>NYCTogether</td>\n",
       "      <td>1</td>\n",
       "      <td>ireland</td>\n",
       "      <td>1498</td>\n",
       "      <td>ireland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text reply_to_screen_name  is_quote is_retweet hashtags  country\n",
       "162661    0          NYCTogether         1    ireland     1498  ireland"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['is_retweet'] == 'ireland']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2b62b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     40284\n",
       "False    19716\n",
       "Name: is_retweet, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['is_retweet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08b4d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235cd14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec713614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "500f3767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from lightgbm) (0.37.0)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from lightgbm) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from lightgbm) (1.0.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from lightgbm) (1.20.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.0.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.2\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d76313ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.376 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.374 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.363 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.363 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.377 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.365 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.356 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.368 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.370 total time=  59.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.371 total time=  58.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.357 total time=  56.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.374 total time=  55.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.376 total time=  55.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.375 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.375 total time=  59.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.376 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.377 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.377 total time=  58.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.356 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.367 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.366 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.357 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.368 total time=  59.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.375 total time=  56.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.374 total time=  56.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.375 total time=  55.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.376 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.375 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.377 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.381 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.363 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.366 total time=  59.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.366 total time=  59.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.367 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.373 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.370 total time=  59.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.374 total time=  54.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.357 total time=  56.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.374 total time=  55.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.374 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.375 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.374 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.379 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.379 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.366 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.366 total time=  59.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.368 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.355 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.357 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.374 total time=  54.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.375 total time=  54.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.374 total time=  55.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.358 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.358 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.375 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.364 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.378 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.367 total time=  59.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.364 total time=  59.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.355 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.371 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.373 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.373 total time=  54.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.374 total time=  53.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.362 total time=  59.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.357 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.357 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.376 total time=  60.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.378 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.375 total time=  59.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.366 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.367 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.367 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.373 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.373 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.357 total time=  56.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.373 total time=  53.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.377 total time=  57.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.376 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.374 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.378 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.379 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.381 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.356 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.356 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.368 total time=  59.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.369 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.373 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.376 total time=  57.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.373 total time=  54.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.376 total time=  57.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.374 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.375 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.377 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.378 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.01, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.379 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 2/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.368 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=20;, score=0.367 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.370 total time=  59.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 5/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.373 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.001, max_depth=7, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.371 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 3/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=15, n_estimators=300, num_leaves=30;, score=0.375 total time=  55.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 1/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=5, min_data_in_leaf=20, n_estimators=300, num_leaves=30;, score=0.356 total time=  55.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[CV 4/5] END feature_fraction=0.8, lambda_l1=0, lambda_l2=10, learning_rate=0.01, max_depth=7, min_data_in_leaf=15, n_estimators=300, num_leaves=20;, score=0.376 total time=  58.8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15137/155368581.py\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m## Performing grid search with 5 folds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mLightGBM_grid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLightGBM_param_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m## Extracting best hyper-parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "## Defining input and target\n",
    "X = train.drop(columns = ['text', 'reply_to_screen_name', 'hashtags', 'country'], axis = 1)\n",
    "Y = train['country']\n",
    "Y = np.where(Y == 'us', 0, \n",
    "             np.where(Y == 'uk', 1, \n",
    "                      np.where(Y == 'canada', 2, \n",
    "                               np.where(Y == 'australia', 3,\n",
    "                                        np.where(Y == 'ireland', 4, 5)))))\n",
    "\n",
    "## Defining the hyper-parameter grid\n",
    "LightGBM_param_grid = {'n_estimators': [300],\n",
    "                       'max_depth': [5, 7],\n",
    "                       'num_leaves': [20, 30],\n",
    "                       'min_data_in_leaf': [15, 20],\n",
    "                       'learning_rate': [0.01, 0.001],\n",
    "                       'feature_fraction': [0.8, 1],\n",
    "                       'lambda_l1': [0, 10],\n",
    "                       'lambda_l2': [0, 10]\n",
    "                      }\n",
    "\n",
    "## Performing grid search with 5 folds\n",
    "LightGBM_grid_search = GridSearchCV(LGBMClassifier(), LightGBM_param_grid, cv = 5, scoring = 'accuracy', n_jobs = -1, verbose = 3).fit(X, Y)\n",
    "\n",
    "## Extracting best hyper-parameters\n",
    "best_params = LightGBM_grid_search.best_params_\n",
    "print('The best hyper-parameters are:', best_params)\n",
    "\n",
    "## Extracting the best score\n",
    "best_score = LightGBM_grid_search.best_score_\n",
    "print('The best accuracy is:', best_score)\n",
    "\n",
    "## Extracting the best model\n",
    "LightGBM_md = LightGBM_grid_search.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
