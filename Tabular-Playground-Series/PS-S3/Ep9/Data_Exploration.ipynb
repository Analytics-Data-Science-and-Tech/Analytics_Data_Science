{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd7737f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: xgboost in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.7.4)\n",
      "Requirement already satisfied: lightgbm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (3.3.5)\n",
      "Requirement already satisfied: catboost in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: optuna in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.22.3)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lightgbm) (1.2.0)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lightgbm) (0.38.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (1.5.2)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (3.6.2)\n",
      "Requirement already satisfied: graphviz in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: plotly in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (5.11.0)\n",
      "Requirement already satisfied: colorlog in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (4.64.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (1.4.46)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (0.9.1)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (1.10.2)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.4.0)\n",
      "Requirement already satisfied: Mako in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=0.24.0->catboost) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (4.38.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from plotly->catboost) (8.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost lightgbm catboost optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9911ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functools import partial\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, HistGradientBoostingClassifier, HistGradientBoostingRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor \n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "import optuna \n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Series/PS-S3/Ep9/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Series/PS-S3/Ep9/test.csv'\n",
    "file_key_3 = 'Tabular-Playground-Series/PS-S3/Ep9/sample_submission.csv'\n",
    "file_key_4 = 'Tabular-Playground-Series/PS-S3/Ep9/ConcreteStrengthData.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "bucket_object_3 = bucket.Object(file_key_3)\n",
    "file_object_3 = bucket_object_3.get()\n",
    "file_content_stream_3 = file_object_3.get('Body')\n",
    "\n",
    "bucket_object_4 = bucket.Object(file_key_4)\n",
    "file_object_4 = bucket_object_4.get()\n",
    "file_content_stream_4 = file_object_4.get('Body')\n",
    "\n",
    "## Reading data files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "submission = pd.read_csv(file_content_stream_3)\n",
    "# original = pd.read_csv(file_content_stream_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d8f08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CementComponent</th>\n",
       "      <th>BlastFurnaceSlag</th>\n",
       "      <th>FlyAshComponent</th>\n",
       "      <th>WaterComponent</th>\n",
       "      <th>SuperplasticizerComponent</th>\n",
       "      <th>CoarseAggregateComponent</th>\n",
       "      <th>FineAggregateComponent</th>\n",
       "      <th>AgeInDays</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CementComponent   BlastFurnaceSlag  FlyAshComponent  WaterComponent  \\\n",
       "0             540.0               0.0              0.0           162.0   \n",
       "1             540.0               0.0              0.0           162.0   \n",
       "2             332.5             142.5              0.0           228.0   \n",
       "3             332.5             142.5              0.0           228.0   \n",
       "4             198.6             132.4              0.0           192.0   \n",
       "\n",
       "   SuperplasticizerComponent  CoarseAggregateComponent  \\\n",
       "0                        2.5                    1040.0   \n",
       "1                        2.5                    1055.0   \n",
       "2                        0.0                     932.0   \n",
       "3                        0.0                     932.0   \n",
       "4                        0.0                     978.4   \n",
       "\n",
       "   FineAggregateComponent  AgeInDays  Strength  \n",
       "0                   676.0         28     79.99  \n",
       "1                   676.0         28     61.89  \n",
       "2                   594.0        270     40.27  \n",
       "3                   594.0        365     41.05  \n",
       "4                   825.5        360     44.30  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c8f1455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5407</td>\n",
       "      <td>45.994091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5408</td>\n",
       "      <td>19.986377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5409</td>\n",
       "      <td>37.940664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5410</td>\n",
       "      <td>45.994091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>37.940664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5412</td>\n",
       "      <td>37.940664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5413</td>\n",
       "      <td>37.940664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5414</td>\n",
       "      <td>19.986377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5415</td>\n",
       "      <td>38.263170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5416</td>\n",
       "      <td>45.994091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   Strength\n",
       "0  5407  45.994091\n",
       "1  5408  19.986377\n",
       "2  5409  37.940664\n",
       "3  5410  45.994091\n",
       "4  5411  37.940664\n",
       "5  5412  37.940664\n",
       "6  5413  37.940664\n",
       "7  5414  19.986377\n",
       "8  5415  38.263170\n",
       "9  5416  45.994091"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "# X['Coarse_Fine'] = X['CoarseAggregateComponent'] / X['FineAggregateComponent']\n",
    "# X['Aggregate'] = X['CoarseAggregateComponent'] + X['FineAggregateComponent']\n",
    "# X['Slag_Cement'] = X['BlastFurnaceSlag'] / X['CementComponent']\n",
    "# X['Ash_Cement'] = X['FlyAshComponent'] / X['CementComponent']\n",
    "# X['Plastic_Cement'] = X['SuperplasticizerComponent'] / X['CementComponent']\n",
    "# X['Age_Water'] = X['AgeInDays'] / X['WaterComponent']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "# test_baseline['Coarse_Fine'] = test_baseline['CoarseAggregateComponent'] / test_baseline['FineAggregateComponent']\n",
    "# test_baseline['Aggregate'] = test_baseline['CoarseAggregateComponent'] + test_baseline['FineAggregateComponent']\n",
    "# test_baseline['Slag_Cement'] = test_baseline['BlastFurnaceSlag'] / test_baseline['CementComponent']\n",
    "# test_baseline['Ash_Cement'] = test_baseline['FlyAshComponent'] / test_baseline['CementComponent']\n",
    "# test_baseline['Plastic_Cement'] = test_baseline['SuperplasticizerComponent'] / test_baseline['CementComponent']\n",
    "# test_baseline['Age_Water'] = test_baseline['AgeInDays'] / test_baseline['WaterComponent']\n",
    "\n",
    "RF_md = RandomForestRegressor(n_estimators = 1000, \n",
    "                              max_depth = 2,\n",
    "                              min_samples_split = 2,\n",
    "                              min_samples_leaf = 2).fit(X, Y)\n",
    "\n",
    "RF_pred = RF_md.predict(test_baseline)\n",
    "submission['Strength'] = RF_pred\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b49455e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5407</td>\n",
       "      <td>47.553146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5408</td>\n",
       "      <td>20.643961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5409</td>\n",
       "      <td>34.345400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5410</td>\n",
       "      <td>47.061130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>30.996661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5412</td>\n",
       "      <td>40.067030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5413</td>\n",
       "      <td>32.971328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5414</td>\n",
       "      <td>23.452455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5415</td>\n",
       "      <td>45.756085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5416</td>\n",
       "      <td>40.705450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   Strength\n",
       "0  5407  47.553146\n",
       "1  5408  20.643961\n",
       "2  5409  34.345400\n",
       "3  5410  47.061130\n",
       "4  5411  30.996661\n",
       "5  5412  40.067030\n",
       "6  5413  32.971328\n",
       "7  5414  23.452455\n",
       "8  5415  45.756085\n",
       "9  5416  40.705450"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "# X['Coarse_Fine'] = X['CoarseAggregateComponent'] / X['FineAggregateComponent']\n",
    "# X['Aggregate'] = X['CoarseAggregateComponent'] + X['FineAggregateComponent']\n",
    "# X['Slag_Cement'] = X['BlastFurnaceSlag'] / X['CementComponent']\n",
    "# X['Ash_Cement'] = X['FlyAshComponent'] / X['CementComponent']\n",
    "# X['Plastic_Cement'] = X['SuperplasticizerComponent'] / X['CementComponent']\n",
    "# X['Age_Water'] = X['AgeInDays'] / X['WaterComponent']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "# test_baseline['Coarse_Fine'] = test_baseline['CoarseAggregateComponent'] / test_baseline['FineAggregateComponent']\n",
    "# test_baseline['Aggregate'] = test_baseline['CoarseAggregateComponent'] + test_baseline['FineAggregateComponent']\n",
    "# test_baseline['Slag_Cement'] = test_baseline['BlastFurnaceSlag'] / test_baseline['CementComponent']\n",
    "# test_baseline['Ash_Cement'] = test_baseline['FlyAshComponent'] / test_baseline['CementComponent']\n",
    "# test_baseline['Plastic_Cement'] = test_baseline['SuperplasticizerComponent'] / test_baseline['CementComponent']\n",
    "# test_baseline['Age_Water'] = test_baseline['AgeInDays'] / test_baseline['WaterComponent']\n",
    "\n",
    "GBR_md = GradientBoostingRegressor(n_estimators = 1000,\n",
    "                                   learning_rate = 0.01,\n",
    "                                   max_depth = 2,\n",
    "                                   min_samples_split = 2,\n",
    "                                   min_samples_leaf = 2).fit(X, Y)\n",
    "\n",
    "GBR_pred = GBR_md.predict(test_baseline)\n",
    "submission['Strength'] = GBR_pred\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff0b0596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5407</td>\n",
       "      <td>47.634815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5408</td>\n",
       "      <td>20.584157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5409</td>\n",
       "      <td>34.306373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5410</td>\n",
       "      <td>47.065304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>31.262939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5412</td>\n",
       "      <td>39.992028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5413</td>\n",
       "      <td>33.404359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5414</td>\n",
       "      <td>23.408216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5415</td>\n",
       "      <td>45.831811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5416</td>\n",
       "      <td>40.655497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   Strength\n",
       "0  5407  47.634815\n",
       "1  5408  20.584157\n",
       "2  5409  34.306373\n",
       "3  5410  47.065304\n",
       "4  5411  31.262939\n",
       "5  5412  39.992028\n",
       "6  5413  33.404359\n",
       "7  5414  23.408216\n",
       "8  5415  45.831811\n",
       "9  5416  40.655497"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "\n",
    "hist_md = HistGradientBoostingRegressor(l2_regularization = 0.01,\n",
    "                                        early_stopping = False,\n",
    "                                        learning_rate = 0.01,\n",
    "                                        max_iter = 1000,\n",
    "                                        max_depth = 2,\n",
    "                                        max_bins = 255,\n",
    "                                        min_samples_leaf = 10,\n",
    "                                        max_leaf_nodes = 10).fit(X, Y)\n",
    "\n",
    "hist_pred = hist_md.predict(test_baseline)\n",
    "submission['Strength'] = hist_pred\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7feb1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5407</td>\n",
       "      <td>47.464255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5408</td>\n",
       "      <td>21.118209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5409</td>\n",
       "      <td>34.147588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5410</td>\n",
       "      <td>46.626609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>31.670514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5412</td>\n",
       "      <td>40.013022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5413</td>\n",
       "      <td>34.257994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5414</td>\n",
       "      <td>23.323489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5415</td>\n",
       "      <td>43.876265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5416</td>\n",
       "      <td>40.875875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   Strength\n",
       "0  5407  47.464255\n",
       "1  5408  21.118209\n",
       "2  5409  34.147588\n",
       "3  5410  46.626609\n",
       "4  5411  31.670514\n",
       "5  5412  40.013022\n",
       "6  5413  34.257994\n",
       "7  5414  23.323489\n",
       "8  5415  43.876265\n",
       "9  5416  40.875875"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "\n",
    "lgb_md = LGBMRegressor(n_estimators = 1000,\n",
    "                       max_depth = 2,\n",
    "                       learning_rate = 0.01,\n",
    "                       num_leaves = 20,\n",
    "                       lambda_l1 = 3,\n",
    "                       lambda_l2 = 3,\n",
    "                       bagging_fraction = 0.7,\n",
    "                       feature_fraction = 0.7).fit(X, Y)\n",
    "\n",
    "lgb_pred = lgb_md.predict(test_baseline)\n",
    "submission['Strength'] = lgb_pred\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f648c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lgb_full_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b144c228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5407</td>\n",
       "      <td>47.530796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5408</td>\n",
       "      <td>20.616440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5409</td>\n",
       "      <td>33.766331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5410</td>\n",
       "      <td>46.767071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>33.138821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5412</td>\n",
       "      <td>39.776501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5413</td>\n",
       "      <td>33.750774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5414</td>\n",
       "      <td>23.091179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5415</td>\n",
       "      <td>44.752090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5416</td>\n",
       "      <td>40.118263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   Strength\n",
       "0  5407  47.530796\n",
       "1  5408  20.616440\n",
       "2  5409  33.766331\n",
       "3  5410  46.767071\n",
       "4  5411  33.138821\n",
       "5  5412  39.776501\n",
       "6  5413  33.750774\n",
       "7  5414  23.091179\n",
       "8  5415  44.752090\n",
       "9  5416  40.118263"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "\n",
    "XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "                      colsample_bytree = 0.7, \n",
    "                      gamma = 0.8, \n",
    "                      learning_rate = 0.01, \n",
    "                      max_depth = 2, \n",
    "                      min_child_weight = 10, \n",
    "                      n_estimators = 1000, \n",
    "                      subsample = 0.7).fit(X, Y)\n",
    "\n",
    "xgb_pred = XGB_md.predict(test_baseline)\n",
    "submission['Strength'] = xgb_pred\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb8ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('xgb_full_submission_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54cd868c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5407</td>\n",
       "      <td>47.949070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5408</td>\n",
       "      <td>19.403589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5409</td>\n",
       "      <td>33.624952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5410</td>\n",
       "      <td>46.432587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>32.492635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5412</td>\n",
       "      <td>39.267866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5413</td>\n",
       "      <td>33.497860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5414</td>\n",
       "      <td>22.609580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5415</td>\n",
       "      <td>45.708015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5416</td>\n",
       "      <td>39.930590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   Strength\n",
       "0  5407  47.949070\n",
       "1  5408  19.403589\n",
       "2  5409  33.624952\n",
       "3  5410  46.432587\n",
       "4  5411  32.492635\n",
       "5  5412  39.267866\n",
       "6  5413  33.497860\n",
       "7  5414  22.609580\n",
       "8  5415  45.708015\n",
       "9  5416  39.930590"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "# X['Coarse_Fine'] = X['CoarseAggregateComponent'] / X['FineAggregateComponent']\n",
    "# X['Aggregate'] = X['CoarseAggregateComponent'] + X['FineAggregateComponent']\n",
    "# X['Slag_Cement'] = X['BlastFurnaceSlag'] / X['CementComponent']\n",
    "# X['Ash_Cement'] = X['FlyAshComponent'] / X['CementComponent']\n",
    "# X['Plastic_Cement'] = X['SuperplasticizerComponent'] / X['CementComponent']\n",
    "# X['Age_Water'] = X['AgeInDays'] / X['WaterComponent']\n",
    "\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "# test_baseline['Coarse_Fine'] = test_baseline['CoarseAggregateComponent'] / test_baseline['FineAggregateComponent']\n",
    "# test_baseline['Aggregate'] = test_baseline['CoarseAggregateComponent'] + test_baseline['FineAggregateComponent']\n",
    "# test_baseline['Slag_Cement'] = test_baseline['BlastFurnaceSlag'] / test_baseline['CementComponent']\n",
    "# test_baseline['Ash_Cement'] = test_baseline['FlyAshComponent'] / test_baseline['CementComponent']\n",
    "# test_baseline['Plastic_Cement'] = test_baseline['SuperplasticizerComponent'] / test_baseline['CementComponent']\n",
    "# test_baseline['Age_Water'] = test_baseline['AgeInDays'] / test_baseline['WaterComponent']\n",
    "\n",
    "\n",
    "cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                           iterations = 1000,\n",
    "                           learning_rate = 0.01,\n",
    "                           depth = 3,\n",
    "                           random_strength = 0.5,\n",
    "                           bagging_temperature = 0.7,\n",
    "                           border_count = 30,\n",
    "                           l2_leaf_reg = 5,\n",
    "                           verbose = False).fit(X, Y)\n",
    "\n",
    "cat_pred = cat_md.predict(test_baseline)\n",
    "submission['Strength'] = cat_pred\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb8cc65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('catboost_full_submission_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15faad20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5407</td>\n",
       "      <td>47.666957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5408</td>\n",
       "      <td>20.312037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5409</td>\n",
       "      <td>34.010764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5410</td>\n",
       "      <td>46.831523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>31.972764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   Strength\n",
       "0  5407  47.666957\n",
       "1  5408  20.312037\n",
       "2  5409  34.010764\n",
       "3  5410  46.831523\n",
       "4  5411  31.972764"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['Strength'] = (cat_pred + xgb_pred + hist_pred + GBR_pred) / 4\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "522df59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('catboost_xgb_hist_GBR_full_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60dbc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5600373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "\n",
    "preds_train, preds_test = list(), list()\n",
    "\n",
    "for i in tqdm(range(0, 1000)):\n",
    "    \n",
    "    CatBoostRegressor(loss_function = 'RMSE',\n",
    "                           iterations = 1000,\n",
    "                           learning_rate = 0.01,\n",
    "                           depth = 3,\n",
    "                           random_strength = 0.5,\n",
    "                           bagging_temperature = 0.7,\n",
    "                           border_count = 30,\n",
    "                           l2_leaf_reg = 5,\n",
    "                           verbose = False, \n",
    "                           random_seed = i).fit(X, Y)\n",
    "    \n",
    "#     cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "#                                iterations = 1756,\n",
    "#                                learning_rate = 0.017975994415651907,\n",
    "#                                depth = 3,\n",
    "#                                random_strength = 2.8219170899365174,\n",
    "#                                bagging_temperature = 0.19623966374044916,\n",
    "#                                border_count = 70,\n",
    "#                                l2_leaf_reg = 29,\n",
    "#                                verbose = False,\n",
    "#                                random_seed = i).fit(X, Y)\n",
    "    \n",
    "    preds_train.append(cat_md.predict(X))\n",
    "    preds_test.append(cat_md.predict(test_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25c65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_preds_test = pd.DataFrame(preds_test).apply(np.mean, axis = 0)\n",
    "\n",
    "submission['Strength'] = cat_preds_test\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d70fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('catboost_full_1000_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26cb410",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedEnsemble(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _rmse_loss(self, coef, X, y):\n",
    "        \n",
    "        n = X.shape[1]\n",
    "        ens = 0\n",
    "        for i in range(0, n):\n",
    "            ens += coef[i]*X[:, i]\n",
    "        \n",
    "        ll = mean_squared_error(y, ens, squared = False)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._rmse_loss, X = X, y = y)\n",
    "        n = X.shape[1]\n",
    "        initial_coef = np.repeat(1/n, n)\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method = 'nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        \n",
    "        n = X.shape[1]\n",
    "        ens = 0\n",
    "        for i in range(0, n):\n",
    "            ens += coef[i]*X[:, i]\n",
    "        return ens\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c71891",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pred_train = np.array(pd.DataFrame(preds_train).T)\n",
    "models_pred_oof = np.array(pd.DataFrame(preds_test).T)\n",
    "\n",
    "# n = models_pred_oof.shape[1]\n",
    "# ens = 0\n",
    "# for i in range(0, n):\n",
    "#     ens += models_pred_oof[:, i]\n",
    "\n",
    "opt_ens = OptimizedEnsemble()\n",
    "opt_ens.fit(models_pred_train, Y)\n",
    "coef = opt_ens.coefficients()\n",
    "ens_pred_train = opt_ens.predict(models_pred_train, coef)\n",
    "ens_pred_test = opt_ens.predict(models_pred_oof, coef)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e4f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(Y, ens_pred_train, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be83706",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256cc116",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Strength'] = ens_pred_test\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f416fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('catboost_full_50_opt_ens_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9cf802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70c212b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419d5356",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(pd.DataFrame(preds).T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9bd654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56c89ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "XGB_cv_scores, XGB_imp = list(), list()\n",
    "XGB_preds = list()\n",
    "\n",
    "lgb_cv_scores, lgb_imp = list(), list()\n",
    "lgb_preds = list()\n",
    "\n",
    "cat_cv_scores, cat_imp = list(), list()\n",
    "cat_preds = list()\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    skf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############    \n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "        XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "                              colsample_bytree = 0.7, \n",
    "                              gamma = 0.8, \n",
    "                              learning_rate = 0.01, \n",
    "                              max_depth = 7, \n",
    "                              min_child_weight = 10, \n",
    "                              n_estimators = 1000, \n",
    "                              subsample = 0.7).fit(X_train, Y_train)\n",
    "        XGB_imp.append(XGB_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        XGB_pred_1 = XGB_md.predict(X_test)\n",
    "        XGB_pred_2 = XGB_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        XGB_cv_scores.append(mean_squared_error(Y_test, XGB_pred_1, squared = False))\n",
    "        XGB_preds.append(XGB_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## LightGBM ##\n",
    "        ##############\n",
    "        \n",
    "        lgb_md = LGBMRegressor(n_estimators = 1000,\n",
    "                               max_depth = 7,\n",
    "                               learning_rate = 0.01,\n",
    "                               num_leaves = 20,\n",
    "                               lambda_l1 = 3,\n",
    "                               lambda_l2 = 3,\n",
    "                               bagging_fraction = 0.7,\n",
    "                               feature_fraction = 0.7).fit(X_train, Y_train)\n",
    "        lgb_imp.append(lgb_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        lgb_pred_1 = lgb_md.predict(X_test)\n",
    "        lgb_pred_2 = lgb_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        lgb_cv_scores.append(mean_squared_error(Y_test, lgb_pred_1, squared = False))\n",
    "        lgb_preds.append(lgb_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## CatBoost ##\n",
    "        ##############\n",
    "        \n",
    "        cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                                   iterations = 1000,\n",
    "                                   learning_rate = 0.01,\n",
    "                                   depth = 7,\n",
    "                                   random_strength = 0.5,\n",
    "                                   bagging_temperature = 0.7,\n",
    "                                   border_count = 30,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   verbose = False).fit(X_train, Y_train)\n",
    "        cat_imp.append(cat_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        cat_pred_1 = cat_md.predict(X_test)\n",
    "        cat_pred_2 = cat_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        cat_cv_scores.append(mean_squared_error(Y_test, cat_pred_1, squared = False))\n",
    "        cat_preds.append(cat_pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ef57e",
   "metadata": {},
   "source": [
    "# Baseline Modeling 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f24ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns = ['id', 'Strength'], axis = 1)\n",
    "Y = train['Strength']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "XGB_cv_scores, XGB_imp = list(), list()\n",
    "XGB_preds = list()\n",
    "\n",
    "lgb_cv_scores, lgb_imp = list(), list()\n",
    "lgb_preds = list()\n",
    "\n",
    "cat_cv_scores, cat_imp = list(), list()\n",
    "cat_preds = list()\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    skf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############    \n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "        XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "                              colsample_bytree = 0.7, \n",
    "                              gamma = 0.8, \n",
    "                              learning_rate = 0.01, \n",
    "                              max_depth = 7, \n",
    "                              min_child_weight = 10, \n",
    "                              n_estimators = 1000, \n",
    "                              subsample = 0.7).fit(X_train, Y_train)\n",
    "        XGB_imp.append(XGB_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        XGB_pred_1 = XGB_md.predict(X_test)\n",
    "        XGB_pred_2 = XGB_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        XGB_cv_scores.append(mean_squared_error(Y_test, XGB_pred_1, squared = False))\n",
    "        XGB_preds.append(XGB_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## LightGBM ##\n",
    "        ##############\n",
    "        \n",
    "        lgb_md = LGBMRegressor(n_estimators = 1000,\n",
    "                               max_depth = 7,\n",
    "                               learning_rate = 0.01,\n",
    "                               num_leaves = 20,\n",
    "                               lambda_l1 = 3,\n",
    "                               lambda_l2 = 3,\n",
    "                               bagging_fraction = 0.7,\n",
    "                               feature_fraction = 0.7).fit(X_train, Y_train)\n",
    "        lgb_imp.append(lgb_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        lgb_pred_1 = lgb_md.predict(X_test)\n",
    "        lgb_pred_2 = lgb_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        lgb_cv_scores.append(mean_squared_error(Y_test, lgb_pred_1, squared = False))\n",
    "        lgb_preds.append(lgb_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## CatBoost ##\n",
    "        ##############\n",
    "        \n",
    "        cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                                   iterations = 1000,\n",
    "                                   learning_rate = 0.01,\n",
    "                                   depth = 7,\n",
    "                                   random_strength = 0.5,\n",
    "                                   bagging_temperature = 0.7,\n",
    "                                   border_count = 30,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   verbose = False).fit(X_train, Y_train)\n",
    "        cat_imp.append(cat_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        cat_pred_1 = cat_md.predict(X_test)\n",
    "        cat_pred_2 = cat_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        cat_cv_scores.append(mean_squared_error(Y_test, cat_pred_1, squared = False))\n",
    "        cat_preds.append(cat_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1591da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_cv_score = np.mean(XGB_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the XGBoost model is:', XGB_cv_score)\n",
    "\n",
    "lgb_cv_score = np.mean(lgb_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the LightGBM model is:', lgb_cv_score)\n",
    "\n",
    "cat_cv_score = np.mean(cat_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the CatBoost model is:', cat_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5627a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_preds_test = pd.DataFrame(cat_preds).apply(np.mean, axis = 0)\n",
    "\n",
    "submission['Strength'] = cat_preds_test\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('catboost_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e41b2",
   "metadata": {},
   "source": [
    "# Baseline Modeling 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_dup = train.drop(columns = 'id', axis = 1)\n",
    "train_no_dup = pd.DataFrame(train_no_dup.groupby(train_no_dup.columns.tolist()[0:8])['Strength'].mean()).reset_index()\n",
    "\n",
    "X = train_no_dup.drop(columns = ['Strength'], axis = 1)\n",
    "Y = train_no_dup['Strength']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "XGB_cv_scores, XGB_imp = list(), list()\n",
    "XGB_preds = list()\n",
    "\n",
    "lgb_cv_scores, lgb_imp = list(), list()\n",
    "lgb_preds = list()\n",
    "\n",
    "cat_cv_scores, cat_imp = list(), list()\n",
    "cat_preds = list()\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    skf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############    \n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "        XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "                              colsample_bytree = 0.7, \n",
    "                              gamma = 0.8, \n",
    "                              learning_rate = 0.01, \n",
    "                              max_depth = 7, \n",
    "                              min_child_weight = 10, \n",
    "                              n_estimators = 1000, \n",
    "                              subsample = 0.7).fit(X_train, Y_train)\n",
    "        XGB_imp.append(XGB_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        XGB_pred_1 = XGB_md.predict(X_test)\n",
    "        XGB_pred_2 = XGB_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        XGB_cv_scores.append(mean_squared_error(Y_test, XGB_pred_1, squared = False))\n",
    "        XGB_preds.append(XGB_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## LightGBM ##\n",
    "        ##############\n",
    "        \n",
    "        lgb_md = LGBMRegressor(n_estimators = 1000,\n",
    "                               max_depth = 7,\n",
    "                               learning_rate = 0.01,\n",
    "                               num_leaves = 20,\n",
    "                               lambda_l1 = 3,\n",
    "                               lambda_l2 = 3,\n",
    "                               bagging_fraction = 0.7,\n",
    "                               feature_fraction = 0.7).fit(X_train, Y_train)\n",
    "        lgb_imp.append(lgb_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        lgb_pred_1 = lgb_md.predict(X_test)\n",
    "        lgb_pred_2 = lgb_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        lgb_cv_scores.append(mean_squared_error(Y_test, lgb_pred_1, squared = False))\n",
    "        lgb_preds.append(lgb_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## CatBoost ##\n",
    "        ##############\n",
    "        \n",
    "        cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                                   iterations = 1000,\n",
    "                                   learning_rate = 0.01,\n",
    "                                   depth = 7,\n",
    "                                   random_strength = 0.5,\n",
    "                                   bagging_temperature = 0.7,\n",
    "                                   border_count = 30,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   verbose = False).fit(X_train, Y_train)\n",
    "        cat_imp.append(cat_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        cat_pred_1 = cat_md.predict(X_test)\n",
    "        cat_pred_2 = cat_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        cat_cv_scores.append(mean_squared_error(Y_test, cat_pred_1, squared = False))\n",
    "        cat_preds.append(cat_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e243329",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_cv_score = np.mean(XGB_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the XGBoost model is:', XGB_cv_score)\n",
    "\n",
    "lgb_cv_score = np.mean(lgb_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the LightGBM model is:', lgb_cv_score)\n",
    "\n",
    "cat_cv_score = np.mean(cat_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the CatBoost model is:', cat_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dafc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_preds_test = pd.DataFrame(cat_preds).apply(np.mean, axis = 0)\n",
    "\n",
    "submission['Strength'] = cat_preds_test\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10836a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('catboost_submission_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db45ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_dup = train.drop(columns = 'id', axis = 1)\n",
    "train_no_dup = pd.DataFrame(train_no_dup.groupby(train_no_dup.columns.tolist()[0:8])['Strength'].median()).reset_index()\n",
    "\n",
    "X = train_no_dup.drop(columns = ['Strength'], axis = 1)\n",
    "Y = train_no_dup['Strength']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "XGB_cv_scores, XGB_imp = list(), list()\n",
    "XGB_preds = list()\n",
    "\n",
    "lgb_cv_scores, lgb_imp = list(), list()\n",
    "lgb_preds = list()\n",
    "\n",
    "cat_cv_scores, cat_imp = list(), list()\n",
    "cat_preds = list()\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    skf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############    \n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "#         XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "#                               colsample_bytree = 0.7, \n",
    "#                               gamma = 0.8, \n",
    "#                               learning_rate = 0.01, \n",
    "#                               max_depth = 7, \n",
    "#                               min_child_weight = 10, \n",
    "#                               n_estimators = 1000, \n",
    "#                               subsample = 0.7).fit(X_train, Y_train)\n",
    "#         XGB_imp.append(XGB_md.feature_importances_)\n",
    "        \n",
    "#         ## Predicting on X_test and test\n",
    "#         XGB_pred_1 = XGB_md.predict(X_test)\n",
    "#         XGB_pred_2 = XGB_md.predict(test_baseline)\n",
    "        \n",
    "#         ## Computing rmse\n",
    "#         XGB_cv_scores.append(mean_squared_error(Y_test, XGB_pred_1, squared = False))\n",
    "#         XGB_preds.append(XGB_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## LightGBM ##\n",
    "        ##############\n",
    "        \n",
    "#         lgb_md = LGBMRegressor(n_estimators = 1000,\n",
    "#                                max_depth = 7,\n",
    "#                                learning_rate = 0.01,\n",
    "#                                num_leaves = 20,\n",
    "#                                lambda_l1 = 3,\n",
    "#                                lambda_l2 = 3,\n",
    "#                                bagging_fraction = 0.7,\n",
    "#                                feature_fraction = 0.7).fit(X_train, Y_train)\n",
    "#         lgb_imp.append(lgb_md.feature_importances_)\n",
    "        \n",
    "#         ## Predicting on X_test and test\n",
    "#         lgb_pred_1 = lgb_md.predict(X_test)\n",
    "#         lgb_pred_2 = lgb_md.predict(test_baseline)\n",
    "        \n",
    "#         ## Computing rmse\n",
    "#         lgb_cv_scores.append(mean_squared_error(Y_test, lgb_pred_1, squared = False))\n",
    "#         lgb_preds.append(lgb_pred_2)\n",
    "        \n",
    "        ##############\n",
    "        ## CatBoost ##\n",
    "        ##############\n",
    "        \n",
    "        cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                                   iterations = 4738,\n",
    "                                   learning_rate = 0.003143666241424718,\n",
    "                                   depth = 4,\n",
    "                                   random_strength = 0.29823973415192867,\n",
    "                                   bagging_temperature = 0.3408793603898661,\n",
    "                                   border_count = 112,\n",
    "                                   l2_leaf_reg = 17,\n",
    "                                   verbose = False).fit(X_train, Y_train)\n",
    "        cat_imp.append(cat_md.feature_importances_)\n",
    "        \n",
    "        ## Predicting on X_test and test\n",
    "        cat_pred_1 = cat_md.predict(X_test)\n",
    "        cat_pred_2 = cat_md.predict(test_baseline)\n",
    "        \n",
    "        ## Computing rmse\n",
    "        cat_cv_scores.append(mean_squared_error(Y_test, cat_pred_1, squared = False))\n",
    "        cat_preds.append(cat_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB_cv_score = np.mean(XGB_cv_scores)    \n",
    "# print('The average oof rmse score over 5-folds (run 5 times) of the XGBoost model is:', XGB_cv_score)\n",
    "\n",
    "# lgb_cv_score = np.mean(lgb_cv_scores)    \n",
    "# print('The average oof rmse score over 5-folds (run 5 times) of the LightGBM model is:', lgb_cv_score)\n",
    "\n",
    "cat_cv_score = np.mean(cat_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the CatBoost model is:', cat_cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c69666",
   "metadata": {},
   "source": [
    "# Baseline 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a08fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedEnsemble(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _rmse_loss(self, coef, X, y):\n",
    "        \n",
    "        ens = coef[0]*X[:, 0] + coef[1]*X[:, 1] + coef[2]*X[:, 2]\n",
    "        ll = mean_squared_error(y, ens, squared = False)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._rmse_loss, X = X, y = y)\n",
    "        initial_coef = [1/3, 1/3, 1/3]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method = 'nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        \n",
    "        ens = coef[0]*X[:, 0] + coef[1]*X[:, 1] + coef[2]*X[:, 2]\n",
    "        return ens\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_dup = train.drop(columns = 'id', axis = 1)\n",
    "train_no_dup = pd.DataFrame(train_no_dup.groupby(train_no_dup.columns.tolist()[0:8])['Strength'].median()).reset_index()\n",
    "\n",
    "X = train_no_dup.drop(columns = ['Strength'], axis = 1)\n",
    "Y = train_no_dup['Strength']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "ens_cv_scores, preds = list(), list()\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "\n",
    "    skf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############    \n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "        XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "                              colsample_bytree = 0.671460244215802, \n",
    "                              gamma = 2.5281806276307384, \n",
    "                              learning_rate = 0.002046162779305807, \n",
    "                              max_depth = 8, \n",
    "                              min_child_weight = 80, \n",
    "                              n_estimators = 2690, \n",
    "                              subsample = 0.44886485549735244).fit(X_train, Y_train)\n",
    "        \n",
    "        ##############\n",
    "        ## LightGBM ##\n",
    "        ##############\n",
    "        \n",
    "        lgb_md = LGBMRegressor(n_estimators = 5420,\n",
    "                               max_depth = 3,\n",
    "                               learning_rate = 0.0014779400349972686,\n",
    "                               num_leaves = 61,\n",
    "                               lambda_l1 = 7.384172796287736,\n",
    "                               lambda_l2 = 0.10456555506292783,\n",
    "                               bagging_fraction = 0.22841166601766863,\n",
    "                               feature_fraction = 0.659898030).fit(X_train, Y_train)\n",
    "        \n",
    "        ##############\n",
    "        ## CatBoost ##\n",
    "        ##############\n",
    "        \n",
    "        cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                                   iterations = 4738,\n",
    "                                   learning_rate = 0.003143666241424718,\n",
    "                                   depth = 4,\n",
    "                                   random_strength = 0.29823973415192867,\n",
    "                                   bagging_temperature = 0.3408793603898661,\n",
    "                                   border_count = 112,\n",
    "                                   l2_leaf_reg = 17,\n",
    "                                   verbose = False).fit(X_train, Y_train)\n",
    "        \n",
    "        ######################\n",
    "        ## Optimal Ensemble ##\n",
    "        ######################\n",
    "        \n",
    "        XGB_pred_1 = XGB_md.predict(X_test)\n",
    "        lgb_pred_1 = lgb_md.predict(X_test)\n",
    "        cat_pred_1 = cat_md.predict(X_test)\n",
    "        models_pred_oof = np.transpose((XGB_pred_1, lgb_pred_1, cat_pred_1))\n",
    "\n",
    "        opt_ens = OptimizedEnsemble()\n",
    "        opt_ens.fit(models_pred_oof, Y_test)\n",
    "        coef = opt_ens.coefficients()\n",
    "        \n",
    "        ens_pred = opt_ens.predict(models_pred_oof, coef)\n",
    "        ens_cv_scores.append(mean_squared_error(Y_test, ens_pred, squared = False))\n",
    "        \n",
    "        XGB_pred_2 = XGB_md.predict(test_baseline)\n",
    "        lgb_pred_2 = lgb_md.predict(test_baseline)\n",
    "        cat_pred_2 = cat_md.predict(test_baseline)\n",
    "        models_pred = np.transpose((XGB_pred_2, lgb_pred_2, cat_pred_2))\n",
    "        \n",
    "        ens_preds = opt_ens.predict(models_pred, coef)\n",
    "        preds.append(ens_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7684984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_cv_score = np.mean(ens_cv_scores) # first run    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the ensemble model is:', ens_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db660adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_cv_score = np.mean(ens_cv_scores)  # second run  \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the ensemble model is:', ens_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e58f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_preds_test = pd.DataFrame(preds).apply(np.mean, axis = 0)\n",
    "\n",
    "submission['Strength'] = ens_preds_test\n",
    "submission.to_csv('Ensemble_Optuna_baseline_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4430f696",
   "metadata": {},
   "source": [
    "## Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c436e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb20034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc56c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e610320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1982fef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02e3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef5ba99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32232e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_dup = train.drop(columns = 'id', axis = 1)\n",
    "train_no_dup = pd.DataFrame(train_no_dup.groupby(train_no_dup.columns.tolist()[0:8])['Strength'].median()).reset_index()\n",
    "\n",
    "X = train_no_dup.drop(columns = ['Strength'], axis = 1)\n",
    "Y = train_no_dup['Strength']\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "ens_cv_scores, preds = list(), list()\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "\n",
    "    skf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "#         #############    \n",
    "#         ## XGBoost ##\n",
    "#         #############\n",
    "        \n",
    "#         XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "#                               colsample_bytree = 0.671460244215802, \n",
    "#                               gamma = 2.5281806276307384, \n",
    "#                               learning_rate = 0.002046162779305807, \n",
    "#                               max_depth = 8, \n",
    "#                               min_child_weight = 80, \n",
    "#                               n_estimators = 2690, \n",
    "#                               subsample = 0.44886485549735244).fit(X_train, Y_train)\n",
    "        \n",
    "#         ##############\n",
    "#         ## LightGBM ##\n",
    "#         ##############\n",
    "        \n",
    "#         lgb_md = LGBMRegressor(n_estimators = 5420,\n",
    "#                                max_depth = 3,\n",
    "#                                learning_rate = 0.0014779400349972686,\n",
    "#                                num_leaves = 61,\n",
    "#                                lambda_l1 = 7.384172796287736,\n",
    "#                                lambda_l2 = 0.10456555506292783,\n",
    "#                                bagging_fraction = 0.22841166601766863,\n",
    "#                                feature_fraction = 0.659898030).fit(X_train, Y_train)\n",
    "        \n",
    "        ##############\n",
    "        ## CatBoost ##\n",
    "        ##############\n",
    "        \n",
    "        cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                                   iterations = 4738,\n",
    "                                   learning_rate = 0.003143666241424718,\n",
    "                                   depth = 4,\n",
    "                                   random_strength = 0.29823973415192867,\n",
    "                                   bagging_temperature = 0.3408793603898661,\n",
    "                                   border_count = 112,\n",
    "                                   l2_leaf_reg = 17,\n",
    "                                   verbose = False).fit(X_train, Y_train)\n",
    "        \n",
    "        ######################\n",
    "        ## Optimal Ensemble ##\n",
    "        ######################\n",
    "        \n",
    "        XGB_pred_1 = XGB_md.predict(X_test)\n",
    "        lgb_pred_1 = lgb_md.predict(X_test)\n",
    "        cat_pred_1 = cat_md.predict(X_test)\n",
    "        models_pred_oof = np.transpose((XGB_pred_1, lgb_pred_1, cat_pred_1))\n",
    "\n",
    "        opt_ens = OptimizedEnsemble()\n",
    "        opt_ens.fit(models_pred_oof, Y_test)\n",
    "        coef = opt_ens.coefficients()\n",
    "        \n",
    "        ens_pred = opt_ens.predict(models_pred_oof, coef)\n",
    "        ens_cv_scores.append(mean_squared_error(Y_test, ens_pred, squared = False))\n",
    "        \n",
    "        XGB_pred_2 = XGB_md.predict(test_baseline)\n",
    "        lgb_pred_2 = lgb_md.predict(test_baseline)\n",
    "        cat_pred_2 = cat_md.predict(test_baseline)\n",
    "        models_pred = np.transpose((XGB_pred_2, lgb_pred_2, cat_pred_2))\n",
    "        \n",
    "        ens_preds = opt_ens.predict(models_pred, coef)\n",
    "        preds.append(ens_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581af49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b73b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31e0d654",
   "metadata": {},
   "source": [
    "# Baseline 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ac4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedEnsemble(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _rmse_loss(self, coef, X, y):\n",
    "        \n",
    "        ens = coef[0]*X[:, 0] + coef[1]*X[:, 1] + coef[2]*X[:, 2]\n",
    "        ll = mean_squared_error(y, ens, squared = False)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._rmse_loss, X = X, y = y)\n",
    "        initial_coef = [1/3, 1/3, 1/3]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method = 'nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        \n",
    "        ens = coef[0]*X[:, 0] + coef[1]*X[:, 1] + coef[2]*X[:, 2]\n",
    "        return ens\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f13f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_dup = train.drop(columns = 'id', axis = 1)\n",
    "train_no_dup = pd.DataFrame(train_no_dup.groupby(train_no_dup.columns.tolist()[0:8])['Strength'].median()).reset_index()\n",
    "\n",
    "X = train_no_dup.drop(columns = ['Strength'], axis = 1)\n",
    "Y = train_no_dup['Strength']\n",
    "\n",
    "X['WaterComponent_to_Cement_ratio'] = X['WaterComponent'] / (X['CementComponent'] + 1e-6)\n",
    "\n",
    "test_baseline = test.drop(columns = ['id'], axis = 1)\n",
    "test_baseline['WaterComponent_to_Cement_ratio'] = test_baseline['WaterComponent'] / (test_baseline['CementComponent'] + 1e-6)\n",
    "\n",
    "ens_cv_scores, preds = list(), list()\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "\n",
    "    skf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "    for train_ix, test_ix in skf.split(X, Y):\n",
    "        \n",
    "        ## Splitting the data \n",
    "        X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "        Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "                \n",
    "        #############    \n",
    "        ## XGBoost ##\n",
    "        #############\n",
    "        \n",
    "        XGB_md = XGBRegressor(tree_method = 'hist',\n",
    "                              colsample_bytree = 0.7940111565728297, \n",
    "                              gamma = 3.3316249893010292, \n",
    "                              learning_rate = 0.0009167011149361065, \n",
    "                              max_depth = 8, \n",
    "                              min_child_weight = 89, \n",
    "                              n_estimators = 6766, \n",
    "                              subsample = 0.3771654611184001).fit(X_train, Y_train)\n",
    "        \n",
    "        ##############\n",
    "        ## LightGBM ##\n",
    "        ##############\n",
    "        \n",
    "        lgb_md = LGBMRegressor(n_estimators = 4273,\n",
    "                               max_depth = 4,\n",
    "                               learning_rate = 0.002480759916271656,\n",
    "                               num_leaves = 5,\n",
    "                               lambda_l1 = 1.2582711296889206,\n",
    "                               lambda_l2 = 0.018040323452000916,\n",
    "                               bagging_fraction = 0.7658802307213928,\n",
    "                               feature_fraction = 0.4895760311486668).fit(X_train, Y_train)\n",
    "        \n",
    "        ##############\n",
    "        ## CatBoost ##\n",
    "        ##############\n",
    "        \n",
    "        cat_md = CatBoostRegressor(loss_function = 'RMSE',\n",
    "                                   iterations = 416,\n",
    "                                   learning_rate = 0.031225761812299576,\n",
    "                                   depth = 4,\n",
    "                                   random_strength = 0.19789440193456237,\n",
    "                                   bagging_temperature = 0.2831892755259466,\n",
    "                                   border_count = 56,\n",
    "                                   l2_leaf_reg = 26,\n",
    "                                   verbose = False).fit(X_train, Y_train)\n",
    "        \n",
    "        ######################\n",
    "        ## Optimal Ensemble ##\n",
    "        ######################\n",
    "        \n",
    "        XGB_pred_1 = XGB_md.predict(X_test)\n",
    "        lgb_pred_1 = lgb_md.predict(X_test)\n",
    "        cat_pred_1 = cat_md.predict(X_test)\n",
    "        models_pred_oof = np.transpose((XGB_pred_1, lgb_pred_1, cat_pred_1))\n",
    "\n",
    "        opt_ens = OptimizedEnsemble()\n",
    "        opt_ens.fit(models_pred_oof, Y_test)\n",
    "        coef = opt_ens.coefficients()\n",
    "        \n",
    "        ens_pred = opt_ens.predict(models_pred_oof, coef)\n",
    "        ens_cv_scores.append(mean_squared_error(Y_test, ens_pred, squared = False))\n",
    "        \n",
    "        XGB_pred_2 = XGB_md.predict(test_baseline)\n",
    "        lgb_pred_2 = lgb_md.predict(test_baseline)\n",
    "        cat_pred_2 = cat_md.predict(test_baseline)\n",
    "        models_pred = np.transpose((XGB_pred_2, lgb_pred_2, cat_pred_2))\n",
    "        \n",
    "        ens_preds = opt_ens.predict(models_pred, coef)\n",
    "        preds.append(ens_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae016c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_cv_score = np.mean(ens_cv_scores) \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the ensemble model is:', ens_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_preds_test = pd.DataFrame(preds).apply(np.mean, axis = 0)\n",
    "\n",
    "submission['Strength'] = ens_preds_test\n",
    "submission.to_csv('Ensemble_Optuna_baseline_submission_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ace62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cv_score = np.mean(cat_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the CatBoost model is:', cat_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c1272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cv_score = np.mean(cat_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the CatBoost model is:', cat_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7087543",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cv_score = np.mean(cat_cv_scores)    \n",
    "print('The average oof rmse score over 5-folds (run 5 times) of the CatBoost model is:', cat_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484f4ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_preds_test = pd.DataFrame(cat_preds).apply(np.mean, axis = 0)\n",
    "\n",
    "submission['Strength'] = cat_preds_test\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('catboost_submission_6.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
