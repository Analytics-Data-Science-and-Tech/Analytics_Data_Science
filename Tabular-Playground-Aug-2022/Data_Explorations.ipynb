{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a5e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "## Filling missing values with kNN\n",
    "knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "train = pd.DataFrame(knn_imputer.fit_transform(train), columns = train.columns)\n",
    "test = pd.DataFrame(knn_imputer.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Engineering features\n",
    "train['feature_1'] = np.where(train['loading'] < 150, 0, 1)\n",
    "test['feature_1'] = np.where(test['loading'] < 150, 0, 1)\n",
    "\n",
    "## Defining input and target variables\n",
    "X = train[['loading', 'measurement_2', 'measurement_4', 'measurement_5',\n",
    "           'measurement_6', 'measurement_7', 'measurement_8', 'measurement_15',\n",
    "           'measurement_17', 'feature_1']]\n",
    "# X = train.drop(columns = ['failure'], axis = 1)\n",
    "Y = train['failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb99749",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7089ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building Random Forest model\n",
    "RF_md = RandomForestClassifier(n_estimators = 300, max_depth = 3, criterion = 'gini').fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ed4d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame({'feature': X.columns, 'Imp': RF_md.feature_importances_})\n",
    "importance = importance.sort_values(by = 'Imp', ascending = False)\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c321f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "## Running RFE with Random forest\n",
    "RF_auto_feature = RFECV(estimator = RandomForestClassifier(n_estimators = 300, max_depth = 3), step = 1, scoring = 'roc_auc', min_features_to_select = 10, cv = 3, n_jobs = -1).fit(X, Y)\n",
    "\n",
    "## Appending results \n",
    "X.columns[RF_auto_feature.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[RF_auto_feature.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ca8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e0f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de0b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the decision tree on the train data-frame\n",
    "tree_md = DecisionTreeClassifier(max_depth = 3).fit(X, Y)\n",
    "\n",
    "## Visualizing the decision-tree model \n",
    "fig = plt.figure(figsize = (25, 15))\n",
    "plot_tree(tree_md, feature_names = X.columns, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b09fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize = (18, 12))\n",
    "\n",
    "sns.boxplot(ax = axes[0], x = 'failure', y = 'loading', hue = 'failure', data = train)\n",
    "sns.boxplot(ax = axes[1], x = 'failure', y = 'measurement_3', hue = 'failure', data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36546b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c89c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17edcf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c62b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the model \n",
    "knn_imputer = KNNImputer(n_neighbors = 5, weights = 'uniform')\n",
    "X_new = knn_imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.DataFrame(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c89690",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cbd8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf13235",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ccb554",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42019b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316bee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c2e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9cbbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['attribute_0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d117df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5cfef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fd801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6da5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4fc6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccfeee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['product_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a7f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummies = pd.get_dummies(train[['product_code', 'attribute_0', 'attribute_1']])\n",
    "train_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed17e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummies = pd.get_dummies(train[['product_code', 'attribute_0', 'attribute_1']])\n",
    "train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591fcbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['failure'].value_counts() / train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dummies = pd.get_dummies(test[['product_code', 'attribute_0', 'attribute_1']])\n",
    "test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ccc35",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf7a1b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "120 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.5               nan 0.5        0.49144444 0.58792262 0.58791902\n",
      "        nan        nan        nan 0.5               nan 0.58762996\n",
      " 0.56935907 0.5874381  0.58743768        nan        nan        nan\n",
      " 0.5898217         nan 0.58967075 0.58672108 0.58788423 0.58788452\n",
      "        nan        nan        nan 0.58823161        nan 0.58822264\n",
      " 0.58778637 0.58779505 0.58779611        nan        nan        nan\n",
      " 0.58781017        nan 0.58779358 0.58777806 0.58774624 0.5877465\n",
      "        nan        nan        nan 0.58777439        nan 0.58774184\n",
      " 0.58775635 0.58773698 0.58773613        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test_id = test['id']\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "## Filling missing values with kNN\n",
    "knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "train = pd.DataFrame(knn_imputer.fit_transform(train), columns = train.columns)\n",
    "test = pd.DataFrame(knn_imputer.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining input and target variables\n",
    "X = train.drop(columns = ['failure'], axis = 1)\n",
    "Y = train['failure']\n",
    "\n",
    "## Scaling inputs to 0-1\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining the hyper-parameter grid\n",
    "logistic_param_grid = {'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                       'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                       'solver': ['liblinear', 'sag', 'saga']}\n",
    "\n",
    "## Performing grid search with 5 folds\n",
    "logistic_grid_search = GridSearchCV(LogisticRegression(max_iter = 1000), logistic_param_grid, cv = 5, scoring = 'roc_auc', n_jobs = -1, verbose = 1).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e419ac98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "best_params = logistic_grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9179c6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best area under the ROC cure is: 0.5898217001986322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_score = logistic_grid_search.best_score_\n",
    "print('The best area under the ROC cure is:', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71ff361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, max_iter=1000, penalty='l1', solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "## Extracting the best model\n",
    "logistic_md = logistic_grid_search.best_estimator_\n",
    "print(logistic_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c304409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>est_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loading</td>\n",
       "      <td>2.467620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>measurement_17</td>\n",
       "      <td>0.491704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>measurement_4</td>\n",
       "      <td>0.196130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attribute_0_material_5</td>\n",
       "      <td>0.077022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>measurement_11</td>\n",
       "      <td>0.057501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>measurement_9</td>\n",
       "      <td>0.050645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>measurement_7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>measurement_8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>measurement_10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>measurement_3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>measurement_12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>measurement_13</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>measurement_14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>measurement_15</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>measurement_16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>measurement_6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>measurement_5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>attribute_0_material_7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  est_coef\n",
       "0                  loading  2.467620\n",
       "1           measurement_17  0.491704\n",
       "2            measurement_4  0.196130\n",
       "3   attribute_0_material_5  0.077022\n",
       "4           measurement_11  0.057501\n",
       "5            measurement_9  0.050645\n",
       "6            measurement_7  0.000000\n",
       "7            measurement_8  0.000000\n",
       "8           measurement_10  0.000000\n",
       "9            measurement_3  0.000000\n",
       "10          measurement_12  0.000000\n",
       "11          measurement_13  0.000000\n",
       "12          measurement_14  0.000000\n",
       "13          measurement_15  0.000000\n",
       "14          measurement_16  0.000000\n",
       "15           measurement_6  0.000000\n",
       "16           measurement_5  0.000000\n",
       "17  attribute_0_material_7  0.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_md = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X, Y)\n",
    "coefs =  pd.DataFrame({'feature': X.columns, 'est_coef': abs(logit_md.coef_.flatten())})\n",
    "coefs = coefs.sort_values(by = 'est_coef', ascending = False).reset_index(drop = True)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1585f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5917109597291497\n"
     ]
    }
   ],
   "source": [
    "logit_1 = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:5].values], Y)\n",
    "logit_1_pred = logit_1.predict_proba(X[coefs['feature'].loc[0:5].values])[:, 1]\n",
    "logit_1_score = roc_auc_score(Y, logit_1_pred)\n",
    "print('The area under the ROC curve is:', logit_1_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_1_test_pred = logit_1.predict_proba(test[coefs['feature'].loc[0:5].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_1_test_pred})\n",
    "data_out.to_csv('Logistic_submission_top_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18d6672f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5917147420076923\n"
     ]
    }
   ],
   "source": [
    "logit_2 = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:6].values], Y)\n",
    "logit_2_pred = logit_2.predict_proba(X[coefs['feature'].loc[0:6].values])[:, 1]\n",
    "logit_2_score = roc_auc_score(Y, logit_2_pred)\n",
    "print('The area under the ROC curve is:', logit_2_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_2_test_pred = logit_2.predict_proba(test[coefs['feature'].loc[0:6].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_2_test_pred})\n",
    "data_out.to_csv('Logistic_submission_top_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42cd203b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5920820884073509\n"
     ]
    }
   ],
   "source": [
    "logit_3 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:7].values], Y)\n",
    "logit_3_pred = logit_3.predict_proba(X[coefs['feature'].loc[0:7].values])[:, 1]\n",
    "logit_3_score = roc_auc_score(Y, logit_3_pred)\n",
    "print('The area under the ROC curve is:', logit_3_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_3_test_pred = logit_3.predict_proba(test[coefs['feature'].loc[0:7].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_3_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "203abb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5921029205544915\n"
     ]
    }
   ],
   "source": [
    "logit_4 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:8].values], Y)\n",
    "logit_4_pred = logit_4.predict_proba(X[coefs['feature'].loc[0:8].values])[:, 1]\n",
    "logit_4_score = roc_auc_score(Y, logit_4_pred)\n",
    "print('The area under the ROC curve is:', logit_4_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_4_test_pred = logit_4.predict_proba(test[coefs['feature'].loc[0:8].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_4_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a09ec261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.592213952006473\n"
     ]
    }
   ],
   "source": [
    "logit_5 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:9].values], Y)\n",
    "logit_5_pred = logit_5.predict_proba(X[coefs['feature'].loc[0:9].values])[:, 1]\n",
    "logit_5_score = roc_auc_score(Y, logit_5_pred)\n",
    "print('The area under the ROC curve is:', logit_5_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_5_test_pred = logit_5.predict_proba(test[coefs['feature'].loc[0:9].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_5_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06c214e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5932685054175725\n"
     ]
    }
   ],
   "source": [
    "logit_6 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:10].values], Y)\n",
    "logit_6_pred = logit_6.predict_proba(X[coefs['feature'].loc[0:10].values])[:, 1]\n",
    "logit_6_score = roc_auc_score(Y, logit_6_pred)\n",
    "print('The area under the ROC curve is:', logit_6_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_6_test_pred = logit_6.predict_proba(test[coefs['feature'].loc[0:10].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_6_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc82cd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5932727446156705\n"
     ]
    }
   ],
   "source": [
    "logit_7 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:11].values], Y)\n",
    "logit_7_pred = logit_7.predict_proba(X[coefs['feature'].loc[0:11].values])[:, 1]\n",
    "logit_7_score = roc_auc_score(Y, logit_7_pred)\n",
    "print('The area under the ROC curve is:', logit_7_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_7_test_pred = logit_7.predict_proba(test[coefs['feature'].loc[0:11].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_7_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_7.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fc21656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5932892106426143\n"
     ]
    }
   ],
   "source": [
    "logit_8 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:12].values], Y)\n",
    "logit_8_pred = logit_8.predict_proba(X[coefs['feature'].loc[0:12].values])[:, 1]\n",
    "logit_8_score = roc_auc_score(Y, logit_8_pred)\n",
    "print('The area under the ROC curve is:', logit_8_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_8_test_pred = logit_8.predict_proba(test[coefs['feature'].loc[0:12].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_8_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_8.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43e8ead3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5935365141212808\n"
     ]
    }
   ],
   "source": [
    "logit_9 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:13].values], Y)\n",
    "logit_9_pred = logit_9.predict_proba(X[coefs['feature'].loc[0:13].values])[:, 1]\n",
    "logit_9_score = roc_auc_score(Y, logit_9_pred)\n",
    "print('The area under the ROC curve is:', logit_9_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_9_test_pred = logit_9.predict_proba(test[coefs['feature'].loc[0:13].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_9_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_9.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee87bdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5936143258292842\n"
     ]
    }
   ],
   "source": [
    "logit_10 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:14].values], Y)\n",
    "logit_10_pred = logit_10.predict_proba(X[coefs['feature'].loc[0:14].values])[:, 1]\n",
    "logit_10_score = roc_auc_score(Y, logit_10_pred)\n",
    "print('The area under the ROC curve is:', logit_10_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_10_test_pred = logit_10.predict_proba(test[coefs['feature'].loc[0:14].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_10_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_10.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e1740e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.593843741753501\n"
     ]
    }
   ],
   "source": [
    "logit_11 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:15].values], Y)\n",
    "logit_11_pred = logit_11.predict_proba(X[coefs['feature'].loc[0:15].values])[:, 1]\n",
    "logit_11_score = roc_auc_score(Y, logit_11_pred)\n",
    "print('The area under the ROC curve is:', logit_11_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_11_test_pred = logit_11.predict_proba(test[coefs['feature'].loc[0:15].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_11_test_pred})\n",
    "data_out.to_csv('Logistic_submission_11.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57177aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5938162335039666\n"
     ]
    }
   ],
   "source": [
    "logit_12 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:16].values], Y)\n",
    "logit_12_pred = logit_12.predict_proba(X[coefs['feature'].loc[0:16].values])[:, 1]\n",
    "logit_12_score = roc_auc_score(Y, logit_12_pred)\n",
    "print('The area under the ROC curve is:', logit_12_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_12_test_pred = logit_12.predict_proba(test[coefs['feature'].loc[0:16].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_12_test_pred})\n",
    "data_out.to_csv('Logistic_submission_12.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94b1e83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937585262564042\n"
     ]
    }
   ],
   "source": [
    "logit_13 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:17].values], Y)\n",
    "logit_13_pred = logit_13.predict_proba(X[coefs['feature'].loc[0:17].values])[:, 1]\n",
    "logit_13_score = roc_auc_score(Y, logit_13_pred)\n",
    "print('The area under the ROC curve is:', logit_13_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_13_test_pred = logit_13.predict_proba(test[coefs['feature'].loc[0:17].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_13_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_13.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95e5e8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937601339363217\n"
     ]
    }
   ],
   "source": [
    "logit_14 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:18].values], Y)\n",
    "logit_14_pred = logit_14.predict_proba(X[coefs['feature'].loc[0:18].values])[:, 1]\n",
    "logit_14_score = roc_auc_score(Y, logit_14_pred)\n",
    "print('The area under the ROC curve is:', logit_14_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_14_test_pred = logit_14.predict_proba(test[coefs['feature'].loc[0:18].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_14_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_14.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ee2b8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937781145669769\n"
     ]
    }
   ],
   "source": [
    "logit_15 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:19].values], Y)\n",
    "logit_15_pred = logit_15.predict_proba(X[coefs['feature'].loc[0:19].values])[:, 1]\n",
    "logit_15_score = roc_auc_score(Y, logit_15_pred)\n",
    "print('The area under the ROC curve is:', logit_15_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_15_test_pred = logit_15.predict_proba(test[coefs['feature'].loc[0:19].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_15_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_15.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d06b41b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937811522358737\n"
     ]
    }
   ],
   "source": [
    "logit_16 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:20].values], Y)\n",
    "logit_16_pred = logit_16.predict_proba(X[coefs['feature'].loc[0:20].values])[:, 1]\n",
    "logit_16_score = roc_auc_score(Y, logit_16_pred)\n",
    "print('The area under the ROC curve is:', logit_16_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_16_test_pred = logit_16.predict_proba(test[coefs['feature'].loc[0:20].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_16_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_16.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45f93b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937849768217824\n"
     ]
    }
   ],
   "source": [
    "logit_17 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:21].values], Y)\n",
    "logit_17_pred = logit_17.predict_proba(X[coefs['feature'].loc[0:21].values])[:, 1]\n",
    "logit_17_score = roc_auc_score(Y, logit_17_pred)\n",
    "print('The area under the ROC curve is:', logit_17_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_17_test_pred = logit_17.predict_proba(test[coefs['feature'].loc[0:21].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_17_test_pred})\n",
    "data_out.to_csv('Logistic_submission_17.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4563b914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937820745364579\n"
     ]
    }
   ],
   "source": [
    "logit_18 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:22].values], Y)\n",
    "logit_18_pred = logit_18.predict_proba(X[coefs['feature'].loc[0:22].values])[:, 1]\n",
    "logit_18_score = roc_auc_score(Y, logit_18_pred)\n",
    "print('The area under the ROC curve is:', logit_18_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_18_test_pred = logit_18.predict_proba(test[coefs['feature'].loc[0:22].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_18_test_pred})\n",
    "data_out.to_csv('Logistic_submission_18.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4139015e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937853406651322\n"
     ]
    }
   ],
   "source": [
    "logit_19 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:23].values], Y)\n",
    "logit_19_pred = logit_19.predict_proba(X[coefs['feature'].loc[0:23].values])[:, 1]\n",
    "logit_19_score = roc_auc_score(Y, logit_19_pred)\n",
    "print('The area under the ROC curve is:', logit_19_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_19_test_pred = logit_19.predict_proba(test[coefs['feature'].loc[0:23].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_19_test_pred})\n",
    "data_out.to_csv('Logistic_submission_19.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b7db17",
   "metadata": {},
   "source": [
    "# Ensemble Logistic Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5df9c176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>failure_11</th>\n",
       "      <th>failure_12</th>\n",
       "      <th>failure_17</th>\n",
       "      <th>failure_18</th>\n",
       "      <th>failure_19</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26570</td>\n",
       "      <td>0.182794</td>\n",
       "      <td>0.183966</td>\n",
       "      <td>0.194206</td>\n",
       "      <td>0.193855</td>\n",
       "      <td>0.194325</td>\n",
       "      <td>0.189829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26571</td>\n",
       "      <td>0.143223</td>\n",
       "      <td>0.142212</td>\n",
       "      <td>0.151202</td>\n",
       "      <td>0.150841</td>\n",
       "      <td>0.151433</td>\n",
       "      <td>0.147782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26572</td>\n",
       "      <td>0.163431</td>\n",
       "      <td>0.163523</td>\n",
       "      <td>0.173477</td>\n",
       "      <td>0.173041</td>\n",
       "      <td>0.173654</td>\n",
       "      <td>0.169425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26573</td>\n",
       "      <td>0.167601</td>\n",
       "      <td>0.167822</td>\n",
       "      <td>0.176308</td>\n",
       "      <td>0.175854</td>\n",
       "      <td>0.176560</td>\n",
       "      <td>0.172829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26574</td>\n",
       "      <td>0.301532</td>\n",
       "      <td>0.302842</td>\n",
       "      <td>0.318281</td>\n",
       "      <td>0.317976</td>\n",
       "      <td>0.318431</td>\n",
       "      <td>0.311812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26575</td>\n",
       "      <td>0.142280</td>\n",
       "      <td>0.142407</td>\n",
       "      <td>0.150982</td>\n",
       "      <td>0.150678</td>\n",
       "      <td>0.151078</td>\n",
       "      <td>0.147485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26576</td>\n",
       "      <td>0.143446</td>\n",
       "      <td>0.143347</td>\n",
       "      <td>0.150532</td>\n",
       "      <td>0.150181</td>\n",
       "      <td>0.150771</td>\n",
       "      <td>0.147655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26577</td>\n",
       "      <td>0.201760</td>\n",
       "      <td>0.202467</td>\n",
       "      <td>0.214964</td>\n",
       "      <td>0.214645</td>\n",
       "      <td>0.215149</td>\n",
       "      <td>0.209797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26578</td>\n",
       "      <td>0.119192</td>\n",
       "      <td>0.119385</td>\n",
       "      <td>0.125221</td>\n",
       "      <td>0.124935</td>\n",
       "      <td>0.125428</td>\n",
       "      <td>0.122832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26579</td>\n",
       "      <td>0.153112</td>\n",
       "      <td>0.153706</td>\n",
       "      <td>0.163677</td>\n",
       "      <td>0.163363</td>\n",
       "      <td>0.163836</td>\n",
       "      <td>0.159539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  failure_11  failure_12  failure_17  failure_18  failure_19   failure\n",
       "0  26570    0.182794    0.183966    0.194206    0.193855    0.194325  0.189829\n",
       "1  26571    0.143223    0.142212    0.151202    0.150841    0.151433  0.147782\n",
       "2  26572    0.163431    0.163523    0.173477    0.173041    0.173654  0.169425\n",
       "3  26573    0.167601    0.167822    0.176308    0.175854    0.176560  0.172829\n",
       "4  26574    0.301532    0.302842    0.318281    0.317976    0.318431  0.311812\n",
       "5  26575    0.142280    0.142407    0.150982    0.150678    0.151078  0.147485\n",
       "6  26576    0.143446    0.143347    0.150532    0.150181    0.150771  0.147655\n",
       "7  26577    0.201760    0.202467    0.214964    0.214645    0.215149  0.209797\n",
       "8  26578    0.119192    0.119385    0.125221    0.124935    0.125428  0.122832\n",
       "9  26579    0.153112    0.153706    0.163677    0.163363    0.163836  0.159539"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_11 = pd.read_csv('Logistic_submission_11.csv')\n",
    "logit_11.columns = ['id', 'failure_11']\n",
    "\n",
    "logit_12 = pd.read_csv('Logistic_submission_12.csv')\n",
    "logit_12.columns = ['id', 'failure_12']\n",
    "\n",
    "logit_17 = pd.read_csv('Logistic_submission_17.csv')\n",
    "logit_17.columns = ['id', 'failure_17']\n",
    "\n",
    "logit_18 = pd.read_csv('Logistic_submission_18.csv')\n",
    "logit_18.columns = ['id', 'failure_18']\n",
    "\n",
    "logit_19 = pd.read_csv('Logistic_submission_19.csv')\n",
    "logit_19.columns = ['id', 'failure_19']\n",
    "\n",
    "logit = pd.merge(logit_11, logit_12, on = 'id')\n",
    "logit = pd.merge(logit, logit_17, on = 'id')\n",
    "logit = pd.merge(logit, logit_18, on = 'id')\n",
    "logit = pd.merge(logit, logit_19, on = 'id')\n",
    "\n",
    "w_11 = 0.593843741753501\n",
    "w_12 = 0.5938162335039666\n",
    "w_17 = 0.5937849768217824\n",
    "w_18 = 0.5937820745364579\n",
    "w_19 = 0.5937853406651322\n",
    "w_tot = w_11 + w_12 + w_17 + w_18 + w_19\n",
    "\n",
    "w_11 = w_11 / w_tot\n",
    "w_12 = w_12 / w_tot\n",
    "w_17 = w_17 / w_tot\n",
    "w_18 = w_18 / w_tot\n",
    "w_19 = w_19 / w_tot\n",
    "\n",
    "logit['failure'] = w_11*logit['failure_11'] + w_12*logit['failure_12'] + w_17*logit['failure_17'] + w_18*logit['failure_18'] + w_19*logit['failure_19']\n",
    "logit.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df09b93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26570</td>\n",
       "      <td>0.189829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26571</td>\n",
       "      <td>0.147782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26572</td>\n",
       "      <td>0.169425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26573</td>\n",
       "      <td>0.172829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26574</td>\n",
       "      <td>0.311812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   failure\n",
       "0  26570  0.189829\n",
       "1  26571  0.147782\n",
       "2  26572  0.169425\n",
       "3  26573  0.172829\n",
       "4  26574  0.311812"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = logit[['id', 'failure']]\n",
    "logit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d3865c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.to_csv('Logistic_submission_ensemble.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905f8479",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b88709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test_id = test['id']\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "## Filling missing values with kNN\n",
    "knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "train = pd.DataFrame(knn_imputer.fit_transform(train), columns = train.columns)\n",
    "test = pd.DataFrame(knn_imputer.fit_transform(test), columns = test.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
