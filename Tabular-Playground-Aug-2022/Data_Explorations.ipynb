{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a280ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "## Filling missing values with kNN\n",
    "knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "train = pd.DataFrame(knn_imputer.fit_transform(train), columns = train.columns)\n",
    "test = pd.DataFrame(knn_imputer.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Engineering features\n",
    "train['feature_1'] = np.where(train['loading'] < 150, 0, 1)\n",
    "test['feature_1'] = np.where(test['loading'] < 150, 0, 1)\n",
    "\n",
    "## Defining input and target variables\n",
    "X = train[['loading', 'measurement_2', 'measurement_4', 'measurement_5',\n",
    "           'measurement_6', 'measurement_7', 'measurement_8', 'measurement_15',\n",
    "           'measurement_17', 'feature_1']]\n",
    "# X = train.drop(columns = ['failure'], axis = 1)\n",
    "Y = train['failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee1e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building Random Forest model\n",
    "RF_md = RandomForestClassifier(n_estimators = 300, max_depth = 3, criterion = 'gini').fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac6e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame({'feature': X.columns, 'Imp': RF_md.feature_importances_})\n",
    "importance = importance.sort_values(by = 'Imp', ascending = False)\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34340eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "## Running RFE with Random forest\n",
    "RF_auto_feature = RFECV(estimator = RandomForestClassifier(n_estimators = 300, max_depth = 3), step = 1, scoring = 'roc_auc', min_features_to_select = 10, cv = 3, n_jobs = -1).fit(X, Y)\n",
    "\n",
    "## Appending results \n",
    "X.columns[RF_auto_feature.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbf2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[RF_auto_feature.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2665cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff0f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the decision tree on the train data-frame\n",
    "tree_md = DecisionTreeClassifier(max_depth = 3).fit(X, Y)\n",
    "\n",
    "## Visualizing the decision-tree model \n",
    "fig = plt.figure(figsize = (25, 15))\n",
    "plot_tree(tree_md, feature_names = X.columns, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f61e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize = (18, 12))\n",
    "\n",
    "sns.boxplot(ax = axes[0], x = 'failure', y = 'loading', hue = 'failure', data = train)\n",
    "sns.boxplot(ax = axes[1], x = 'failure', y = 'measurement_3', hue = 'failure', data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb0e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6fd18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8969ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3682a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the model \n",
    "knn_imputer = KNNImputer(n_neighbors = 5, weights = 'uniform')\n",
    "X_new = knn_imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8bf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.DataFrame(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a42dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6daa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be9d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b058be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040614d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['attribute_0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f755bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2330a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a89919",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f910b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708358a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f94f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['product_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b97d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bdd1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attribute_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824726a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12128b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummies = pd.get_dummies(train[['product_code', 'attribute_0', 'attribute_1']])\n",
    "train_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummies = pd.get_dummies(train[['product_code', 'attribute_0', 'attribute_1']])\n",
    "train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320796ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['failure'].value_counts() / train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de31e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dummies = pd.get_dummies(test[['product_code', 'attribute_0', 'attribute_1']])\n",
    "test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae966cd",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e23ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "120 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.5               nan 0.5        0.49144444 0.58792262 0.58791902\n",
      "        nan        nan        nan 0.5               nan 0.58762996\n",
      " 0.56935907 0.5874381  0.58743768        nan        nan        nan\n",
      " 0.5898217         nan 0.58967075 0.58672108 0.58788423 0.58788452\n",
      "        nan        nan        nan 0.58823161        nan 0.58822264\n",
      " 0.58778637 0.58779505 0.58779611        nan        nan        nan\n",
      " 0.58781017        nan 0.58779358 0.58777806 0.58774624 0.5877465\n",
      "        nan        nan        nan 0.58777439        nan 0.58774184\n",
      " 0.58775635 0.58773698 0.58773613        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test_id = test['id']\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "## Filling missing values with kNN\n",
    "knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "train = pd.DataFrame(knn_imputer.fit_transform(train), columns = train.columns)\n",
    "test = pd.DataFrame(knn_imputer.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining input and target variables\n",
    "X = train.drop(columns = ['failure'], axis = 1)\n",
    "Y = train['failure']\n",
    "\n",
    "## Scaling inputs to 0-1\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining the hyper-parameter grid\n",
    "logistic_param_grid = {'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                       'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                       'solver': ['liblinear', 'sag', 'saga']}\n",
    "\n",
    "## Performing grid search with 5 folds\n",
    "logistic_grid_search = GridSearchCV(LogisticRegression(max_iter = 1000), logistic_param_grid, cv = 5, scoring = 'roc_auc', n_jobs = -1, verbose = 1).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852e996e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "best_params = logistic_grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cfb6004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best area under the ROC cure is: 0.5898217001986322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_score = logistic_grid_search.best_score_\n",
    "print('The best area under the ROC cure is:', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59679047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, max_iter=1000, penalty='l1', solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "## Extracting the best model\n",
    "logistic_md = logistic_grid_search.best_estimator_\n",
    "print(logistic_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecb4afba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>est_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loading</td>\n",
       "      <td>2.467620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>measurement_17</td>\n",
       "      <td>0.491704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>measurement_4</td>\n",
       "      <td>0.196130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attribute_0_material_5</td>\n",
       "      <td>0.077022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>measurement_11</td>\n",
       "      <td>0.057501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>measurement_9</td>\n",
       "      <td>0.050645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>measurement_7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>measurement_8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>measurement_10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>measurement_3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>measurement_12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>measurement_13</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>measurement_14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>measurement_15</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>measurement_16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>measurement_6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>measurement_5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>attribute_0_material_7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  est_coef\n",
       "0                  loading  2.467620\n",
       "1           measurement_17  0.491704\n",
       "2            measurement_4  0.196130\n",
       "3   attribute_0_material_5  0.077022\n",
       "4           measurement_11  0.057501\n",
       "5            measurement_9  0.050645\n",
       "6            measurement_7  0.000000\n",
       "7            measurement_8  0.000000\n",
       "8           measurement_10  0.000000\n",
       "9            measurement_3  0.000000\n",
       "10          measurement_12  0.000000\n",
       "11          measurement_13  0.000000\n",
       "12          measurement_14  0.000000\n",
       "13          measurement_15  0.000000\n",
       "14          measurement_16  0.000000\n",
       "15           measurement_6  0.000000\n",
       "16           measurement_5  0.000000\n",
       "17  attribute_0_material_7  0.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_md = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X, Y)\n",
    "coefs =  pd.DataFrame({'feature': X.columns, 'est_coef': abs(logit_md.coef_.flatten())})\n",
    "coefs = coefs.sort_values(by = 'est_coef', ascending = False).reset_index(drop = True)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a26fb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5917109597291497\n"
     ]
    }
   ],
   "source": [
    "logit_1 = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:5].values], Y)\n",
    "logit_1_pred = logit_1.predict_proba(X[coefs['feature'].loc[0:5].values])[:, 1]\n",
    "logit_1_score = roc_auc_score(Y, logit_1_pred)\n",
    "print('The area under the ROC curve is:', logit_1_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_1_test_pred = logit_1.predict_proba(test[coefs['feature'].loc[0:5].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_1_test_pred})\n",
    "data_out.to_csv('Logistic_submission_top_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "989bf0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5917147420076923\n"
     ]
    }
   ],
   "source": [
    "logit_2 = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:6].values], Y)\n",
    "logit_2_pred = logit_2.predict_proba(X[coefs['feature'].loc[0:6].values])[:, 1]\n",
    "logit_2_score = roc_auc_score(Y, logit_2_pred)\n",
    "print('The area under the ROC curve is:', logit_2_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_2_test_pred = logit_2.predict_proba(test[coefs['feature'].loc[0:6].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_2_test_pred})\n",
    "data_out.to_csv('Logistic_submission_top_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "199a30df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5920820884073509\n"
     ]
    }
   ],
   "source": [
    "logit_3 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:7].values], Y)\n",
    "logit_3_pred = logit_3.predict_proba(X[coefs['feature'].loc[0:7].values])[:, 1]\n",
    "logit_3_score = roc_auc_score(Y, logit_3_pred)\n",
    "print('The area under the ROC curve is:', logit_3_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_3_test_pred = logit_3.predict_proba(test[coefs['feature'].loc[0:7].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_3_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12821c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5921029205544915\n"
     ]
    }
   ],
   "source": [
    "logit_4 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:8].values], Y)\n",
    "logit_4_pred = logit_4.predict_proba(X[coefs['feature'].loc[0:8].values])[:, 1]\n",
    "logit_4_score = roc_auc_score(Y, logit_4_pred)\n",
    "print('The area under the ROC curve is:', logit_4_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_4_test_pred = logit_4.predict_proba(test[coefs['feature'].loc[0:8].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_4_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44865685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.592213952006473\n"
     ]
    }
   ],
   "source": [
    "logit_5 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:9].values], Y)\n",
    "logit_5_pred = logit_5.predict_proba(X[coefs['feature'].loc[0:9].values])[:, 1]\n",
    "logit_5_score = roc_auc_score(Y, logit_5_pred)\n",
    "print('The area under the ROC curve is:', logit_5_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_5_test_pred = logit_5.predict_proba(test[coefs['feature'].loc[0:9].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_5_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4d9f390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5932685054175725\n"
     ]
    }
   ],
   "source": [
    "logit_6 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:10].values], Y)\n",
    "logit_6_pred = logit_6.predict_proba(X[coefs['feature'].loc[0:10].values])[:, 1]\n",
    "logit_6_score = roc_auc_score(Y, logit_6_pred)\n",
    "print('The area under the ROC curve is:', logit_6_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_6_test_pred = logit_6.predict_proba(test[coefs['feature'].loc[0:10].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_6_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b48aef7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5932727446156705\n"
     ]
    }
   ],
   "source": [
    "logit_7 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:11].values], Y)\n",
    "logit_7_pred = logit_7.predict_proba(X[coefs['feature'].loc[0:11].values])[:, 1]\n",
    "logit_7_score = roc_auc_score(Y, logit_7_pred)\n",
    "print('The area under the ROC curve is:', logit_7_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_7_test_pred = logit_7.predict_proba(test[coefs['feature'].loc[0:11].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_7_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_7.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "448b6638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5932892106426143\n"
     ]
    }
   ],
   "source": [
    "logit_8 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:12].values], Y)\n",
    "logit_8_pred = logit_8.predict_proba(X[coefs['feature'].loc[0:12].values])[:, 1]\n",
    "logit_8_score = roc_auc_score(Y, logit_8_pred)\n",
    "print('The area under the ROC curve is:', logit_8_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_8_test_pred = logit_8.predict_proba(test[coefs['feature'].loc[0:12].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_8_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_8.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b296534a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5935365141212808\n"
     ]
    }
   ],
   "source": [
    "logit_9 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:13].values], Y)\n",
    "logit_9_pred = logit_9.predict_proba(X[coefs['feature'].loc[0:13].values])[:, 1]\n",
    "logit_9_score = roc_auc_score(Y, logit_9_pred)\n",
    "print('The area under the ROC curve is:', logit_9_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_9_test_pred = logit_9.predict_proba(test[coefs['feature'].loc[0:13].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_9_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_9.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "008451ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5936143258292842\n"
     ]
    }
   ],
   "source": [
    "logit_10 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:14].values], Y)\n",
    "logit_10_pred = logit_10.predict_proba(X[coefs['feature'].loc[0:14].values])[:, 1]\n",
    "logit_10_score = roc_auc_score(Y, logit_10_pred)\n",
    "print('The area under the ROC curve is:', logit_10_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_10_test_pred = logit_10.predict_proba(test[coefs['feature'].loc[0:14].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_10_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_10.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abd3ea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.593843741753501\n"
     ]
    }
   ],
   "source": [
    "logit_11 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:15].values], Y)\n",
    "logit_11_pred = logit_11.predict_proba(X[coefs['feature'].loc[0:15].values])[:, 1]\n",
    "logit_11_score = roc_auc_score(Y, logit_11_pred)\n",
    "print('The area under the ROC curve is:', logit_11_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_11_test_pred = logit_11.predict_proba(test[coefs['feature'].loc[0:15].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_11_test_pred})\n",
    "data_out.to_csv('Logistic_submission_11.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0a8dbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5938162335039666\n"
     ]
    }
   ],
   "source": [
    "logit_12 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:16].values], Y)\n",
    "logit_12_pred = logit_12.predict_proba(X[coefs['feature'].loc[0:16].values])[:, 1]\n",
    "logit_12_score = roc_auc_score(Y, logit_12_pred)\n",
    "print('The area under the ROC curve is:', logit_12_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_12_test_pred = logit_12.predict_proba(test[coefs['feature'].loc[0:16].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_12_test_pred})\n",
    "data_out.to_csv('Logistic_submission_12.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "017de12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937585262564042\n"
     ]
    }
   ],
   "source": [
    "logit_13 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:17].values], Y)\n",
    "logit_13_pred = logit_13.predict_proba(X[coefs['feature'].loc[0:17].values])[:, 1]\n",
    "logit_13_score = roc_auc_score(Y, logit_13_pred)\n",
    "print('The area under the ROC curve is:', logit_13_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_13_test_pred = logit_13.predict_proba(test[coefs['feature'].loc[0:17].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_13_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_13.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a1a2d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937601339363217\n"
     ]
    }
   ],
   "source": [
    "logit_14 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:18].values], Y)\n",
    "logit_14_pred = logit_14.predict_proba(X[coefs['feature'].loc[0:18].values])[:, 1]\n",
    "logit_14_score = roc_auc_score(Y, logit_14_pred)\n",
    "print('The area under the ROC curve is:', logit_14_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_14_test_pred = logit_14.predict_proba(test[coefs['feature'].loc[0:18].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_14_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_14.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a01935f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937781145669769\n"
     ]
    }
   ],
   "source": [
    "logit_15 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:19].values], Y)\n",
    "logit_15_pred = logit_15.predict_proba(X[coefs['feature'].loc[0:19].values])[:, 1]\n",
    "logit_15_score = roc_auc_score(Y, logit_15_pred)\n",
    "print('The area under the ROC curve is:', logit_15_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_15_test_pred = logit_15.predict_proba(test[coefs['feature'].loc[0:19].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_15_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_15.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd579b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937811522358737\n"
     ]
    }
   ],
   "source": [
    "logit_16 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:20].values], Y)\n",
    "logit_16_pred = logit_16.predict_proba(X[coefs['feature'].loc[0:20].values])[:, 1]\n",
    "logit_16_score = roc_auc_score(Y, logit_16_pred)\n",
    "print('The area under the ROC curve is:', logit_16_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_16_test_pred = logit_16.predict_proba(test[coefs['feature'].loc[0:20].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_16_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_16.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ae48695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937849768217824\n"
     ]
    }
   ],
   "source": [
    "logit_17 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:21].values], Y)\n",
    "logit_17_pred = logit_17.predict_proba(X[coefs['feature'].loc[0:21].values])[:, 1]\n",
    "logit_17_score = roc_auc_score(Y, logit_17_pred)\n",
    "print('The area under the ROC curve is:', logit_17_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_17_test_pred = logit_17.predict_proba(test[coefs['feature'].loc[0:21].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_17_test_pred})\n",
    "data_out.to_csv('Logistic_submission_17.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a108be13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937820745364579\n"
     ]
    }
   ],
   "source": [
    "logit_18 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:22].values], Y)\n",
    "logit_18_pred = logit_18.predict_proba(X[coefs['feature'].loc[0:22].values])[:, 1]\n",
    "logit_18_score = roc_auc_score(Y, logit_18_pred)\n",
    "print('The area under the ROC curve is:', logit_18_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_18_test_pred = logit_18.predict_proba(test[coefs['feature'].loc[0:22].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_18_test_pred})\n",
    "data_out.to_csv('Logistic_submission_18.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9da2f344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5937853406651322\n"
     ]
    }
   ],
   "source": [
    "logit_19 = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', max_iter = 1000).fit(X[coefs['feature'].loc[0:23].values], Y)\n",
    "logit_19_pred = logit_19.predict_proba(X[coefs['feature'].loc[0:23].values])[:, 1]\n",
    "logit_19_score = roc_auc_score(Y, logit_19_pred)\n",
    "print('The area under the ROC curve is:', logit_19_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_19_test_pred = logit_19.predict_proba(test[coefs['feature'].loc[0:23].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_19_test_pred})\n",
    "data_out.to_csv('Logistic_submission_19.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14222e57",
   "metadata": {},
   "source": [
    "# Ensemble Logistic Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e44b9ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>failure_11</th>\n",
       "      <th>failure_12</th>\n",
       "      <th>failure_17</th>\n",
       "      <th>failure_18</th>\n",
       "      <th>failure_19</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26570</td>\n",
       "      <td>0.182794</td>\n",
       "      <td>0.183966</td>\n",
       "      <td>0.194206</td>\n",
       "      <td>0.193855</td>\n",
       "      <td>0.194325</td>\n",
       "      <td>0.189829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26571</td>\n",
       "      <td>0.143223</td>\n",
       "      <td>0.142212</td>\n",
       "      <td>0.151202</td>\n",
       "      <td>0.150841</td>\n",
       "      <td>0.151433</td>\n",
       "      <td>0.147782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26572</td>\n",
       "      <td>0.163431</td>\n",
       "      <td>0.163523</td>\n",
       "      <td>0.173477</td>\n",
       "      <td>0.173041</td>\n",
       "      <td>0.173654</td>\n",
       "      <td>0.169425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26573</td>\n",
       "      <td>0.167601</td>\n",
       "      <td>0.167822</td>\n",
       "      <td>0.176308</td>\n",
       "      <td>0.175854</td>\n",
       "      <td>0.176560</td>\n",
       "      <td>0.172829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26574</td>\n",
       "      <td>0.301532</td>\n",
       "      <td>0.302842</td>\n",
       "      <td>0.318281</td>\n",
       "      <td>0.317976</td>\n",
       "      <td>0.318431</td>\n",
       "      <td>0.311812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26575</td>\n",
       "      <td>0.142280</td>\n",
       "      <td>0.142407</td>\n",
       "      <td>0.150982</td>\n",
       "      <td>0.150678</td>\n",
       "      <td>0.151078</td>\n",
       "      <td>0.147485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26576</td>\n",
       "      <td>0.143446</td>\n",
       "      <td>0.143347</td>\n",
       "      <td>0.150532</td>\n",
       "      <td>0.150181</td>\n",
       "      <td>0.150771</td>\n",
       "      <td>0.147655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26577</td>\n",
       "      <td>0.201760</td>\n",
       "      <td>0.202467</td>\n",
       "      <td>0.214964</td>\n",
       "      <td>0.214645</td>\n",
       "      <td>0.215149</td>\n",
       "      <td>0.209797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26578</td>\n",
       "      <td>0.119192</td>\n",
       "      <td>0.119385</td>\n",
       "      <td>0.125221</td>\n",
       "      <td>0.124935</td>\n",
       "      <td>0.125428</td>\n",
       "      <td>0.122832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26579</td>\n",
       "      <td>0.153112</td>\n",
       "      <td>0.153706</td>\n",
       "      <td>0.163677</td>\n",
       "      <td>0.163363</td>\n",
       "      <td>0.163836</td>\n",
       "      <td>0.159539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  failure_11  failure_12  failure_17  failure_18  failure_19   failure\n",
       "0  26570    0.182794    0.183966    0.194206    0.193855    0.194325  0.189829\n",
       "1  26571    0.143223    0.142212    0.151202    0.150841    0.151433  0.147782\n",
       "2  26572    0.163431    0.163523    0.173477    0.173041    0.173654  0.169425\n",
       "3  26573    0.167601    0.167822    0.176308    0.175854    0.176560  0.172829\n",
       "4  26574    0.301532    0.302842    0.318281    0.317976    0.318431  0.311812\n",
       "5  26575    0.142280    0.142407    0.150982    0.150678    0.151078  0.147485\n",
       "6  26576    0.143446    0.143347    0.150532    0.150181    0.150771  0.147655\n",
       "7  26577    0.201760    0.202467    0.214964    0.214645    0.215149  0.209797\n",
       "8  26578    0.119192    0.119385    0.125221    0.124935    0.125428  0.122832\n",
       "9  26579    0.153112    0.153706    0.163677    0.163363    0.163836  0.159539"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_11 = pd.read_csv('Logistic_submission_11.csv')\n",
    "logit_11.columns = ['id', 'failure_11']\n",
    "\n",
    "logit_12 = pd.read_csv('Logistic_submission_12.csv')\n",
    "logit_12.columns = ['id', 'failure_12']\n",
    "\n",
    "logit_17 = pd.read_csv('Logistic_submission_17.csv')\n",
    "logit_17.columns = ['id', 'failure_17']\n",
    "\n",
    "logit_18 = pd.read_csv('Logistic_submission_18.csv')\n",
    "logit_18.columns = ['id', 'failure_18']\n",
    "\n",
    "logit_19 = pd.read_csv('Logistic_submission_19.csv')\n",
    "logit_19.columns = ['id', 'failure_19']\n",
    "\n",
    "logit = pd.merge(logit_11, logit_12, on = 'id')\n",
    "logit = pd.merge(logit, logit_17, on = 'id')\n",
    "logit = pd.merge(logit, logit_18, on = 'id')\n",
    "logit = pd.merge(logit, logit_19, on = 'id')\n",
    "\n",
    "w_11 = 0.593843741753501\n",
    "w_12 = 0.5938162335039666\n",
    "w_17 = 0.5937849768217824\n",
    "w_18 = 0.5937820745364579\n",
    "w_19 = 0.5937853406651322\n",
    "w_tot = w_11 + w_12 + w_17 + w_18 + w_19\n",
    "\n",
    "w_11 = w_11 / w_tot\n",
    "w_12 = w_12 / w_tot\n",
    "w_17 = w_17 / w_tot\n",
    "w_18 = w_18 / w_tot\n",
    "w_19 = w_19 / w_tot\n",
    "\n",
    "logit['failure'] = w_11*logit['failure_11'] + w_12*logit['failure_12'] + w_17*logit['failure_17'] + w_18*logit['failure_18'] + w_19*logit['failure_19']\n",
    "logit.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05d55252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26570</td>\n",
       "      <td>0.189829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26571</td>\n",
       "      <td>0.147782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26572</td>\n",
       "      <td>0.169425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26573</td>\n",
       "      <td>0.172829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26574</td>\n",
       "      <td>0.311812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   failure\n",
       "0  26570  0.189829\n",
       "1  26571  0.147782\n",
       "2  26572  0.169425\n",
       "3  26573  0.172829\n",
       "4  26574  0.311812"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = logit[['id', 'failure']]\n",
    "logit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5338bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.to_csv('Logistic_submission_ensemble.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9fa57",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3a5082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test_id = test['id']\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "## Filling missing values with kNN\n",
    "knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "train = pd.DataFrame(knn_imputer.fit_transform(train), columns = train.columns)\n",
    "test = pd.DataFrame(knn_imputer.fit_transform(test), columns = test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b3c8879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_measurement = train.drop(columns = ['loading', 'attribute_2', 'attribute_3', 'measurement_17', 'failure', 'attribute_0_material_5', 'attribute_0_material_7'], axis = 1)\n",
    "test_measurement = test.drop(columns = ['loading', 'attribute_2', 'attribute_3', 'measurement_17', 'attribute_0_material_5', 'attribute_0_material_7'], axis = 1)\n",
    "\n",
    "train_measurement_trans = scaler.fit_transform(train_measurement)\n",
    "test_measurement_trans = scaler.fit_transform(test_measurement)\n",
    "\n",
    "## Running PCA\n",
    "pca = PCA(n_components = 10, svd_solver = 'full').fit(train_measurement_trans)\n",
    "\n",
    "## Creating component names\n",
    "components = ['component_' + str(i) for i in range(1, 11)]\n",
    "\n",
    "prin_comp_train = pd.DataFrame(pca.transform(train_measurement_trans), columns = components)\n",
    "prin_comp_test = pd.DataFrame(pca.transform(test_measurement_trans), columns = components)\n",
    "\n",
    "train = pd.concat([train, prin_comp_train], axis = 1)\n",
    "test = pd.concat([test, prin_comp_test], axis = 1)\n",
    "\n",
    "train = train.drop(columns = ['measurement_' + str(i) for i in range(3, 17)], axis = 1)\n",
    "test = test.drop(columns = ['measurement_' + str(i) for i in range(3, 17)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0f84b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature engineering \n",
    "train['area'] = train['attribute_2'] * train['attribute_3']\n",
    "test['area'] = test['attribute_2'] * test['attribute_3']\n",
    "\n",
    "train = train.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)\n",
    "test = test.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46f37314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.5               nan 0.5        0.50394386 0.59189669 0.59193825\n",
      " 0.50072797        nan 0.58747703 0.57594994 0.58914188 0.5891445\n",
      " 0.58966553        nan 0.5901794  0.58818055 0.58900808 0.58900681\n",
      " 0.58925803        nan 0.58925937 0.58894681 0.58891164 0.58891354\n",
      " 0.58893922        nan 0.58891372 0.58888397 0.58887323 0.58887323\n",
      " 0.588894          nan 0.58887297 0.58886549 0.58886836 0.58886815]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Filling missing values with kNN\n",
    "# knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "# train = pd.DataFrame(knn_imputer.fit_transform(train), columns = train.columns)\n",
    "# test = pd.DataFrame(knn_imputer.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining input and target variables\n",
    "X = train.drop(columns = ['failure'], axis = 1)\n",
    "Y = train['failure']\n",
    "\n",
    "## Scaling inputs to 0-1\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining the hyper-parameter grid\n",
    "logistic_param_grid = {'penalty': ['l1', 'l2'],\n",
    "                       'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                       'solver': ['liblinear', 'sag', 'saga']}\n",
    "\n",
    "## Performing grid search with 5 folds\n",
    "logistic_grid_search = GridSearchCV(LogisticRegression(max_iter = 10000), logistic_param_grid, cv = 5, scoring = 'roc_auc', n_jobs = -1, verbose = 1).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a6156ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best area under the ROC cure is: 0.5919382524712525\n",
      "{'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "LogisticRegression(C=0.001, max_iter=10000, solver='saga')\n"
     ]
    }
   ],
   "source": [
    "## Extracting best auc score\n",
    "best_score = logistic_grid_search.best_score_\n",
    "print('The best area under the ROC cure is:', best_score)\n",
    "\n",
    "## Extracting the best parameters\n",
    "best_params = logistic_grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "## Extracting the best model\n",
    "logistic_md = logistic_grid_search.best_estimator_\n",
    "print(logistic_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8b16add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>est_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loading</td>\n",
       "      <td>0.145958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>measurement_17</td>\n",
       "      <td>0.035316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>area</td>\n",
       "      <td>0.024280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attribute_0_material_5</td>\n",
       "      <td>0.021656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attribute_0_material_7</td>\n",
       "      <td>0.021655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>component_7</td>\n",
       "      <td>0.021434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>component_1</td>\n",
       "      <td>0.017620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>component_9</td>\n",
       "      <td>0.016114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>component_2</td>\n",
       "      <td>0.007632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>component_4</td>\n",
       "      <td>0.007206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>component_10</td>\n",
       "      <td>0.005867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>component_6</td>\n",
       "      <td>0.005075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>component_3</td>\n",
       "      <td>0.003631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>component_5</td>\n",
       "      <td>0.002725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>component_8</td>\n",
       "      <td>0.000803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  est_coef\n",
       "0                  loading  0.145958\n",
       "1           measurement_17  0.035316\n",
       "2                     area  0.024280\n",
       "3   attribute_0_material_5  0.021656\n",
       "4   attribute_0_material_7  0.021655\n",
       "5              component_7  0.021434\n",
       "6              component_1  0.017620\n",
       "7              component_9  0.016114\n",
       "8              component_2  0.007632\n",
       "9              component_4  0.007206\n",
       "10            component_10  0.005867\n",
       "11             component_6  0.005075\n",
       "12             component_3  0.003631\n",
       "13             component_5  0.002725\n",
       "14             component_8  0.000803"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_md = LogisticRegression(C = 0.001, penalty = 'l2', solver = 'saga', max_iter = 1000).fit(X, Y)\n",
    "coefs =  pd.DataFrame({'feature': X.columns, 'est_coef': abs(logit_md.coef_.flatten())})\n",
    "coefs = coefs.sort_values(by = 'est_coef', ascending = False).reset_index(drop = True)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b93ea72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5680349198908752\n"
     ]
    }
   ],
   "source": [
    "logit_1 = LogisticRegression(C = 0.001, penalty = 'l2', solver = 'saga', max_iter = 10000).fit(X[coefs['feature'].loc[0:10].values], Y)\n",
    "logit_1_pred = logit_1.predict_proba(X[coefs['feature'].loc[0:10].values])[:, 1]\n",
    "logit_1_score = roc_auc_score(Y, logit_1_pred)\n",
    "print('The area under the ROC curve is:', logit_1_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_1_test_pred = logit_1.predict_proba(test[coefs['feature'].loc[0:10].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "# data_out = pd.DataFrame({'id': test_id, 'failure': logit_1_test_pred})\n",
    "# data_out.to_csv('Logistic_submission_top_6_area.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0225d0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loading</th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>measurement_4</th>\n",
       "      <th>measurement_5</th>\n",
       "      <th>measurement_6</th>\n",
       "      <th>measurement_7</th>\n",
       "      <th>measurement_8</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "      <th>failure</th>\n",
       "      <th>attribute_0_material_5</th>\n",
       "      <th>attribute_0_material_7</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.10</td>\n",
       "      <td>18.040</td>\n",
       "      <td>12.518</td>\n",
       "      <td>15.748</td>\n",
       "      <td>19.292</td>\n",
       "      <td>11.739</td>\n",
       "      <td>20.155</td>\n",
       "      <td>10.672</td>\n",
       "      <td>15.859</td>\n",
       "      <td>17.594</td>\n",
       "      <td>15.193</td>\n",
       "      <td>15.029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.034</td>\n",
       "      <td>14.684</td>\n",
       "      <td>764.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.89</td>\n",
       "      <td>18.213</td>\n",
       "      <td>11.540</td>\n",
       "      <td>17.717</td>\n",
       "      <td>17.893</td>\n",
       "      <td>12.748</td>\n",
       "      <td>17.889</td>\n",
       "      <td>12.448</td>\n",
       "      <td>17.947</td>\n",
       "      <td>17.915</td>\n",
       "      <td>11.755</td>\n",
       "      <td>14.732</td>\n",
       "      <td>15.425</td>\n",
       "      <td>14.395</td>\n",
       "      <td>15.631</td>\n",
       "      <td>682.057</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.43</td>\n",
       "      <td>18.057</td>\n",
       "      <td>11.652</td>\n",
       "      <td>16.738</td>\n",
       "      <td>18.240</td>\n",
       "      <td>12.718</td>\n",
       "      <td>18.288</td>\n",
       "      <td>12.715</td>\n",
       "      <td>15.607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.798</td>\n",
       "      <td>16.711</td>\n",
       "      <td>18.631</td>\n",
       "      <td>14.094</td>\n",
       "      <td>17.946</td>\n",
       "      <td>663.376</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.07</td>\n",
       "      <td>17.295</td>\n",
       "      <td>11.188</td>\n",
       "      <td>18.576</td>\n",
       "      <td>18.339</td>\n",
       "      <td>12.583</td>\n",
       "      <td>19.060</td>\n",
       "      <td>12.471</td>\n",
       "      <td>16.346</td>\n",
       "      <td>18.377</td>\n",
       "      <td>10.020</td>\n",
       "      <td>15.250</td>\n",
       "      <td>15.562</td>\n",
       "      <td>16.154</td>\n",
       "      <td>17.172</td>\n",
       "      <td>826.282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188.06</td>\n",
       "      <td>19.346</td>\n",
       "      <td>12.950</td>\n",
       "      <td>16.990</td>\n",
       "      <td>15.746</td>\n",
       "      <td>11.306</td>\n",
       "      <td>18.093</td>\n",
       "      <td>10.337</td>\n",
       "      <td>17.082</td>\n",
       "      <td>19.932</td>\n",
       "      <td>12.428</td>\n",
       "      <td>16.182</td>\n",
       "      <td>12.760</td>\n",
       "      <td>13.153</td>\n",
       "      <td>16.412</td>\n",
       "      <td>579.885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loading  measurement_3  measurement_4  measurement_5  measurement_6  \\\n",
       "0    80.10         18.040         12.518         15.748         19.292   \n",
       "1    84.89         18.213         11.540         17.717         17.893   \n",
       "2    82.43         18.057         11.652         16.738         18.240   \n",
       "3   101.07         17.295         11.188         18.576         18.339   \n",
       "4   188.06         19.346         12.950         16.990         15.746   \n",
       "\n",
       "   measurement_7  measurement_8  measurement_9  measurement_10  \\\n",
       "0         11.739         20.155         10.672          15.859   \n",
       "1         12.748         17.889         12.448          17.947   \n",
       "2         12.718         18.288         12.715          15.607   \n",
       "3         12.583         19.060         12.471          16.346   \n",
       "4         11.306         18.093         10.337          17.082   \n",
       "\n",
       "   measurement_11  measurement_12  measurement_13  measurement_14  \\\n",
       "0          17.594          15.193          15.029             NaN   \n",
       "1          17.915          11.755          14.732          15.425   \n",
       "2             NaN          13.798          16.711          18.631   \n",
       "3          18.377          10.020          15.250          15.562   \n",
       "4          19.932          12.428          16.182          12.760   \n",
       "\n",
       "   measurement_15  measurement_16  measurement_17  failure  \\\n",
       "0          13.034          14.684         764.100        0   \n",
       "1          14.395          15.631         682.057        0   \n",
       "2          14.094          17.946         663.376        0   \n",
       "3          16.154          17.172         826.282        0   \n",
       "4          13.153          16.412         579.885        0   \n",
       "\n",
       "   attribute_0_material_5  attribute_0_material_7  area  \n",
       "0                       0                       1    45  \n",
       "1                       0                       1    45  \n",
       "2                       0                       1    45  \n",
       "3                       0                       1    45  \n",
       "4                       0                       1    45  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd85b268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='failure', ylabel='area'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(data = train, y = 'area', x = 'failure', hue = 'failure')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f86cac2",
   "metadata": {},
   "source": [
    "# Imputing by Product Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56057240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test_id = test['id']\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "## Filling missing values with kNN\n",
    "# knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "# train = pd.DataFrame(knn_imputer.fit_transform(train), columns = train.columns)\n",
    "# test = pd.DataFrame(knn_imputer.fit_transform(test), columns = test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e745c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_impute_by_product(data):\n",
    "    \n",
    "    ## Extracting product codes\n",
    "    prod_code = data['product_code'].unique()\n",
    "    \n",
    "    ## Defining the k-NN model\n",
    "    knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "    \n",
    "    ## Defining list to store data \n",
    "    data_out = list()\n",
    "    \n",
    "    for i in range(0, len(prod_code)):\n",
    "        \n",
    "        ## Subsetting the data \n",
    "        data_temp = data[data['product_code'] == prod_code[i]].reset_index(drop = True)\n",
    "        data_temp = data_temp.drop(columns = 'product_code', axis = 1)\n",
    "        \n",
    "        ## k-NN imputation\n",
    "        data_temp = pd.DataFrame(knn_imputer.fit_transform(data_temp), columns = data.columns[1:])\n",
    "        \n",
    "        ## Storing imputed data\n",
    "        data_out.append(data_temp)\n",
    "        \n",
    "    return pd.concat(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c42b6787",
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-NN imputation\n",
    "train = knn_impute_by_product(train)\n",
    "test = knn_impute_by_product(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9353e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature engineering \n",
    "train['area'] = train['attribute_2'] * train['attribute_3']\n",
    "test['area'] = test['attribute_2'] * test['attribute_3']\n",
    "\n",
    "group_1 = [f\"measurement_{i:d}\" for i in list(range(3, 5)) + list(range(9, 17))]\n",
    "train['group_1_avg'] = np.mean(train[group_1], axis = 1)\n",
    "train['group_1_std'] = np.std(train[group_1], axis = 1)\n",
    "train['group_1_IQR'] = np.percentile(train[group_1], 75) - np.percentile(train[group_1], 25)\n",
    "train['group_1_min'] = train[group_1].min(axis = 1)\n",
    "train['group_1_max'] = train[group_1].max(axis = 1)\n",
    "\n",
    "test['group_1_avg'] = np.mean(test[group_1], axis = 1)\n",
    "test['group_1_std'] = np.std(test[group_1], axis = 1) \n",
    "test['group_1_IQR'] = np.percentile(test[group_1], 75) - np.percentile(test[group_1], 25)\n",
    "test['group_1_min'] = test[group_1].min(axis = 1)\n",
    "test['group_1_max'] = test[group_1].max(axis = 1)\n",
    "\n",
    "\n",
    "group_2 = [f\"measurement_{i:d}\" for i in list(range(5, 9))]\n",
    "train['group_2_avg'] = np.mean(train[group_2], axis = 1)\n",
    "train['group_2_std'] = np.std(train[group_2], axis = 1)\n",
    "train['group_2_IQR'] = np.percentile(train[group_2], 75) - np.percentile(train[group_2], 25)\n",
    "train['group_2_min'] = train[group_2].min(axis = 1)\n",
    "train['group_2_max'] = train[group_2].max(axis = 1)\n",
    "\n",
    "test['group_2_avg'] = np.mean(test[group_2], axis = 1)\n",
    "test['group_2_std'] = np.std(test[group_2], axis = 1)\n",
    "test['group_2_IQR'] = np.percentile(test[group_2], 75) - np.percentile(test[group_2], 25)\n",
    "test['group_2_min'] = test[group_2].min(axis = 1)\n",
    "test['group_2_max'] = test[group_2].max(axis = 1)\n",
    "\n",
    "train = train.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)\n",
    "test = test.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)\n",
    "\n",
    "train = train.drop(columns = group_1, axis = 1)\n",
    "train = train.drop(columns = group_2, axis = 1)\n",
    "\n",
    "test = test.drop(columns = group_1, axis = 1)\n",
    "test = test.drop(columns = group_2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85032db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loading</th>\n",
       "      <th>measurement_17</th>\n",
       "      <th>failure</th>\n",
       "      <th>attribute_0_material_5</th>\n",
       "      <th>attribute_0_material_7</th>\n",
       "      <th>area</th>\n",
       "      <th>group_1_avg</th>\n",
       "      <th>group_1_std</th>\n",
       "      <th>group_1_IQR</th>\n",
       "      <th>group_1_min</th>\n",
       "      <th>group_1_max</th>\n",
       "      <th>group_2_avg</th>\n",
       "      <th>group_2_std</th>\n",
       "      <th>group_2_IQR</th>\n",
       "      <th>group_2_min</th>\n",
       "      <th>group_2_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.10</td>\n",
       "      <td>764.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.698816</td>\n",
       "      <td>2.123658</td>\n",
       "      <td>4.64352</td>\n",
       "      <td>10.672</td>\n",
       "      <td>18.04000</td>\n",
       "      <td>16.73350</td>\n",
       "      <td>3.322982</td>\n",
       "      <td>3.997</td>\n",
       "      <td>11.739</td>\n",
       "      <td>20.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.89</td>\n",
       "      <td>682.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>2.398674</td>\n",
       "      <td>4.64352</td>\n",
       "      <td>11.540</td>\n",
       "      <td>18.21300</td>\n",
       "      <td>16.56175</td>\n",
       "      <td>2.203016</td>\n",
       "      <td>3.997</td>\n",
       "      <td>12.748</td>\n",
       "      <td>17.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.43</td>\n",
       "      <td>663.376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.784577</td>\n",
       "      <td>2.454714</td>\n",
       "      <td>4.64352</td>\n",
       "      <td>11.652</td>\n",
       "      <td>18.63477</td>\n",
       "      <td>16.49600</td>\n",
       "      <td>2.268515</td>\n",
       "      <td>3.997</td>\n",
       "      <td>12.718</td>\n",
       "      <td>18.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.07</td>\n",
       "      <td>826.282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.983500</td>\n",
       "      <td>2.657732</td>\n",
       "      <td>4.64352</td>\n",
       "      <td>10.020</td>\n",
       "      <td>18.37700</td>\n",
       "      <td>17.13950</td>\n",
       "      <td>2.643499</td>\n",
       "      <td>3.997</td>\n",
       "      <td>12.583</td>\n",
       "      <td>19.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188.06</td>\n",
       "      <td>579.885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.058200</td>\n",
       "      <td>3.031408</td>\n",
       "      <td>4.64352</td>\n",
       "      <td>10.337</td>\n",
       "      <td>19.93200</td>\n",
       "      <td>15.53375</td>\n",
       "      <td>2.578243</td>\n",
       "      <td>3.997</td>\n",
       "      <td>11.306</td>\n",
       "      <td>18.093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loading  measurement_17  failure  attribute_0_material_5  \\\n",
       "0    80.10         764.100      0.0                     0.0   \n",
       "1    84.89         682.057      0.0                     0.0   \n",
       "2    82.43         663.376      0.0                     0.0   \n",
       "3   101.07         826.282      0.0                     0.0   \n",
       "4   188.06         579.885      0.0                     0.0   \n",
       "\n",
       "   attribute_0_material_7  area  group_1_avg  group_1_std  group_1_IQR  \\\n",
       "0                     1.0  45.0    14.698816     2.123658      4.64352   \n",
       "1                     1.0  45.0    15.000100     2.398674      4.64352   \n",
       "2                     1.0  45.0    15.784577     2.454714      4.64352   \n",
       "3                     1.0  45.0    14.983500     2.657732      4.64352   \n",
       "4                     1.0  45.0    15.058200     3.031408      4.64352   \n",
       "\n",
       "   group_1_min  group_1_max  group_2_avg  group_2_std  group_2_IQR  \\\n",
       "0       10.672     18.04000     16.73350     3.322982        3.997   \n",
       "1       11.540     18.21300     16.56175     2.203016        3.997   \n",
       "2       11.652     18.63477     16.49600     2.268515        3.997   \n",
       "3       10.020     18.37700     17.13950     2.643499        3.997   \n",
       "4       10.337     19.93200     15.53375     2.578243        3.997   \n",
       "\n",
       "   group_2_min  group_2_max  \n",
       "0       11.739       20.155  \n",
       "1       12.748       17.893  \n",
       "2       12.718       18.288  \n",
       "3       12.583       19.060  \n",
       "4       11.306       18.093  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0e0ca8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.5               nan 0.5        0.4913598  0.58750938 0.58750904\n",
      " 0.50072797        nan 0.58750034 0.57663227 0.58827259 0.588275\n",
      " 0.5900976         nan 0.59018491 0.58988232 0.58948926 0.58948719\n",
      " 0.58951128        nan 0.58960177 0.58938549 0.58917278 0.58917304\n",
      " 0.58913425        nan 0.58894913 0.58904516 0.58896893 0.5889694\n",
      " 0.58913877        nan 0.58887393 0.5888829  0.58887795 0.58887719]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Defining input and target variables\n",
    "X = train.drop(columns = ['failure'], axis = 1)\n",
    "Y = train['failure']\n",
    "\n",
    "## Scaling inputs to 0-1\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining the hyper-parameter grid\n",
    "logistic_param_grid = {'penalty': ['l1', 'l2'],\n",
    "                       'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                       'solver': ['liblinear', 'sag', 'saga']}\n",
    "\n",
    "## Performing grid search with 5 folds\n",
    "logistic_grid_search = GridSearchCV(LogisticRegression(max_iter = 10000), logistic_param_grid, cv = 5, scoring = 'roc_auc', n_jobs = -1, verbose = 1).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "defad967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best area under the ROC cure is: 0.5901849079405923\n",
      "{'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "LogisticRegression(C=0.1, max_iter=10000, penalty='l1', solver='saga')\n"
     ]
    }
   ],
   "source": [
    "## Extracting best auc score\n",
    "best_score = logistic_grid_search.best_score_\n",
    "print('The best area under the ROC cure is:', best_score)\n",
    "\n",
    "## Extracting the best parameters\n",
    "best_params = logistic_grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "## Extracting the best model\n",
    "logistic_md = logistic_grid_search.best_estimator_\n",
    "print(logistic_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be205860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>est_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loading</td>\n",
       "      <td>2.520016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>group_2_avg</td>\n",
       "      <td>0.342762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>measurement_17</td>\n",
       "      <td>0.249400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area</td>\n",
       "      <td>0.045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attribute_0_material_5</td>\n",
       "      <td>0.022742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>attribute_0_material_7</td>\n",
       "      <td>0.016343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>group_1_max</td>\n",
       "      <td>0.008903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>group_1_avg</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>group_1_std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>group_1_IQR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>group_1_min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>group_2_std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>group_2_IQR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>group_2_min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>group_2_max</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  est_coef\n",
       "0                  loading  2.520016\n",
       "1              group_2_avg  0.342762\n",
       "2           measurement_17  0.249400\n",
       "3                     area  0.045618\n",
       "4   attribute_0_material_5  0.022742\n",
       "5   attribute_0_material_7  0.016343\n",
       "6              group_1_max  0.008903\n",
       "7              group_1_avg  0.000000\n",
       "8              group_1_std  0.000000\n",
       "9              group_1_IQR  0.000000\n",
       "10             group_1_min  0.000000\n",
       "11             group_2_std  0.000000\n",
       "12             group_2_IQR  0.000000\n",
       "13             group_2_min  0.000000\n",
       "14             group_2_max  0.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_md = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'saga', max_iter = 1000).fit(X, Y)\n",
    "coefs =  pd.DataFrame({'feature': X.columns, 'est_coef': abs(logit_md.coef_.flatten())})\n",
    "coefs = coefs.sort_values(by = 'est_coef', ascending = False).reset_index(drop = True)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ef2bb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the ROC curve is: 0.5910694446732568\n"
     ]
    }
   ],
   "source": [
    "logit_1 = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'saga', max_iter = 10000).fit(X[coefs['feature'].loc[0:6].values], Y)\n",
    "logit_1_pred = logit_1.predict_proba(X[coefs['feature'].loc[0:6].values])[:, 1]\n",
    "logit_1_score = roc_auc_score(Y, logit_1_pred)\n",
    "print('The area under the ROC curve is:', logit_1_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_1_test_pred = logit_1.predict_proba(test[coefs['feature'].loc[0:6].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_1_test_pred})\n",
    "data_out.to_csv('Logistic_submission_top_6_area_knn_avg_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22f96ed",
   "metadata": {},
   "source": [
    "## Another Look 08/09/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b0b74e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'analytics-data-science-competitions'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key_1 = 'Tabular-Playground-Aug-2022/train.csv'\n",
    "file_key_2 = 'Tabular-Playground-Aug-2022/test.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading data-files\n",
    "train = pd.read_csv(file_content_stream_1)\n",
    "train = train.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "test = pd.read_csv(file_content_stream_2)\n",
    "test_id = test['id']\n",
    "test = test.drop(columns = ['id'], axis = 1)\n",
    "\n",
    "## Changing labels to dummies\n",
    "train_dummies = pd.get_dummies(train[['attribute_0']])\n",
    "train = train.drop(columns = ['attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# train = train.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "train = pd.concat([train, train_dummies], axis = 1)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['attribute_0']])\n",
    "test = test.drop(columns = ['attribute_0', 'attribute_1', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "# test = test.drop(columns = ['product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2'], axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis = 1)\n",
    "\n",
    "def knn_impute_by_product(data):\n",
    "    \n",
    "    ## Extracting product codes\n",
    "    prod_code = data['product_code'].unique()\n",
    "    \n",
    "    ## Defining the k-NN model\n",
    "    knn_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
    "    \n",
    "    ## Defining list to store data \n",
    "    data_out = list()\n",
    "    \n",
    "    for i in range(0, len(prod_code)):\n",
    "        \n",
    "        ## Subsetting the data \n",
    "        data_temp = data[data['product_code'] == prod_code[i]].reset_index(drop = True)\n",
    "        data_temp = data_temp.drop(columns = 'product_code', axis = 1)\n",
    "        \n",
    "        ## k-NN imputation\n",
    "        data_temp = pd.DataFrame(knn_imputer.fit_transform(data_temp), columns = data.columns[1:])\n",
    "        \n",
    "        ## Storing imputed data\n",
    "        data_out.append(data_temp)\n",
    "        \n",
    "    return pd.concat(data_out)\n",
    "\n",
    "## k-NN imputation\n",
    "train = knn_impute_by_product(train)\n",
    "test = knn_impute_by_product(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64370ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature engineering \n",
    "train['area'] = train['attribute_2'] * train['attribute_3']\n",
    "test['area'] = test['attribute_2'] * test['attribute_3']\n",
    "\n",
    "group_1 = [f\"measurement_{i:d}\" for i in list(range(3, 5)) + list(range(9, 17))]\n",
    "train['group_1_avg'] = np.mean(train[group_1], axis = 1)\n",
    "train['group_1_std'] = np.std(train[group_1], axis = 1)\n",
    "train['group_1_IQR'] = np.percentile(train[group_1], 75) - np.percentile(train[group_1], 25)\n",
    "train['group_1_min'] = train[group_1].min(axis = 1)\n",
    "train['group_1_max'] = train[group_1].max(axis = 1)\n",
    "train['group_1_pct_values_above_mean'] = np.sum((train[group_1] - np.mean(train[group_1], axis = 0)) > 0, axis = 1)\n",
    "\n",
    "test['group_1_avg'] = np.mean(test[group_1], axis = 1)\n",
    "test['group_1_std'] = np.std(test[group_1], axis = 1) \n",
    "test['group_1_IQR'] = np.percentile(test[group_1], 75) - np.percentile(test[group_1], 25)\n",
    "test['group_1_min'] = test[group_1].min(axis = 1)\n",
    "test['group_1_max'] = test[group_1].max(axis = 1)\n",
    "test['group_1_pct_values_above_mean'] = np.sum((test[group_1] - np.mean(test[group_1], axis = 0)) > 0, axis = 1)\n",
    "\n",
    "\n",
    "group_2 = [f\"measurement_{i:d}\" for i in list(range(5, 9))]\n",
    "train['group_2_avg'] = np.mean(train[group_2], axis = 1)\n",
    "train['group_2_std'] = np.std(train[group_2], axis = 1)\n",
    "train['group_2_IQR'] = np.percentile(train[group_2], 75) - np.percentile(train[group_2], 25)\n",
    "train['group_2_min'] = train[group_2].min(axis = 1)\n",
    "train['group_2_max'] = train[group_2].max(axis = 1)\n",
    "train['group_2_pct_values_above_mean'] = np.sum((train[group_2] - np.mean(train[group_2], axis = 0)) > 0, axis = 1)\n",
    "\n",
    "\n",
    "test['group_2_avg'] = np.mean(test[group_2], axis = 1)\n",
    "test['group_2_std'] = np.std(test[group_2], axis = 1)\n",
    "test['group_2_IQR'] = np.percentile(test[group_2], 75) - np.percentile(test[group_2], 25)\n",
    "test['group_2_min'] = test[group_2].min(axis = 1)\n",
    "test['group_2_max'] = test[group_2].max(axis = 1)\n",
    "test['group_2_pct_values_above_mean'] = np.sum((test[group_2] - np.mean(test[group_2], axis = 0)) > 0, axis = 1)\n",
    "\n",
    "\n",
    "train = train.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)\n",
    "test = test.drop(columns = ['attribute_2', 'attribute_3'], axis = 1)\n",
    "\n",
    "train = train.drop(columns = group_1, axis = 1)\n",
    "train = train.drop(columns = group_2, axis = 1)\n",
    "\n",
    "test = test.drop(columns = group_1, axis = 1)\n",
    "test = test.drop(columns = group_2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f603b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='failure', ylabel='pct_values_above_mean'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data = train, x = 'failure', y = 'pct_values_above_mean', hue = 'failure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66332480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "measurement_3     17.790800\n",
       "measurement_4     11.732665\n",
       "measurement_9     11.428563\n",
       "measurement_10    16.122489\n",
       "measurement_11    19.171328\n",
       "measurement_12    11.700378\n",
       "measurement_13    15.646933\n",
       "measurement_14    16.037245\n",
       "measurement_15    15.001662\n",
       "measurement_16    16.463504\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train[group_1] - \n",
    "np.mean(train[group_1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d049dc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>measurement_4</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.040</td>\n",
       "      <td>12.518</td>\n",
       "      <td>10.672</td>\n",
       "      <td>15.859</td>\n",
       "      <td>17.59400</td>\n",
       "      <td>15.193</td>\n",
       "      <td>15.029</td>\n",
       "      <td>14.365157</td>\n",
       "      <td>13.034</td>\n",
       "      <td>14.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.213</td>\n",
       "      <td>11.540</td>\n",
       "      <td>12.448</td>\n",
       "      <td>17.947</td>\n",
       "      <td>17.91500</td>\n",
       "      <td>11.755</td>\n",
       "      <td>14.732</td>\n",
       "      <td>15.425000</td>\n",
       "      <td>14.395</td>\n",
       "      <td>15.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.057</td>\n",
       "      <td>11.652</td>\n",
       "      <td>12.715</td>\n",
       "      <td>15.607</td>\n",
       "      <td>18.63477</td>\n",
       "      <td>13.798</td>\n",
       "      <td>16.711</td>\n",
       "      <td>18.631000</td>\n",
       "      <td>14.094</td>\n",
       "      <td>17.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.295</td>\n",
       "      <td>11.188</td>\n",
       "      <td>12.471</td>\n",
       "      <td>16.346</td>\n",
       "      <td>18.37700</td>\n",
       "      <td>10.020</td>\n",
       "      <td>15.250</td>\n",
       "      <td>15.562000</td>\n",
       "      <td>16.154</td>\n",
       "      <td>17.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.346</td>\n",
       "      <td>12.950</td>\n",
       "      <td>10.337</td>\n",
       "      <td>17.082</td>\n",
       "      <td>19.93200</td>\n",
       "      <td>12.428</td>\n",
       "      <td>16.182</td>\n",
       "      <td>12.760000</td>\n",
       "      <td>13.153</td>\n",
       "      <td>16.412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   measurement_3  measurement_4  measurement_9  measurement_10  \\\n",
       "0         18.040         12.518         10.672          15.859   \n",
       "1         18.213         11.540         12.448          17.947   \n",
       "2         18.057         11.652         12.715          15.607   \n",
       "3         17.295         11.188         12.471          16.346   \n",
       "4         19.346         12.950         10.337          17.082   \n",
       "\n",
       "   measurement_11  measurement_12  measurement_13  measurement_14  \\\n",
       "0        17.59400          15.193          15.029       14.365157   \n",
       "1        17.91500          11.755          14.732       15.425000   \n",
       "2        18.63477          13.798          16.711       18.631000   \n",
       "3        18.37700          10.020          15.250       15.562000   \n",
       "4        19.93200          12.428          16.182       12.760000   \n",
       "\n",
       "   measurement_15  measurement_16  \n",
       "0          13.034          14.684  \n",
       "1          14.395          15.631  \n",
       "2          14.094          17.946  \n",
       "3          16.154          17.172  \n",
       "4          13.153          16.412  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[group_1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "454c1b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       4\n",
       "2       6\n",
       "3       4\n",
       "4       6\n",
       "       ..\n",
       "5338    5\n",
       "5339    3\n",
       "5340    3\n",
       "5341    5\n",
       "5342    5\n",
       "Length: 26570, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((train[group_1] - np.mean(train[group_1], axis = 0)) > 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b27a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.5               nan 0.5        0.4913598  0.58750823 0.58751031\n",
      " 0.50072797        nan 0.58750034 0.57663227 0.58827407 0.58827246\n",
      " 0.59009388        nan 0.59018338 0.58988232 0.5894874  0.58948871\n",
      " 0.58950214        nan 0.58960266 0.58938549 0.58917304 0.58917312\n",
      " 0.58918743        nan 0.58894998 0.58904516 0.58896893 0.5889694\n",
      " 0.58907634        nan 0.58887385 0.5888829  0.58887791 0.58887719]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Defining input and target variables\n",
    "X = train.drop(columns = ['failure'], axis = 1)\n",
    "Y = train['failure']\n",
    "\n",
    "## Scaling inputs to 0-1\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns = test.columns)\n",
    "\n",
    "## Defining the hyper-parameter grid\n",
    "logistic_param_grid = {'penalty': ['l1', 'l2'],\n",
    "                       'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                       'solver': ['liblinear', 'sag', 'saga']}\n",
    "\n",
    "## Performing grid search with 5 folds\n",
    "logistic_grid_search = GridSearchCV(LogisticRegression(max_iter = 10000), logistic_param_grid, cv = 5, scoring = 'roc_auc', n_jobs = -1, verbose = 1).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ab2849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best area under the ROC cure is: 0.5901833835952023\n",
      "{'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "LogisticRegression(C=0.1, max_iter=10000, penalty='l1', solver='saga')\n"
     ]
    }
   ],
   "source": [
    "## Extracting best auc score\n",
    "best_score = logistic_grid_search.best_score_\n",
    "print('The best area under the ROC cure is:', best_score)\n",
    "\n",
    "## Extracting the best parameters\n",
    "best_params = logistic_grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "## Extracting the best model\n",
    "logistic_md = logistic_grid_search.best_estimator_\n",
    "print(logistic_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d8136eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>est_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loading</td>\n",
       "      <td>2.520023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>group_2_avg</td>\n",
       "      <td>0.342848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>measurement_17</td>\n",
       "      <td>0.249331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area</td>\n",
       "      <td>0.045554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attribute_0_material_7</td>\n",
       "      <td>0.019599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>attribute_0_material_5</td>\n",
       "      <td>0.019409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>group_1_max</td>\n",
       "      <td>0.008935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>group_1_avg</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>group_1_std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>group_1_IQR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>group_1_min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>group_2_std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>group_2_IQR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>group_2_min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>group_2_max</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  est_coef\n",
       "0                  loading  2.520023\n",
       "1              group_2_avg  0.342848\n",
       "2           measurement_17  0.249331\n",
       "3                     area  0.045554\n",
       "4   attribute_0_material_7  0.019599\n",
       "5   attribute_0_material_5  0.019409\n",
       "6              group_1_max  0.008935\n",
       "7              group_1_avg  0.000000\n",
       "8              group_1_std  0.000000\n",
       "9              group_1_IQR  0.000000\n",
       "10             group_1_min  0.000000\n",
       "11             group_2_std  0.000000\n",
       "12             group_2_IQR  0.000000\n",
       "13             group_2_min  0.000000\n",
       "14             group_2_max  0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_md = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'saga', max_iter = 1000).fit(X, Y)\n",
    "coefs =  pd.DataFrame({'feature': X.columns, 'est_coef': abs(logit_md.coef_.flatten())})\n",
    "coefs = coefs.sort_values(by = 'est_coef', ascending = False).reset_index(drop = True)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7891842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['loading', 'group_2_avg', 'measurement_17', 'area',\n",
       "       'attribute_0_material_7', 'attribute_0_material_5', 'group_1_max'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs['feature'].loc[0:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656edef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_1 = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'saga', max_iter = 10000).fit(X[coefs['feature'].loc[0:6].values], Y)\n",
    "logit_1_pred = logit_1.predict_proba(X[coefs['feature'].loc[0:6].values])[:, 1]\n",
    "logit_1_score = roc_auc_score(Y, logit_1_pred)\n",
    "print('The area under the ROC curve is:', logit_1_score)\n",
    "\n",
    "## Predicting on test with best model \n",
    "logit_1_test_pred = logit_1.predict_proba(test[coefs['feature'].loc[0:6].values])[:, 1] \n",
    "\n",
    "## Defining data-frame to be exported\n",
    "data_out = pd.DataFrame({'id': test_id, 'failure': logit_1_test_pred})\n",
    "data_out.to_csv('Logistic_submission_top_6_area_knn_avg_1.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
